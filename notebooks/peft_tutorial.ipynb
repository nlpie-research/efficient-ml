{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "#set visible cuda devices\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, IA3Config,TaskType\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    PrefixTuningConfig,\n",
    "    PromptEncoderConfig,\n",
    "    PromptTuningConfig,\n",
    "    prepare_model_for_int8_training,\n",
    "    # AutoPeftModel,\n",
    "    prepare_model_for_kbit_training # only for latest dev version of peft\n",
    ")\n",
    "\n",
    "\n",
    "import evaluate\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import (AutoModelForSequenceClassification,\n",
    "                          AutoModelForTokenClassification, \n",
    "                          AutoModelForCausalLM,\n",
    "                          AutoModelForMaskedLM,\n",
    "                          AutoModel,\n",
    "                        AutoTokenizer,\n",
    "                        get_linear_schedule_with_warmup,\n",
    "                        set_seed,\n",
    "                        LlamaForSequenceClassification,\n",
    "                        LlamaForCausalLM,\n",
    "                        LlamaTokenizer, LongformerForMaskedLM, LongformerForSequenceClassification)\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from loguru import logger as loguru_logger\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from data_utils.model_utils import count_trainable_parameters, freeze_model, unfreeze_model\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # med dataset instructions\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"nlpie/Llama2-MedTuned-Instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 205048\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup some parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count trainable params of a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.llama.tokenization_llama.LlamaTokenizer"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LlamaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 2\n",
    "# model_name_or_path = \"/mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-wecho/sampled_250000/08-03-2023--13-06/checkpoint-84000/\" # \n",
    "# model_name_or_path = \"/mnt/sdc/niallt/saved_models/declutr/mimic/few_epoch/mimic-roberta-base/2_anch_2_pos_min_1024/transformer_format/\"\n",
    "# model_name_or_path = \"/mnt/sdc/niallt/saved_models/language_modelling/mimic/mimic-roberta-base/sampled_250000/22-12-2022--12-45/checkpoint-100000/\"\n",
    "# model_name_or_path = \"/mnt/sdc/niallt/saved_models/declutr/mimic/few_epoch/mimic-roberta-base/2_anch_2_pos_min_1024/transformer_format/\"\n",
    "model_name_or_path = \"roberta-base\" # | roberta-large\n",
    "peft_method = \"LORA\" # | PROMPT_TUNING | PREFIX_TUNING | P_TUNING\n",
    "device = \"cuda\"\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## llama model\n",
    "# model_name_or_path = \"decapoda-research/llama-7b-hf\" # ybelkada/falcon-7b-sharded-bf16\n",
    "model_name_or_path =\"ybelkada/falcon-7b-sharded-bf16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a363db36d247929bcb6e7fc3ab8a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca6676602f74e20a4b889a84caddb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/6.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/accelerate/utils/imports.py:197: UserWarning: Intel Extension for PyTorch 1.12 needs to work with PyTorch 1.12.*, but PyTorch 2.0.1 is found. Please switch to the matching version and run again.\n",
      "  warnings.warn(\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a97c69788fe479e820f8c1cf7858b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## open llama 3b\n",
    "model_path = 'openlm-research/open_llama_3b'\n",
    "model = LlamaForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 3200, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (k_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (v_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (o_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3200, out_features=8640, bias=False)\n",
       "          (down_proj): Linear(in_features=8640, out_features=3200, bias=False)\n",
       "          (up_proj): Linear(in_features=3200, out_features=8640, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3200, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    }
   ],
   "source": [
    "auto_model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 3200, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (k_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (v_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (o_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3200, out_features=8640, bias=False)\n",
       "          (down_proj): Linear(in_features=8640, out_features=3200, bias=False)\n",
       "          (up_proj): Linear(in_features=3200, out_features=8640, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3200, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/accelerate/utils/imports.py:249: UserWarning: Intel Extension for PyTorch 1.12 needs to work with PyTorch 1.12.*, but PyTorch 2.1.2 is found. Please switch to the matching version and run again.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load standard model with peft\n",
    "model_name_or_path = \"roberta-base\"\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map = \"auto\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map = \"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model hidden states\n",
    "# create random prompt\n",
    "prompt = \"this is a test prompt and lets make it bit longer for funsies\"\n",
    "batch = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "# pass to model and get hidden states\n",
    "outputs = model(**batch, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0184,  0.1240],\n",
       "         [-0.0780,  0.4109],\n",
       "         [-0.2964,  0.3555],\n",
       "         [-0.2192,  0.1602],\n",
       "         [-0.0996,  0.2478],\n",
       "         [-0.0077,  0.3706],\n",
       "         [-0.2177,  0.5303],\n",
       "         [-0.0495,  0.4836],\n",
       "         [-0.2133,  0.2869],\n",
       "         [-0.0471,  0.3550],\n",
       "         [-0.0575,  0.3772],\n",
       "         [-0.1148,  0.1251],\n",
       "         [-0.2037,  0.4351],\n",
       "         [-0.0977,  0.2900],\n",
       "         [-0.1378,  0.4795],\n",
       "         [-0.2089,  0.2837],\n",
       "         [ 0.0451,  0.1555]]], dtype=torch.float16, grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.hidden_states[12].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 17, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.hidden_states[12].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0184,  0.1240],\n",
       "         [-0.0780,  0.4109],\n",
       "         [-0.2964,  0.3555],\n",
       "         [-0.2192,  0.1602],\n",
       "         [-0.0996,  0.2478],\n",
       "         [-0.0077,  0.3706],\n",
       "         [-0.2177,  0.5303],\n",
       "         [-0.0495,  0.4836],\n",
       "         [-0.2133,  0.2869],\n",
       "         [-0.0471,  0.3550],\n",
       "         [-0.0575,  0.3772],\n",
       "         [-0.1148,  0.1251],\n",
       "         [-0.2037,  0.4351],\n",
       "         [-0.0977,  0.2900],\n",
       "         [-0.1378,  0.4795],\n",
       "         [-0.2089,  0.2837],\n",
       "         [ 0.0451,  0.1555]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass manually to token classifier head\n",
    "model.classifier(outputs.hidden_states[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0184,  0.1240],\n",
       "         [-0.0780,  0.4109],\n",
       "         [-0.2964,  0.3555],\n",
       "         [-0.2192,  0.1602],\n",
       "         [-0.0996,  0.2478],\n",
       "         [-0.0077,  0.3706],\n",
       "         [-0.2177,  0.5303],\n",
       "         [-0.0495,  0.4836],\n",
       "         [-0.2133,  0.2869],\n",
       "         [-0.0471,  0.3550],\n",
       "         [-0.0575,  0.3772],\n",
       "         [-0.1148,  0.1251],\n",
       "         [-0.2037,  0.4351],\n",
       "         [-0.0977,  0.2900],\n",
       "         [-0.1378,  0.4795],\n",
       "         [-0.2089,  0.2837],\n",
       "         [ 0.0451,  0.1555]]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decompose the classifier\n",
    "\n",
    "outputs.hidden_states[12].cuda() @ model.classifier.weight.T + model.classifier.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just freeze the plm\n",
    "freeze_model(model.base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592130"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load standard model with peft\n",
    "model_name_or_path = \"roberta-base\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map = \"auto\")\n",
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type = \"SEQ_CLS\", inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1, modules_to_save=[\"classifier\"])\n",
    "peft_model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='roberta-base', revision=None, task_type='SEQ_CLS', inference_mode=False, r=8, target_modules={'value', 'query'}, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', modules_to_save=['classifier'], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184260"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(peft_model.base_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### can we load in a base peft model with no spcific task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can happen is the get_peft_model will end up freezing all layers if no task is specified\n",
    "\n",
    "[x] - Works for AutoModel with no LM head\n",
    "[]  - Does not work for AutoModelForMLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "auto_model = AutoModel.from_pretrained(model_name_or_path, torch_dtype=torch.float16)\n",
    "mlm_model = AutoModelForMaskedLM.from_pretrained(model_name_or_path, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type=None, inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, base_model_name_or_path=None, revision=None, task_type=None, inference_mode=False, r=8, target_modules=None, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lora_roberta  \u001b[39m=\u001b[39m get_peft_model(model, peft_config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "lora_roberta  = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForMaskedLM(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 124,992,345 || trainable%: 0.23594404921357384\n"
     ]
    }
   ],
   "source": [
    "lora_roberta.print_trainable_parameters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we use peft on top of peft method - i.e. LORA first and then PROMPT_TUNING on top of that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_roberta  = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,479,172 || all params: 125,534,212 || trainable%: 1.1783018959006968\n"
     ]
    }
   ],
   "source": [
    "lora_roberta.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count trainable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1479172"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(lora_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,479,172 || all params: 125,534,212 || trainable%: 1.1783018959006968\n"
     ]
    }
   ],
   "source": [
    "lora_roberta.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'named_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B129.67.153.198/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb#Y223sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m lr \u001b[39m=\u001b[39m \u001b[39m1e-3\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B129.67.153.198/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb#Y223sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m second_peft_config \u001b[39m=\u001b[39m PromptTuningConfig(task_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSEQ_CLS\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B129.67.153.198/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb#Y223sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m                                     num_virtual_tokens\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B129.67.153.198/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb#Y223sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m full_peft_roberta \u001b[39m=\u001b[39m get_peft_model(lora_roberta, second_peft_config)\n",
      "File \u001b[0;32m~/peft/src/peft/mapping.py:122\u001b[0m, in \u001b[0;36mget_peft_model\u001b[0;34m(model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(peft_config, PromptLearningConfig):\n\u001b[1;32m    121\u001b[0m     peft_config \u001b[39m=\u001b[39m _prepare_prompt_learning_config(peft_config, model_config)\n\u001b[0;32m--> 122\u001b[0m \u001b[39mreturn\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING[peft_config\u001b[39m.\u001b[39;49mtask_type](model, peft_config, adapter_name\u001b[39m=\u001b[39;49madapter_name)\n",
      "File \u001b[0;32m~/peft/src/peft/peft_model.py:613\u001b[0m, in \u001b[0;36mPeftModelForSequenceClassification.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, model, peft_config: PeftConfig, adapter_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 613\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(model, peft_config, adapter_name)\n\u001b[1;32m    614\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodules_to_save \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    615\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodules_to_save \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m}\n",
      "File \u001b[0;32m~/peft/src/peft/peft_model.py:111\u001b[0m, in \u001b[0;36mPeftModel.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_additional_trainable_modules(peft_config, adapter_name)\n\u001b[1;32m    110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_adapter(adapter_name, peft_config)\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39mis_gradient_checkpointing\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    114\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_model_for_gradient_checkpointing(model)\n",
      "File \u001b[0;32m~/peft/src/peft/peft_model.py:375\u001b[0m, in \u001b[0;36mPeftModel.add_adapter\u001b[0;34m(self, adapter_name, peft_config)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpeft_config[adapter_name] \u001b[39m=\u001b[39m peft_config\n\u001b[1;32m    374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(peft_config, PromptLearningConfig):\n\u001b[0;32m--> 375\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_prompt_encoder(adapter_name)\n\u001b[1;32m    376\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_model\u001b[39m.\u001b[39madd_adapter(adapter_name, peft_config)\n",
      "File \u001b[0;32m~/peft/src/peft/peft_model.py:223\u001b[0m, in \u001b[0;36mPeftModel._setup_prompt_encoder\u001b[0;34m(self, adapter_name)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mnum_transformer_submodules \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     config\u001b[39m.\u001b[39mnum_transformer_submodules \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mtask_type \u001b[39m==\u001b[39m TaskType\u001b[39m.\u001b[39mSEQ_2_SEQ_LM \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m named_param, value \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(transformer_backbone\u001b[39m.\u001b[39;49mnamed_parameters()):\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mvocab_size:\n\u001b[1;32m    225\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embeddings \u001b[39m=\u001b[39m transformer_backbone\u001b[39m.\u001b[39mget_submodule(named_param\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.weight\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'named_parameters'"
     ]
    }
   ],
   "source": [
    "# now run this through the prefix tuning peft config too\n",
    "\n",
    "second_peft_type = PeftType.PROMPT_TUNING\n",
    "lr = 1e-3\n",
    "second_peft_config = PromptTuningConfig(task_type=\"SEQ_CLS\", \n",
    "                                    num_virtual_tokens=10)\n",
    "\n",
    "full_peft_roberta = get_peft_model(lora_roberta, second_peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IA3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type =PeftType.IA3\n",
    "# peft_config = IA3Config(task_type=\"SEQ_CLS\", inference_mode=False)\n",
    "# for bio-distilbert\n",
    "peft_config = IA3Config(task_type=\"SEQ_CLS\", \n",
    "                        target_modules=[\"k_lin\", \"v_lin\",\"lin1\", \"lin2\"], \n",
    "                        feedforward_modules=[\"lin1\",\"lin2\"],\n",
    "                        inference_mode=False)\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IA3Config(peft_type=<PeftType.IA3: 'IA3'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='SEQ_CLS', inference_mode=False, target_modules=None, feedforward_modules=None, fan_in_fan_out=False, modules_to_save=None, init_ia3_weights=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at nlpie/bio-distilbert-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 624,386 || all params: 67,579,396 || trainable%: 0.9239295361562568\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"nlpie/bio-distilbert-uncased\" # \"nlpie/bio-mobilebert\" nlpie/bio-distilbert-uncased\n",
    " \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): IA3Model(\n",
       "    (model): DistilBertForSequenceClassification(\n",
       "      (distilbert): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(\n",
       "                  in_features=768, out_features=768, bias=True\n",
       "                  (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 768x1])\n",
       "                )\n",
       "                (v_lin): Linear(\n",
       "                  in_features=768, out_features=768, bias=True\n",
       "                  (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 768x1])\n",
       "                )\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(\n",
       "                  in_features=768, out_features=3072, bias=True\n",
       "                  (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 1x768])\n",
       "                )\n",
       "                (lin2): Linear(\n",
       "                  in_features=3072, out_features=768, bias=True\n",
       "                  (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 1x3072])\n",
       "                )\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pre_classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=128, bias=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.model.mobilebert.encoder.layer[0].bottleneck.attention.dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': IA3Config(peft_type=<PeftType.IA3: 'IA3'>, auto_mapping=None, base_model_name_or_path='roberta-base', revision=None, task_type='SEQ_CLS', inference_mode=False, target_modules=['key', 'value', 'output.dense'], feedforward_modules=['output.dense'], fan_in_fan_out=False, modules_to_save=None, init_ia3_weights=True)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): IA3Model(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 768x1])\n",
       "                  )\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 768x1])\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 1x768])\n",
       "                  )\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(\n",
       "                  in_features=3072, out_features=768, bias=True\n",
       "                  (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 1x3072])\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mobile bert models\n",
    "at moment does not work with mobile bert models - the peft library does not support them directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at nlpie/clinical-mobilebert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# moible bert doesn't work with lora right now\n",
    "mobile_bert = AutoModelForSequenceClassification.from_pretrained(\"nlpie/clinical-mobilebert\") # nlpie/clinical-mobilebert | nlpie/bio-mobilebert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileBertForSequenceClassification(\n",
       "  (mobilebert): MobileBertModel(\n",
       "    (embeddings): MobileBertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
       "      (LayerNorm): NoNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): MobileBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x MobileBertLayer(\n",
       "          (attention): MobileBertAttention(\n",
       "            (self): MobileBertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): MobileBertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): MobileBertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (output): MobileBertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (bottleneck): OutputBottleneck(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (bottleneck): Bottleneck(\n",
       "            (input): BottleneckLayer(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "            (attention): BottleneckLayer(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (ffn): ModuleList(\n",
       "            (0-2): 3 x FFNLayer(\n",
       "              (intermediate): MobileBertIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): ReLU()\n",
       "              )\n",
       "              (output): FFNOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (LayerNorm): NoNorm()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): MobileBertPooler()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileBertConfig {\n",
       "  \"_name_or_path\": \"nlpie/bio-mobilebert\",\n",
       "  \"architectures\": [\n",
       "    \"MobileBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_activation\": false,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"embedding_size\": 128,\n",
       "  \"hidden_act\": \"relu\",\n",
       "  \"hidden_dropout_prob\": 0.0,\n",
       "  \"hidden_size\": 512,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 512,\n",
       "  \"intra_bottleneck_size\": 128,\n",
       "  \"key_query_shared_bottleneck\": true,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"mobilebert\",\n",
       "  \"normalization_type\": \"no_norm\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_feedforward_networks\": 4,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.30.2\",\n",
       "  \"trigram_input\": true,\n",
       "  \"true_hidden_size\": 128,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_bottleneck\": true,\n",
       "  \"use_bottleneck_attention\": false,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_bert.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", target_modules=[\"key\", \"value\", \"query\"], inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get peft model\n",
    "lora_mobile_bert  = get_peft_model(mobile_bert, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MobileBertForSequenceClassification(\n",
       "      (mobilebert): MobileBertModel(\n",
       "        (embeddings): MobileBertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 512)\n",
       "          (token_type_embeddings): Embedding(2, 512)\n",
       "          (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (encoder): MobileBertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-23): 24 x MobileBertLayer(\n",
       "              (attention): MobileBertAttention(\n",
       "                (self): MobileBertSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=128, out_features=128, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(\n",
       "                    in_features=128, out_features=128, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): Linear(\n",
       "                    in_features=512, out_features=128, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): MobileBertSelfOutput(\n",
       "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (LayerNorm): NoNorm()\n",
       "                )\n",
       "              )\n",
       "              (intermediate): MobileBertIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): ReLU()\n",
       "              )\n",
       "              (output): MobileBertOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (LayerNorm): NoNorm()\n",
       "                (bottleneck): OutputBottleneck(\n",
       "                  (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                  (LayerNorm): NoNorm()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (bottleneck): Bottleneck(\n",
       "                (input): BottleneckLayer(\n",
       "                  (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  (LayerNorm): NoNorm()\n",
       "                )\n",
       "                (attention): BottleneckLayer(\n",
       "                  (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  (LayerNorm): NoNorm()\n",
       "                )\n",
       "              )\n",
       "              (ffn): ModuleList(\n",
       "                (0-2): 3 x FFNLayer(\n",
       "                  (intermediate): MobileBertIntermediate(\n",
       "                    (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (intermediate_act_fn): ReLU()\n",
       "                  )\n",
       "                  (output): FFNOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                    (LayerNorm): NoNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): MobileBertPooler()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=512, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_mobile_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222210"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(lora_mobile_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1026"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(lora_mobile_bert.base_model.classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distil bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at nlpie/bio-distilbert-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "distil_bert = AutoModelForSequenceClassification.from_pretrained(\"nlpie/bio-distilbert-uncased\") # distilbert-base-uncased nlpie/distil-biobert nlpie/distil-clinicalbert nlpie/bio-distilbert-uncased\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distil_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65784578"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(distil_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", target_modules=[\"q_lin\",\"k_lin\", \"v_lin\"], inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_distil_bert  = get_peft_model(distil_bert, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DistilBertForSequenceClassification(\n",
       "      (distilbert): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(\n",
       "                  in_features=768, out_features=768, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (k_lin): Linear(\n",
       "                  in_features=768, out_features=768, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (v_lin): Linear(\n",
       "                  in_features=768, out_features=768, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pre_classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_distil_bert "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"nlpie/bio-distilbert-uncased\" # \"nlpie/bio-mobilebert\" nlpie/bio-distilbert-uncased\n",
    "peft_type = PeftType.PREFIX_TUNING\n",
    "# peft_config = PrefixTuningConfig(task_type=\"SEQ_CLS\",\n",
    "#                                     num_virtual_tokens=20,\n",
    "#           )\n",
    "\n",
    "# for distil\n",
    "peft_config = PrefixTuningConfig(task_type=\"SEQ_CLS\",\n",
    "                                    num_virtual_tokens=20,\n",
    "                                    num_layers = 6,\n",
    "                                    num_attention_heads = 12,\n",
    "                                    token_dim = 768)\n",
    "lr = 1e-2 # default 1e-2\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True)\n",
    "model = get_peft_model(model, peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': PrefixTuningConfig(peft_type=<PeftType.PREFIX_TUNING: 'PREFIX_TUNING'>, auto_mapping=None, base_model_name_or_path='roberta-base', revision=None, task_type='SEQ_CLS', inference_mode=False, num_virtual_tokens=20, token_dim=768, num_transformer_submodules=1, num_attention_heads=12, num_layers=12, encoder_hidden_size=768, prefix_projection=False)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tiny bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpie/tiny-biobert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tiny_bert = AutoModelForSequenceClassification.from_pretrained(\"nlpie/tiny-biobert\") # prajjwal1/bert-tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type =PeftType.IA3\n",
    "peft_config = IA3Config(task_type=\"SEQ_CLS\", inference_mode=False)\n",
    "# for bio-distilbert\n",
    "# peft_config = IA3Config(task_type=\"SEQ_CLS\", \n",
    "#                         target_modules=[\"k_lin\", \"v_lin\",\"lin1\", \"lin2\"], \n",
    "#                         feedforward_modules=[\"lin1\",\"lin2\"],\n",
    "#                         inference_mode=False)\n",
    "lr = 1e-3\n",
    "\n",
    "model = get_peft_model(tiny_bert, peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): IA3Model(\n",
       "    (model): BertForSequenceClassification(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(28996, 312, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 312)\n",
       "          (token_type_embeddings): Embedding(2, 312)\n",
       "          (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-3): 4 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "                  (key): Linear(\n",
       "                    in_features=312, out_features=312, bias=True\n",
       "                    (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 312x1])\n",
       "                  )\n",
       "                  (value): Linear(\n",
       "                    in_features=312, out_features=312, bias=True\n",
       "                    (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 312x1])\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(\n",
       "                    in_features=312, out_features=312, bias=True\n",
       "                    (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 1x312])\n",
       "                  )\n",
       "                  (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(\n",
       "                  in_features=1200, out_features=312, bias=True\n",
       "                  (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 1x1200])\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=312, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=312, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longformer models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load longformer \n",
    "\n",
    "longformer = LongformerForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerClassificationHead(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longformer.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148660994"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(longformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592130"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(longformer.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"longformer\" in \"yikuan8/Clinical-Longformer\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at yikuan8/Clinical-Longformer were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'longformer.embeddings.position_ids', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "auto_longformer = AutoModelForSequenceClassification.from_pretrained(\"yikuan8/Clinical-Longformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148660994"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(auto_longformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592130"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(auto_longformer.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerClassificationHead(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_longformer.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type=None, target_modules=[\"query\",\"value\",\"key\", \n",
    "                                                         \"query_global\", \n",
    "                                                         \"value_global\",\n",
    "                                                         \"key_global\"] ,inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_longformer = get_peft_model(longformer, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LongformerForSequenceClassification(\n",
       "      (longformer): LongformerModel(\n",
       "        (embeddings): LongformerEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "        )\n",
       "        (encoder): LongformerEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x LongformerLayer(\n",
       "              (attention): LongformerAttention(\n",
       "                (self): LongformerSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (query_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                )\n",
       "                (output): LongformerSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): LongformerIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): LongformerOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): LongformerClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 149,545,730 || trainable%: 0.5916156883917716\n"
     ]
    }
   ],
   "source": [
    "peft_longformer.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(peft_longformer.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze classifier\n",
    "unfreeze_model(peft_longformer.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592130"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(peft_longformer.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,476,866 || all params: 149,545,730 || trainable%: 0.987568150558361\n"
     ]
    }
   ],
   "source": [
    "peft_longformer.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LongformerForSequenceClassification(\n",
       "      (longformer): LongformerModel(\n",
       "        (embeddings): LongformerEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "        )\n",
       "        (encoder): LongformerEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x LongformerLayer(\n",
       "              (attention): LongformerAttention(\n",
       "                (self): LongformerSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (query_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                )\n",
       "                (output): LongformerSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): LongformerIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): LongformerOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): LongformerClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerClassificationHead(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_longformer.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when no task is specified peft library freezes all non-lora weights including the classifier etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a57c6d755b0429a97e69d6e1d5a51c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d6bce44e31432eab757d90e0bccb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9c1d7d6fdc4769b694234daa06d97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create set of inputs to pass to transformer model\n",
    "inputs = tokenizer([\"Hello, my dog is cute\", \"Hello, my cat is cute\"], return_tensors=\"pt\", padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 31414,     6,  ...,     1,     1,     1],\n",
       "        [    0, 31414,     6,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass to model\n",
    "outputs = peft_longformer(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we just load with seq task type? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", target_modules=[\"query\",\"value\",\"key\", \n",
    "                                                         \"query_global\", \n",
    "                                                         \"value_global\",\n",
    "                                                         \"key_global\"] ,inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_long_auto = get_peft_model(auto_longformer, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LongformerForSequenceClassification(\n",
       "      (longformer): LongformerModel(\n",
       "        (embeddings): LongformerEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "        )\n",
       "        (encoder): LongformerEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x LongformerLayer(\n",
       "              (attention): LongformerAttention(\n",
       "                (self): LongformerSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (query_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                )\n",
       "                (output): LongformerSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): LongformerIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): LongformerOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): LongformerClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): LongformerClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_long_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,068,996 || all params: 150,137,860 || trainable%: 1.3780641338567101\n"
     ]
    }
   ],
   "source": [
    "lora_long_auto.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModulesToSaveWrapper(\n",
       "  (original_module): LongformerClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       "  (modules_to_save): ModuleDict(\n",
       "    (default): LongformerClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_long_auto.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184260"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(lora_long_auto.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591360"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768*768 + 768*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal LM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "clm_model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38597376"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(clm_model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=50257, bias=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clm_model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clm_peft_config = LoraConfig(task_type=\"CAUSAL_LM\",\n",
    "                             \n",
    "                         inference_mode=False,\n",
    "                         r=8,\n",
    "                         lora_alpha=16,\n",
    "                         lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=8, target_modules=['query', 'value', 'key', 'lm_head.dense'], lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clm_peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "from_pretrained() missing 1 required positional argument: 'model_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-94a0b8e7726d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mPeftModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclm_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: from_pretrained() missing 1 required positional argument: 'model_id'"
     ]
    }
   ],
   "source": [
    "PeftModel.from_pretrained(clm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niall\\anaconda3\\envs\\general_nlp\\lib\\site-packages\\peft\\tuners\\lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "peft_clm_model = get_peft_model(clm_model, clm_peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2LMHeadModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): Linear(\n",
       "                in_features=768, out_features=2304, bias=True\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_clm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294912"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(peft_clm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_model(peft_clm_model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38892288"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(peft_clm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked language model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/accelerate/utils/imports.py:197: UserWarning: Intel Extension for PyTorch 1.12 needs to work with PyTorch 1.12.*, but PyTorch 2.0.1 is found. Please switch to the matching version and run again.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "# auto_model = AutoModel.from_pretrained(model_name, torch_dtype=torch.float16, device_map = \"auto\")\n",
    "mlm_model = AutoModelForMaskedLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map = \"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124055040"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(mlm_model.base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124697433"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(mlm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaLMHead(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590592"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(mlm_model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38603520"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(mlm_model.roberta.embeddings.word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_model.lm_head.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38653785"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(mlm_model.lm_head.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peft_config = LoraConfig(task_type=None, target_modules=[\"query\",\"value\",\"key\", \"lm_head.dense\"],\n",
    "#                          inference_mode=False,\n",
    "#                          r=8,\n",
    "#                          lora_alpha=16,\n",
    "#                          lora_dropout=0.1)\n",
    "peft_config = LoraConfig(task_type=None,\n",
    "                         inference_mode=False,\n",
    "                         r=8,\n",
    "                         lora_alpha=16,\n",
    "                         lora_dropout=0.1,\n",
    "                         modules_to_save = [\"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load peft model\n",
    "peft_mlm_model = get_peft_model(mlm_model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='roberta-base', revision=None, task_type=None, inference_mode=False, r=8, target_modules=['query', 'value'], lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', modules_to_save=['lm_head'], init_lora_weights=True, layers_to_transform=None, layers_pattern=None)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_mlm_model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78491826"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(peft_mlm_model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaLMHead(\n",
       "  (dense): Linear(\n",
       "    in_features=768, out_features=768, bias=True\n",
       "    (lora_dropout): ModuleDict(\n",
       "      (default): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lora_A): ModuleDict(\n",
       "      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "    )\n",
       "    (lora_B): ModuleDict(\n",
       "      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "    )\n",
       "    (lora_embedding_A): ParameterDict()\n",
       "    (lora_embedding_B): ParameterDict()\n",
       "  )\n",
       "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_mlm_model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to unfreeze/need to just write the class for peft model and add as pull request\n",
    "unfreeze_model(peft_mlm_model.lm_head.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38666073"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(peft_mlm_model.lm_head)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 bit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n",
      "- configuration_RW.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n",
      "- modelling_RW.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9fd57bfaae451b98550c51cf81dbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ybelkada/falcon-7b-sharded-bf16 were not used when initializing RWForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing RWForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RWForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RWForSequenceClassification were not initialized from the model checkpoint at ybelkada/falcon-7b-sharded-bf16 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# can you do 8 bit roberta?\n",
    "model_name_or_path = \"ybelkada/falcon-7b-sharded-bf16\" # | roberta-large | ybelkada/falcon-7b-sharded-bf16\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path,num_labels=7, torch_dtype=torch.bfloat16, \n",
    "                                                              load_in_8bit=True, output_hidden_states=False,                                                                \n",
    "                                                                device_map=\"auto\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.word_embeddings.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prepared = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prepared.transformer.word_embeddings.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model_prepared.roberta.encoder.layer[0].attention.self.query.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear8bitLt(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear8bitLt(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear8bitLt(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear8bitLt(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear8bitLt(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear8bitLt(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear8bitLt(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# falcon \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no pad token\n"
     ]
    }
   ],
   "source": [
    "tokenizer\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    print(\"no pad token\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d702e5fc01164d68987727903f0e30a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ybelkada/falcon-7b-sharded-bf16 were not used when initializing RWForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing RWForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RWForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RWForSequenceClassification were not initialized from the model checkpoint at ybelkada/falcon-7b-sharded-bf16 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "falcon_model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path,num_labels=7, torch_dtype=torch.bfloat16, \n",
    "                                                              load_in_8bit=True, output_hidden_states=False,                                                                \n",
    "                                                                device_map=\"auto\", trust_remote_code = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RWForSequenceClassification(\n",
       "  (transformer): RWModel(\n",
       "    (word_embeddings): Embedding(65024, 4544)\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x DecoderLayer(\n",
       "        (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): Attention(\n",
       "          (maybe_rotary): RotaryEmbedding()\n",
       "          (query_key_value): Linear8bitLt(in_features=4544, out_features=4672, bias=False)\n",
       "          (dense): Linear8bitLt(in_features=4544, out_features=4544, bias=False)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): MLP(\n",
       "          (dense_h_to_4h): Linear8bitLt(in_features=4544, out_features=18176, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (dense_4h_to_h): Linear8bitLt(in_features=18176, out_features=4544, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=4544, out_features=7, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falcon_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "falcon_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falcon_model.config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1d32496bf54e3686fecef02280e58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at decapoda-research/llama-7b-hf were not used when initializing LlamaForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at decapoda-research/llama-7b-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 8 bit llama\n",
    "llama_model = LlamaForSequenceClassification.from_pretrained(model_name_or_path, num_labels=7, torch_dtype=torch.bfloat16, \n",
    "                                                              load_in_8bit=True, output_hidden_states=False,                                                                \n",
    "                                                                device_map=\"auto\",\n",
    "                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16bit\n",
    "# llama_model = LlamaForSequenceClassification.from_pretrained(model_name_or_path, num_labels=7, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (score): Linear(in_features=4096, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (score): Linear(in_features=4096, out_features=7, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", output_hidden_states=True)\n",
    "# custom_model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['roberta.embeddings.position_ids', 'roberta.embeddings.word_embeddings.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for p in roberta_model.parameters():\n",
    "    print(p.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"roberta-base\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.27.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['roberta.embeddings.position_ids', 'roberta.embeddings.word_embeddings.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"/mnt/sdc/niallt/saved_models/declutr/mimic/few_epoch/mimic-roberta-base/2_anch_2_pos_min_1024/transformer_format/\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.27.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for p in custom_model.parameters():\n",
    "    print(p.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761365d64da44b13b8182f80716e95db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac81ba4c83314027a2f1cd2fed7413a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "# custom_tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "llama_tokenizer = LlamaTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizerFast(name_or_path='/mnt/sdc/niallt/saved_models/declutr/mimic/few_epoch/mimic-roberta-base/2_anch_2_pos_min_1024/transformer_format/', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peft_config = LoraConfig(task_type=\"SEQ_CLS\", inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)\n",
    "# lr = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(params=roberta_model.parameters(), lr=0.001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_optimizer = AdamW(params=custom_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to load different peft setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_peft_model(model_name_or_path,                     \n",
    "                     peft_method,\n",
    "                     task_type,                     \n",
    "                     device,\n",
    "                     num_virtual_tokens= 20,\n",
    "                     num_labels = 7):\n",
    "    '''\n",
    "    Function to setup the peft model for training and return a peft model based on the peft method specified.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if peft_method == \"LORA\":\n",
    "        loguru_logger.info(\"Using LORA\")\n",
    "        peft_type = PeftType.LORA\n",
    "        lr = 3e-4\n",
    "        peft_config = LoraConfig(task_type=task_type, inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)\n",
    "    elif peft_method == \"PREFIX_TUNING\":\n",
    "        loguru_logger.info(\"Using PREFIX_TUNING\")\n",
    "        peft_type = PeftType.PREFIX_TUNING\n",
    "        peft_config = PrefixTuningConfig(task_type=task_type, num_virtual_tokens=20)\n",
    "        lr = 1e-2\n",
    "    elif peft_method == \"PROMPT_TUNING\":\n",
    "        loguru_logger.info(\"Using PROMPT_TUNING\")\n",
    "        peft_type = PeftType.PROMPT_TUNING\n",
    "        peft_config = PromptTuningConfig(task_type=task_type, num_virtual_tokens=10)\n",
    "        lr = 1e-3\n",
    "    elif peft_method == \"P_TUNING\":\n",
    "        loguru_logger.info(\"Using P_TUNING\")\n",
    "        peft_type = PeftType.P_TUNING\n",
    "        peft_config = PromptEncoderConfig(task_type=task_type, num_virtual_tokens=20, encoder_hidden_size=128)\n",
    "        lr = 1e-3\n",
    "        \n",
    "\n",
    "    # load peft model\n",
    "    if \"llama\" in model_name_or_path:\n",
    "        loguru_logger.info(\"Loading LLAMA model in 8 bit\")\n",
    "        # model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path,\n",
    "        #                                                            torch_dtype=torch.bfloat16,\n",
    "        #                                                            num_labels = num_labels,return_dict=True)\n",
    "        # 8 bit\n",
    "        model = LlamaForSequenceClassification.from_pretrained(model_name_or_path, num_labels=num_labels, torch_dtype=torch.float16, \n",
    "                                                              load_in_8bit=True, output_hidden_states=False,                                                                \n",
    "                                                                device_map=\"auto\",\n",
    "                                                                )\n",
    "    else:\n",
    "        \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels = num_labels,return_dict=True)\n",
    "        model.to(device)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    # setup optimizer and lr_scheduler\n",
    "    optimizer = AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "    # Instantiate scheduler\n",
    "    lr_scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0.06 * (len(train_dataloader) * num_epochs),\n",
    "        num_training_steps=(len(train_dataloader) * num_epochs),\n",
    "    )\n",
    "    return model, peft_config, optimizer, lr_scheduler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup task and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of various datasets and their sentence keys\n",
    "task_to_keys ={\n",
    "                \"cola\": (\"sentence\", None),\n",
    "                \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "                \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "                \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "                \"qnli\": (\"question\", \"sentence\"),\n",
    "                \"qqp\": (\"question1\", \"question2\"),\n",
    "                \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "                \"sst2\": (\"sentence\", None),\n",
    "                \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "                \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "                \"mimic-note-category\": (\"TEXT\", None),\n",
    "                \"icd9-triage\":(\"text\", None),\n",
    "                \"icd9-triage-no-category-in-text\":(\"text\", None),\n",
    "                \"ICD9-Triage\":(\"text\", None),\n",
    "                \"mednli\":(\"sentence1\", \"sentence2\")\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task for now is icd9-triage\n",
    "task = \"ICD9-Triage\"\n",
    "\n",
    "# task = \"mrpc\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets.yaml', 'r') as f:\n",
    "    datasets = yaml.load(f, yaml.FullLoader)\n",
    "\n",
    "try:\n",
    "    dataset_info = datasets[task]\n",
    "\n",
    "except KeyError:\n",
    "    print(f\"Task name {task} not in datasets.yaml. Available tasks are: {list(datasets.keys())}\")\n",
    "    exit(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_data_dir': '/mnt/sdd/efficient_ml_data/datasets/icd9-triage/no_category_in_text',\n",
       " 'eval_data_dir': '/mnt/sdd/efficient_ml_data/datasets/icd9-triage/no_category_in_text',\n",
       " 'data_dir': '',\n",
       " 'training_file': 'train.csv',\n",
       " 'validation_file': 'valid.csv',\n",
       " 'test_file': 'test.csv',\n",
       " 'task_type': 'SEQ_CLS',\n",
       " 'label_name': 'label',\n",
       " 'text_column': 'text',\n",
       " 'remove_columns': ['text', 'triage-category']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets = load_dataset(\"csv\", \n",
    "                        data_files = {\"train\":f\"{dataset_info['training_data_dir']}/{dataset_info['training_file']}\",\n",
    "                                    \"validation\":f\"{dataset_info['eval_data_dir']}/{dataset_info['validation_file']}\",\n",
    "                                    \"test\":f\"{dataset_info['eval_data_dir']}/{dataset_info['validation_file']}\",\n",
    "                                    },\n",
    "                    cache_dir = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load dataset\n",
    "\n",
    "# training_data_dir = \"/mnt/sdc/niallt/mimic_iii/processed/HADM_ID_split/icd9-triage/no_category_in_text/fewshot_64/\"\n",
    "# eval_data_dir = \"/mnt/sdc/niallt/mimic_iii/processed/HADM_ID_split/icd9-triage/no_category_in_text/\"\n",
    "# datasets = load_dataset(\"csv\", \n",
    "#                         data_files = {\"train\":f\"{training_data_dir}/train.csv\",\n",
    "#                                         \"validation\":f\"{eval_data_dir}/valid.csv\",\n",
    "#                                         \"test\":f\"{eval_data_dir}/test.csv\"},\n",
    "#                         cache_dir = \"/mnt/sdc/niallt/.cache/\")\n",
    "\n",
    "# loguru_logger.info(f\"Number of training samples: {len(datasets['train'])}\\n and validation samples:{len(datasets['validation'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of labels\n",
    "num_labels = len(np.unique(datasets[\"train\"][\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets[\"train\"])/batch_size * num_epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-process/encode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1_key, sentence2_key = task_to_keys[task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"roberta-base\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
    "    padding_side = \"left\"\n",
    "else:\n",
    "    padding_side = \"right\"\n",
    "\n",
    "if \"llama\" in model_name_or_path:\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "# set the sentence/task keys\n",
    "# sentence1_key, sentence2_key = task_to_keys[task]\n",
    "\n",
    "# for glue\n",
    "# def tokenize_function(examples):\n",
    "#     # max_length=None => use the model max length (it's actually the default)\n",
    "#     outputs = tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True, max_length=480)\n",
    "#     return outputs\n",
    "\n",
    "# own\n",
    "def tokenize_function(examples):\n",
    "    # max_length is important when using prompt tuning  or prefix tuning or p tuning as virtual tokens are added - which can overshoot the max length in pefts current form\n",
    "    # for now set to 480 and see how it goes\n",
    "    if sentence2_key is None:\n",
    "        return tokenizer(examples[sentence1_key], truncation=True, max_length = 480)\n",
    "    return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True, max_length=480)\n",
    "\n",
    "# own\n",
    "tokenized_datasets = datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=['text', 'triage-category']\n",
    ")\n",
    "\n",
    "# for glue\n",
    "# tokenized_datasets = datasets.map(\n",
    "#     tokenize_function,\n",
    "#     batched=True,\n",
    "#     remove_columns=[\"idx\", \"sentence1\", \"sentence2\"],\n",
    "# )\n",
    "# We also rename the 'label' column to 'labels' which is the expected name for labels by the models of the\n",
    "# transformers library\n",
    "# tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "\n",
    "def collate_fn(examples):\n",
    "    return tokenizer.pad(examples, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "# Instantiate dataloaders.\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, collate_fn=collate_fn, batch_size=batch_size)\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], shuffle=False, collate_fn=collate_fn, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"labels\" not in tokenized_datasets[\"train\"].features:\n",
    "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'input_ids': [0,\n",
       "  35,\n",
       "  4832,\n",
       "  4832,\n",
       "  2099,\n",
       "  35,\n",
       "  856,\n",
       "  26331,\n",
       "  35,\n",
       "  3186,\n",
       "  2673,\n",
       "  25,\n",
       "  519,\n",
       "  117,\n",
       "  684,\n",
       "  26331,\n",
       "  7,\n",
       "  2196,\n",
       "  4832,\n",
       "  18769,\n",
       "  19,\n",
       "  21655,\n",
       "  1499,\n",
       "  6,\n",
       "  1144,\n",
       "  22802,\n",
       "  20541,\n",
       "  187,\n",
       "  1423,\n",
       "  73,\n",
       "  139,\n",
       "  538,\n",
       "  15535,\n",
       "  50,\n",
       "  19341,\n",
       "  7089,\n",
       "  35,\n",
       "  6286,\n",
       "  7085,\n",
       "  24423,\n",
       "  5010,\n",
       "  1640,\n",
       "  5471,\n",
       "  8635,\n",
       "  11576,\n",
       "  1423,\n",
       "  73,\n",
       "  139,\n",
       "  2182,\n",
       "  19,\n",
       "  684,\n",
       "  475,\n",
       "  45883,\n",
       "  54,\n",
       "  21,\n",
       "  6443,\n",
       "  19,\n",
       "  10,\n",
       "  1144,\n",
       "  22802,\n",
       "  20541,\n",
       "  23,\n",
       "  1046,\n",
       "  479,\n",
       "  79,\n",
       "  21,\n",
       "  15423,\n",
       "  19,\n",
       "  13603,\n",
       "  326,\n",
       "  859,\n",
       "  18,\n",
       "  61,\n",
       "  969,\n",
       "  21319,\n",
       "  475,\n",
       "  338,\n",
       "  4,\n",
       "  23930,\n",
       "  969,\n",
       "  784,\n",
       "  548,\n",
       "  506,\n",
       "  7606,\n",
       "  19,\n",
       "  6286,\n",
       "  7085,\n",
       "  24423,\n",
       "  6701,\n",
       "  7150,\n",
       "  41448,\n",
       "  13484,\n",
       "  9,\n",
       "  7606,\n",
       "  4,\n",
       "  79,\n",
       "  9118,\n",
       "  143,\n",
       "  5298,\n",
       "  4,\n",
       "  375,\n",
       "  1131,\n",
       "  750,\n",
       "  35,\n",
       "  8944,\n",
       "  33330,\n",
       "  808,\n",
       "  23249,\n",
       "  6,\n",
       "  475,\n",
       "  45883,\n",
       "  73,\n",
       "  35685,\n",
       "  6,\n",
       "  6943,\n",
       "  6,\n",
       "  14057,\n",
       "  592,\n",
       "  750,\n",
       "  35,\n",
       "  592,\n",
       "  4400,\n",
       "  2678,\n",
       "  6,\n",
       "  697,\n",
       "  19,\n",
       "  985,\n",
       "  6,\n",
       "  9118,\n",
       "  6106,\n",
       "  50,\n",
       "  9681,\n",
       "  304,\n",
       "  284,\n",
       "  750,\n",
       "  35,\n",
       "  786,\n",
       "  10800,\n",
       "  24008,\n",
       "  4405,\n",
       "  2166,\n",
       "  10743,\n",
       "  35,\n",
       "  1423,\n",
       "  73,\n",
       "  139,\n",
       "  856,\n",
       "  11,\n",
       "  3267,\n",
       "  295,\n",
       "  625,\n",
       "  14913,\n",
       "  10,\n",
       "  102,\n",
       "  947,\n",
       "  4325,\n",
       "  6,\n",
       "  786,\n",
       "  506,\n",
       "  21103,\n",
       "  7050,\n",
       "  740,\n",
       "  34108,\n",
       "  18237,\n",
       "  35237,\n",
       "  873,\n",
       "  9640,\n",
       "  23427,\n",
       "  40139,\n",
       "  4375,\n",
       "  6,\n",
       "  740,\n",
       "  73,\n",
       "  417,\n",
       "  73,\n",
       "  118,\n",
       "  117,\n",
       "  385,\n",
       "  73,\n",
       "  438,\n",
       "  6,\n",
       "  910,\n",
       "  28015,\n",
       "  117,\n",
       "  475,\n",
       "  73,\n",
       "  338,\n",
       "  73,\n",
       "  571,\n",
       "  7050,\n",
       "  25587,\n",
       "  8,\n",
       "  9066,\n",
       "  1120,\n",
       "  2617,\n",
       "  22893,\n",
       "  2928,\n",
       "  4,\n",
       "  4091,\n",
       "  417,\n",
       "  579,\n",
       "  73,\n",
       "  3999,\n",
       "  73,\n",
       "  1187,\n",
       "  73,\n",
       "  4311,\n",
       "  2744,\n",
       "  8935,\n",
       "  3279,\n",
       "  19,\n",
       "  13946,\n",
       "  4803,\n",
       "  8557,\n",
       "  28870,\n",
       "  775,\n",
       "  35,\n",
       "  13206,\n",
       "  17129,\n",
       "  6104,\n",
       "  266,\n",
       "  7050,\n",
       "  36,\n",
       "  6709,\n",
       "  359,\n",
       "  16619,\n",
       "  4832,\n",
       "  524,\n",
       "  7050,\n",
       "  36,\n",
       "  6709,\n",
       "  359,\n",
       "  16619,\n",
       "  1219,\n",
       "  35,\n",
       "  7118,\n",
       "  19385,\n",
       "  462,\n",
       "  23,\n",
       "  6930,\n",
       "  17048,\n",
       "  1131,\n",
       "  1881,\n",
       "  35,\n",
       "  76,\n",
       "  793,\n",
       "  693,\n",
       "  19,\n",
       "  11696,\n",
       "  23,\n",
       "  6930,\n",
       "  17048,\n",
       "  450,\n",
       "  15,\n",
       "  13512,\n",
       "  139,\n",
       "  822,\n",
       "  1219,\n",
       "  13,\n",
       "  42,\n",
       "  9027,\n",
       "  35,\n",
       "  7118,\n",
       "  19385,\n",
       "  462,\n",
       "  23,\n",
       "  6930,\n",
       "  17048,\n",
       "  7335,\n",
       "  35,\n",
       "  11696,\n",
       "  6,\n",
       "  23,\n",
       "  6930,\n",
       "  17048,\n",
       "  450,\n",
       "  15,\n",
       "  2052,\n",
       "  822,\n",
       "  4,\n",
       "  17941,\n",
       "  35,\n",
       "  479,\n",
       "  6044,\n",
       "  8,\n",
       "  30972,\n",
       "  7050,\n",
       "  22750,\n",
       "  30725,\n",
       "  311,\n",
       "  4375,\n",
       "  17301,\n",
       "  8,\n",
       "  18422,\n",
       "  1988,\n",
       "  6204,\n",
       "  36133,\n",
       "  16683,\n",
       "  4,\n",
       "  456,\n",
       "  450,\n",
       "  32,\n",
       "  9640,\n",
       "  23427,\n",
       "  40139,\n",
       "  22893,\n",
       "  8,\n",
       "  22115,\n",
       "  18667,\n",
       "  6286,\n",
       "  7085,\n",
       "  24423,\n",
       "  4,\n",
       "  89,\n",
       "  34,\n",
       "  57,\n",
       "  22455,\n",
       "  3855,\n",
       "  11,\n",
       "  5,\n",
       "  1433,\n",
       "  450,\n",
       "  314,\n",
       "  11299,\n",
       "  6940,\n",
       "  9504,\n",
       "  46224,\n",
       "  5542,\n",
       "  3927,\n",
       "  23,\n",
       "  6930,\n",
       "  17048,\n",
       "  4,\n",
       "  117,\n",
       "  22628,\n",
       "  5963,\n",
       "  1043,\n",
       "  2192,\n",
       "  32,\n",
       "  450,\n",
       "  4,\n",
       "  117,\n",
       "  16415,\n",
       "  9799,\n",
       "  22089,\n",
       "  26841,\n",
       "  32,\n",
       "  450,\n",
       "  4,\n",
       "  8450,\n",
       "  35,\n",
       "  2782,\n",
       "  314,\n",
       "  11299,\n",
       "  6940,\n",
       "  9504,\n",
       "  46224,\n",
       "  38907,\n",
       "  9,\n",
       "  3927,\n",
       "  23,\n",
       "  6930,\n",
       "  17048,\n",
       "  4,\n",
       "  3299,\n",
       "  479,\n",
       "  3299,\n",
       "  4832,\n",
       "  424,\n",
       "  1925,\n",
       "  885,\n",
       "  23219,\n",
       "  42760,\n",
       "  910,\n",
       "  23219,\n",
       "  12,\n",
       "  26487,\n",
       "  1368,\n",
       "  19562,\n",
       "  12,\n",
       "  26487,\n",
       "  1368,\n",
       "  3894,\n",
       "  12,\n",
       "  26487,\n",
       "  475,\n",
       "  38635,\n",
       "  12,\n",
       "  3226,\n",
       "  475,\n",
       "  611,\n",
       "  42760,\n",
       "  475,\n",
       "  611,\n",
       "  438,\n",
       "  12,\n",
       "  26487,\n",
       "  910,\n",
       "  417,\n",
       "  605,\n",
       "  42760,\n",
       "  2968,\n",
       "  90,\n",
       "  740,\n",
       "  90,\n",
       "  12,\n",
       "  4832,\n",
       "  424,\n",
       "  1925,\n",
       "  46238,\n",
       "  12,\n",
       "  26487,\n",
       "  181,\n",
       "  5967,\n",
       "  42760,\n",
       "  11,\n",
       "  338,\n",
       "  1640,\n",
       "  3320,\n",
       "  42760,\n",
       "  4832,\n",
       "  424,\n",
       "  1925,\n",
       "  26071,\n",
       "  12,\n",
       "  3226,\n",
       "  1717,\n",
       "  241,\n",
       "  260,\n",
       "  12,\n",
       "  34113,\n",
       "  42760,\n",
       "  2750,\n",
       "  12,\n",
       "  449,\n",
       "  42760,\n",
       "  3741,\n",
       "  12,\n",
       "  1368,\n",
       "  876,\n",
       "  12,\n",
       "  5667,\n",
       "  1115,\n",
       "  12,\n",
       "  4832,\n",
       "  424,\n",
       "  1925,\n",
       "  28221,\n",
       "  42760,\n",
       "  7843,\n",
       "  366,\n",
       "  42760,\n",
       "  17844,\n",
       "  42760,\n",
       "  4832,\n",
       "  424,\n",
       "  1925,\n",
       "  1907,\n",
       "  12,\n",
       "  2013,\n",
       "  4202,\n",
       "  12,\n",
       "  3226,\n",
       "  181,\n",
       "  876,\n",
       "  12,\n",
       "  7843,\n",
       "  42760,\n",
       "  13011,\n",
       "  298,\n",
       "  876,\n",
       "  12,\n",
       "  7531,\n",
       "  12,\n",
       "  4832,\n",
       "  1925,\n",
       "  2040,\n",
       "  42888,\n",
       "  7304,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>: : : sex: f allergies: patient recorded as having no known allergies to drugs : sob with exertion, heart murmur since y/o major surgical or invasive procedure: mitral valve replacement(mm ce tissue y/o female with known mvp who was diagnosed with a heart murmur at age. she was evaluated with serial tte's which showed worsening mr. echo showed lvef % with mitral valve regurgitant fraction of %. she denies any symptoms. past medical history: hyperlipidemia, mvp/mr, depression, obesity social history: social etoh, live with mother, deniesda or tobacco use family history: noncontributory physical exam: y/o f in bed nad neuro aa&ox, nonfocal chest ctab resp unlab median sternotomy stable, c/d/i no d/c, rrr no m/r/g chest tubes and epicardial wires removed. abd s/nt/nd/bs+ ext warm with trace edema pertinent results: radiology preliminary report chest (pa & lat : am chest (pa & lat reason: assess lll atelectasis medical condition: year old woman with fever atelectasis seen on prio film reason for this examination: assess lll atelectasis indication: fever, atelectasis seen on prior film. comparisons:. pa and lateral chest radiographs show stable cardiac and mediastinal silhouettes. again seen are median sternotomy wires and prosthetic mitral valve. there has been interval improvement in the previously seen left retrocardiac opacity suggesting improving atelectasis. no focal opacities are seen. no pleural effusions are seen. impression: improved left retrocardiac opacity suggestive of improving atelectasis. doctor. doctor :am blood wbc-. rbc-.* hgb-.* hct-.* mcv-* mch-. mchc-.* rdw-. plt ct- :am blood pt-.* ptt-. inr(pt-. :am blood glucose-* urean- creat-. na- k-. cl- hco- angap- :am blood calcium-. phos-. mg-. :am blood type-art po-* pco- ph-. calhco- bases- : blood culture aerobic bottle</s>\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use tokenizer to decode a sample\n",
    "\n",
    "tokenizer.decode(train_dataloader.dataset[0][\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "# run through dataloader and check that the labels are correct\n",
    "for batch in train_dataloader:\n",
    "    # print length of input ids\n",
    "    print(len(batch[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "def compute_metrics(eval_pred):\n",
    "        precision_score = evaluate.load(\"precision\")\n",
    "        recall_score = evaluate.load(\"recall\")\n",
    "        accuracy_score = evaluate.load(\"accuracy\")\n",
    "        f1_score = evaluate.load(\"f1\")        \n",
    "        roc_auc_score = evaluate.load(\"roc_auc\", \"multiclass\")        \n",
    "\n",
    "        logits, labels = eval_pred\n",
    "        \n",
    "        # print(f\"logits are: {logits} of shape: {logits.shape}\")\n",
    "        #TODO add softmax to convert logits to probs\n",
    "        # print(f\"logits shape is: {logits.shape}\")\n",
    "        pred_scores = softmax(logits, axis = -1)        \n",
    "        predictions = np.argmax(logits, axis = -1)\n",
    "        \n",
    "        # print(f\"Labels are: {labels}\\n\")\n",
    "        # print(f\"Preds are: {predictions}\")\n",
    "        precision = precision_score.compute(predictions=predictions, references=labels, average = \"macro\")[\"precision\"]\n",
    "        recall = recall_score.compute(predictions=predictions, references=labels, average = \"macro\")[\"recall\"]\n",
    "        accuracy = accuracy_score.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "        f1_macro = f1_score.compute(predictions=predictions, references=labels, average = \"macro\")[\"f1\"]\n",
    "        f1_micro = f1_score.compute(predictions=predictions, references=labels, average = \"micro\")[\"f1\"]\n",
    "        f1_weighted = f1_score.compute(predictions=predictions, references=labels, average = \"weighted\")[\"f1\"]\n",
    "        # roc_auc has slightly different format - needs the probs/scores rather than predicted labels\n",
    "        roc_auc = roc_auc_score.compute(references=labels,\n",
    "                                        prediction_scores = pred_scores,\n",
    "                                        multi_class = 'ovr', \n",
    "                                        average = \"macro\")['roc_auc']\n",
    "        \n",
    "        return {\"precision\": precision, \n",
    "                \"recall\": recall,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"f1_macro\":f1_macro,\n",
    "                \"f1_micro\":f1_micro,\n",
    "                \"f1_weighted\":f1_weighted,\n",
    "                \"roc_auc_macro\":roc_auc}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup PEFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 15:54:44.832 | INFO     | __main__:setup_peft_model:13 - Using LORA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf1eeabaa1a4f38b2bf6d55a019a2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at decapoda-research/llama-7b-hf were not used when initializing LlamaForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at decapoda-research/llama-7b-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,251,648 || all params: 6,611,595,264 || trainable%: 0.06430593268692861\n"
     ]
    }
   ],
   "source": [
    "model, peft_config, optimizer, lr_scheduler = setup_peft_model(model_name_or_path, peft_method = \"LORA\", task_type = \"SEQ_CLS\", device = \"cuda\", num_labels = num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 13:53:51.951 | INFO     | __main__:setup_peft_model:13 - Using LORA\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1486862 || all params: 125541902 || trainable%: 1.1843551645409993\n"
     ]
    }
   ],
   "source": [
    "# roberta_model, peft_config, optimizer, lr_scheduler = setup_peft_model(\"roberta-base\", peft_method = \"LORA\", task_type = \"SEQ_CLS\", device = \"cuda\", num_labels = num_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros: tensor(149774, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Count the number of zeros in each parameter tensor\n",
    "num_zeros = 0\n",
    "for param in model.parameters():\n",
    "    num_zeros += torch.numel(param) - torch.count_nonzero(param)\n",
    "print(\"Number of zeros:\", num_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros: tensor(150612, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Count the number of zeros in each parameter tensor\n",
    "num_zeros = 0\n",
    "for param in roberta_model.parameters():\n",
    "    num_zeros += torch.numel(param) - torch.count_nonzero(param)\n",
    "print(\"Number of zeros:\", num_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros: tensor(149774, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Count the number of zeros in each parameter tensor\n",
    "num_zeros = 0\n",
    "for param in declutr_model.parameters():\n",
    "    num_zeros += torch.numel(param) - torch.count_nonzero(param)\n",
    "print(\"Number of zeros:\", num_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                                                      Param #\n",
       "====================================================================================================\n",
       "PeftModelForSequenceClassification                                          --\n",
       "├─LoraModel: 1-1                                                            --\n",
       "│    └─RobertaForSequenceClassification: 2-1                                --\n",
       "│    │    └─RobertaModel: 3-1                                               124,349,952\n",
       "│    │    └─ModulesToSaveWrapper: 3-2                                       1,191,950\n",
       "====================================================================================================\n",
       "Total params: 125,541,902\n",
       "Trainable params: 1,486,862\n",
       "Non-trainable params: 124,055,040\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "====================================================================================================\n",
    "Layer (type:depth-idx)                                                      Param #\n",
    "====================================================================================================\n",
    "PeftModelForSequenceClassification                                          --\n",
    "├─LoraModel: 1-1                                                            --\n",
    "│    └─RobertaForSequenceClassification: 2-1                                --\n",
    "│    │    └─RobertaModel: 3-1                                               124,349,952\n",
    "│    │    └─ModulesToSaveWrapper: 3-2                                       1,191,950\n",
    "====================================================================================================\n",
    "Total params: 125,541,902\n",
    "Trainable params: 1,486,862\n",
    "Non-trainable params: 124,055,040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable params: 1486862 || all params: 125541902 || trainable%: 1.1843551645409993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1983452398406846"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "294912/1486862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, base_model_name_or_path='roberta-base', task_type='SEQ_CLS', inference_mode=False, r=8, target_modules=['query', 'value'], lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train PEFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForSequenceClassification(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=4096, out_features=7, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=7, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### debugging - custom roberta model leads to weird memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "predictions:tensor([1, 5, 5, 4], device='cuda:0')\n",
      "references:tensor([0, 1, 1, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for batch in eval_dataloader:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch.to(device))\n",
    "    predictions = outputs.logits.argmax(dim=-1)\n",
    "    predictions, references = predictions, batch[\"labels\"]\n",
    "    print(batch.keys())\n",
    "    # print(f\"outputs:{outputs}\")\n",
    "    print(f\"predictions:{predictions}\")\n",
    "    print(f\"references:{references}\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(2.0110, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.0555, -0.0210, -0.1128,  0.0344,  0.1020, -0.0508, -0.0510],\n",
       "        [-0.0573, -0.0200, -0.1036,  0.0467,  0.1004, -0.0551, -0.0567],\n",
       "        [-0.0556, -0.0172, -0.1156,  0.0369,  0.0998, -0.0592, -0.0500],\n",
       "        [-0.0651, -0.0201, -0.1072,  0.0478,  0.0974, -0.0566, -0.0518]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(2.0342, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.1482, -0.0124, -0.0138,  0.2247,  0.0693, -0.3117,  0.2074],\n",
       "        [-0.0756,  0.0031, -0.0501,  0.1328,  0.0983, -0.2762,  0.2746],\n",
       "        [-0.0222,  0.0371, -0.0096,  0.2350,  0.1343, -0.2727,  0.1959],\n",
       "        [-0.0484, -0.0302, -0.0769,  0.1806, -0.0051, -0.2624,  0.1530]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=(tensor([[[ 0.1712, -0.0483, -0.0230,  ..., -0.0518,  0.0839,  0.0430],\n",
       "         [ 0.0998, -0.1730, -0.0247,  ..., -0.1891, -0.0604,  0.0077],\n",
       "         [-0.1805, -0.3721, -0.0325,  ..., -0.2030, -0.2124,  0.0519],\n",
       "         ...,\n",
       "         [-0.2720,  0.0421,  0.2390,  ..., -0.5429,  0.1871, -0.1404],\n",
       "         [ 0.2573, -0.1542,  0.0187,  ..., -0.9629,  0.0768,  0.2467],\n",
       "         [-0.0058, -0.2664, -0.1019,  ...,  0.3818,  0.1682,  0.1829]],\n",
       "\n",
       "        [[ 0.1712, -0.0483, -0.0230,  ..., -0.0518,  0.0839,  0.0430],\n",
       "         [ 0.0998, -0.1730, -0.0247,  ..., -0.1891, -0.0604,  0.0077],\n",
       "         [-0.1805, -0.3721, -0.0325,  ..., -0.2030, -0.2124,  0.0519],\n",
       "         ...,\n",
       "         [-0.2097, -0.3274,  0.2702,  ...,  0.1441,  0.2568,  0.0109],\n",
       "         [ 0.2086,  0.5350,  0.6377,  ..., -0.0962,  0.0451,  0.0018],\n",
       "         [-0.0058, -0.2664, -0.1019,  ...,  0.3818,  0.1682,  0.1829]],\n",
       "\n",
       "        [[ 0.1712, -0.0483, -0.0230,  ..., -0.0518,  0.0839,  0.0430],\n",
       "         [ 0.0998, -0.1730, -0.0247,  ..., -0.1891, -0.0604,  0.0077],\n",
       "         [-0.1805, -0.3721, -0.0325,  ..., -0.2030, -0.2124,  0.0519],\n",
       "         ...,\n",
       "         [-0.1175, -0.1669,  0.1918,  ...,  0.0619,  0.0245, -0.1847],\n",
       "         [ 0.0338, -0.4038, -0.0889,  ..., -0.3330, -0.0938,  0.0060],\n",
       "         [-0.0058, -0.2664, -0.1019,  ...,  0.3818,  0.1682,  0.1829]],\n",
       "\n",
       "        [[ 0.1712, -0.0483, -0.0230,  ..., -0.0518,  0.0839,  0.0430],\n",
       "         [ 0.0998, -0.1730, -0.0247,  ..., -0.1891, -0.0604,  0.0077],\n",
       "         [-0.1805, -0.3721, -0.0325,  ..., -0.2030, -0.2124,  0.0519],\n",
       "         ...,\n",
       "         [ 0.0581, -0.1827, -0.1092,  ..., -0.3845,  0.0741, -0.1307],\n",
       "         [ 0.1218, -0.5385, -0.0160,  ...,  0.2719, -0.8401,  0.5507],\n",
       "         [-0.0058, -0.2664, -0.1019,  ...,  0.3818,  0.1682,  0.1829]]],\n",
       "       device='cuda:0'), tensor([[[ 0.0266, -0.0183,  0.0226,  ..., -0.0470,  0.0279, -0.1413],\n",
       "         [ 0.7323, -0.0684, -0.2277,  ..., -0.0679, -0.2408,  0.3948],\n",
       "         [ 0.1194, -0.8336, -0.3854,  ..., -0.3688, -0.5647,  0.4122],\n",
       "         ...,\n",
       "         [-0.0295, -0.1339,  0.2329,  ..., -1.1826,  0.1676, -0.3673],\n",
       "         [ 0.2965, -0.3175,  0.0475,  ..., -0.8617, -0.1269,  0.3743],\n",
       "         [-0.6358,  0.0322,  0.0531,  ...,  0.3302, -0.0740,  0.1952]],\n",
       "\n",
       "        [[ 0.0303, -0.0222,  0.0138,  ..., -0.0474,  0.0220, -0.1401],\n",
       "         [ 0.6678, -0.0404, -0.1844,  ..., -0.1214, -0.2659,  0.3617],\n",
       "         [ 0.0596, -0.7457, -0.3503,  ..., -0.3038, -0.6008,  0.3613],\n",
       "         ...,\n",
       "         [-0.0030, -0.4433,  0.3480,  ..., -0.0401,  0.5283, -0.2611],\n",
       "         [ 0.4993,  1.2664,  0.8888,  ..., -0.2329,  0.2774, -0.4313],\n",
       "         [-0.5244, -0.0666,  0.0281,  ...,  0.3130,  0.0643,  0.0481]],\n",
       "\n",
       "        [[ 0.0312, -0.0185,  0.0239,  ..., -0.0476,  0.0206, -0.1396],\n",
       "         [ 0.7046, -0.0233, -0.1864,  ..., -0.0691, -0.2736,  0.4682],\n",
       "         [ 0.1767, -0.8106, -0.3678,  ..., -0.3029, -0.5620,  0.4151],\n",
       "         ...,\n",
       "         [ 0.1061, -0.6260, -0.2030,  ..., -0.0800,  0.1122, -0.0906],\n",
       "         [ 0.0156, -0.6508,  0.2366,  ..., -0.3733, -0.3156,  0.4479],\n",
       "         [-0.4355, -0.0773, -0.0132,  ...,  0.3110, -0.0291,  0.0852]],\n",
       "\n",
       "        [[ 0.0329, -0.0212,  0.0261,  ..., -0.0436,  0.0156, -0.1299],\n",
       "         [ 0.7559, -0.0049, -0.1947,  ..., -0.0397, -0.2475,  0.4408],\n",
       "         [ 0.1648, -0.8419, -0.3752,  ..., -0.2754, -0.5540,  0.4090],\n",
       "         ...,\n",
       "         [ 0.3755, -0.2268, -0.2233,  ..., -0.1891,  0.0449,  0.1021],\n",
       "         [ 0.3526, -0.8990,  0.0121,  ...,  0.4529, -1.2892,  1.2771],\n",
       "         [-0.3810,  0.0097,  0.1224,  ...,  0.3566, -0.0115,  0.1439]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0689,  0.0070,  0.0441,  ...,  0.0143,  0.0442, -0.0497],\n",
       "         [ 0.5191, -0.1454, -0.2387,  ...,  0.1558, -0.5789,  0.5470],\n",
       "         [ 0.0837, -0.8679, -0.2341,  ..., -0.2964, -0.7411,  0.5421],\n",
       "         ...,\n",
       "         [ 0.2520, -0.1139,  0.4221,  ..., -1.5155,  0.2572, -0.3989],\n",
       "         [-0.2664,  0.0746,  0.1572,  ..., -0.6143, -0.2336,  0.2225],\n",
       "         [-0.5096,  0.2834,  0.2533,  ...,  0.5363,  0.3496,  0.4659]],\n",
       "\n",
       "        [[ 0.0715,  0.0100,  0.0420,  ...,  0.0050,  0.0493, -0.0576],\n",
       "         [ 0.5085, -0.0621, -0.2482,  ...,  0.0812, -0.5425,  0.5431],\n",
       "         [ 0.1147, -0.8768, -0.0555,  ..., -0.2742, -0.7695,  0.5062],\n",
       "         ...,\n",
       "         [ 0.0961, -0.4087,  0.2188,  ..., -0.4123,  0.5325, -0.1047],\n",
       "         [ 0.4908,  1.5552,  0.7788,  ..., -1.2737,  0.3759, -0.2535],\n",
       "         [-0.4357,  0.1588,  0.2271,  ...,  0.5161,  0.3326,  0.2792]],\n",
       "\n",
       "        [[ 0.0566, -0.0087,  0.0461,  ...,  0.0078,  0.0394, -0.0573],\n",
       "         [ 0.4967, -0.1478, -0.1599,  ...,  0.0954, -0.5346,  0.5979],\n",
       "         [ 0.1895, -0.8428, -0.1251,  ..., -0.2910, -0.7579,  0.5128],\n",
       "         ...,\n",
       "         [ 0.3105, -0.6041, -0.0093,  ..., -0.1796, -0.1528,  0.2044],\n",
       "         [ 0.2661, -0.7101,  0.3244,  ..., -0.3433, -0.2251,  0.3180],\n",
       "         [-0.4708,  0.0930,  0.2542,  ...,  0.4450,  0.3021,  0.3112]],\n",
       "\n",
       "        [[ 0.0735,  0.0279,  0.0412,  ...,  0.0146,  0.0436, -0.0619],\n",
       "         [ 0.5847, -0.2176, -0.2296,  ...,  0.1573, -0.5229,  0.4669],\n",
       "         [ 0.2027, -0.8637, -0.2009,  ..., -0.2402, -0.6588,  0.4709],\n",
       "         ...,\n",
       "         [ 0.3734, -0.6683,  0.0307,  ..., -0.1150, -0.3139,  0.2051],\n",
       "         [-0.0371, -1.3621, -0.0310,  ...,  0.7322, -0.8900,  0.9141],\n",
       "         [-0.3280,  0.2318,  0.3352,  ...,  0.5411,  0.3552,  0.3557]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 8.4426e-02,  2.8092e-02,  5.4468e-02,  ...,  7.0186e-02,\n",
       "           1.6382e-02, -6.0602e-02],\n",
       "         [ 1.9033e-01,  1.9446e-01, -1.0785e-01,  ..., -8.3040e-03,\n",
       "          -2.4663e-01,  1.6006e-01],\n",
       "         [ 1.2427e-01, -6.7594e-01, -4.8281e-01,  ..., -9.7735e-02,\n",
       "          -3.0454e-01,  4.2236e-01],\n",
       "         ...,\n",
       "         [ 6.0129e-01,  5.2061e-02,  1.7752e-01,  ..., -1.2854e+00,\n",
       "           4.4943e-01,  1.8361e-02],\n",
       "         [ 1.0377e-01,  7.1123e-02,  2.6853e-01,  ..., -4.5236e-01,\n",
       "          -1.5842e-01,  2.0573e-01],\n",
       "         [ 5.4656e-03,  2.6727e-01,  1.2495e-01,  ...,  4.8198e-01,\n",
       "           3.3929e-03,  4.7976e-01]],\n",
       "\n",
       "        [[ 7.7897e-02,  3.1812e-02,  6.9761e-02,  ...,  5.9715e-02,\n",
       "           3.1596e-02, -6.5110e-02],\n",
       "         [ 1.4983e-01,  1.4753e-01, -1.0663e-01,  ...,  3.0120e-02,\n",
       "          -3.8723e-01,  1.6768e-01],\n",
       "         [ 1.7142e-01, -7.8199e-01, -3.3088e-01,  ...,  7.7460e-02,\n",
       "          -4.5483e-01,  4.8176e-01],\n",
       "         ...,\n",
       "         [-4.7154e-01, -8.8890e-02,  3.8556e-01,  ..., -5.1650e-01,\n",
       "           4.4898e-01, -3.4425e-01],\n",
       "         [-5.0395e-01,  1.4709e+00,  5.1013e-01,  ..., -1.3707e+00,\n",
       "           3.5271e-01, -7.7989e-04],\n",
       "         [-1.6232e-01,  1.3514e-01,  2.1151e-01,  ...,  4.6634e-01,\n",
       "           1.3938e-02,  2.6704e-01]],\n",
       "\n",
       "        [[ 6.3145e-02,  7.6183e-03,  7.8755e-02,  ...,  3.7372e-02,\n",
       "           1.0361e-02, -4.9815e-02],\n",
       "         [ 1.1678e-01,  1.0505e-01, -3.1264e-02,  ..., -1.3323e-02,\n",
       "          -1.7706e-01,  3.0897e-01],\n",
       "         [ 1.4113e-01, -7.5080e-01, -4.1681e-01,  ..., -8.3520e-02,\n",
       "          -3.2725e-01,  5.2990e-01],\n",
       "         ...,\n",
       "         [ 5.2416e-01, -3.3018e-01,  2.4757e-01,  ..., -3.9594e-01,\n",
       "          -7.6063e-01,  1.9301e-01],\n",
       "         [-5.7127e-02, -8.9627e-01,  4.0288e-01,  ..., -5.5673e-01,\n",
       "          -3.3693e-01,  1.3507e-01],\n",
       "         [-1.3547e-01,  1.4972e-01,  3.7383e-01,  ...,  3.3322e-01,\n",
       "          -1.7691e-01,  2.6169e-01]],\n",
       "\n",
       "        [[ 8.3911e-02,  3.2985e-02,  7.0859e-02,  ...,  6.2557e-02,\n",
       "           3.6558e-02, -5.7907e-02],\n",
       "         [ 1.3890e-01,  6.4416e-02,  4.6955e-02,  ..., -2.5258e-02,\n",
       "          -2.5109e-01,  2.5990e-01],\n",
       "         [ 1.8165e-01, -7.8058e-01, -3.6653e-01,  ..., -4.4319e-02,\n",
       "          -1.1436e-01,  5.3255e-01],\n",
       "         ...,\n",
       "         [ 1.2036e-01, -5.5646e-01,  5.9343e-01,  ..., -2.9635e-01,\n",
       "          -2.0279e-01,  4.1090e-01],\n",
       "         [ 1.9428e-01, -1.2220e+00,  2.9549e-01,  ...,  7.9631e-01,\n",
       "          -5.4757e-01,  7.3539e-01],\n",
       "         [-9.4948e-02,  3.6587e-01,  4.3374e-01,  ...,  4.9648e-01,\n",
       "          -1.0835e-01,  4.0826e-01]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-4.0383e-02,  5.8217e-02, -1.9119e-02,  ...,  4.3777e-02,\n",
       "          -4.9207e-02, -6.3465e-02],\n",
       "         [-8.3827e-02, -1.0736e-01, -2.5192e-01,  ..., -6.4802e-02,\n",
       "           5.6631e-03,  1.4622e-01],\n",
       "         [-1.2293e-01, -9.6212e-01, -4.1244e-01,  ..., -1.5250e-01,\n",
       "          -6.2958e-01, -1.3514e-01],\n",
       "         ...,\n",
       "         [-4.1948e-02, -3.3058e-01,  2.8094e-01,  ..., -1.1770e+00,\n",
       "           5.0410e-01,  3.6965e-02],\n",
       "         [ 1.4428e-02, -4.0158e-02, -3.5958e-02,  ..., -4.7659e-01,\n",
       "          -1.1652e-02,  2.2096e-01],\n",
       "         [-2.8226e-01, -1.4444e-01, -3.3402e-01,  ...,  3.2754e-01,\n",
       "           1.4087e-01,  6.2506e-01]],\n",
       "\n",
       "        [[-4.9260e-02,  4.9843e-02, -1.3001e-02,  ...,  3.4380e-02,\n",
       "          -1.2267e-02, -6.0515e-02],\n",
       "         [-2.0145e-01, -1.5034e-01, -2.6453e-01,  ..., -1.8686e-02,\n",
       "          -1.0834e-01,  4.8450e-02],\n",
       "         [ 3.9092e-02, -9.8640e-01, -4.0374e-01,  ..., -7.0195e-02,\n",
       "          -7.4434e-01, -2.6197e-01],\n",
       "         ...,\n",
       "         [-6.3434e-01, -4.4986e-01,  5.7599e-01,  ..., -6.1555e-01,\n",
       "           3.7046e-01, -1.7315e-01],\n",
       "         [-5.9209e-01,  1.3520e+00,  2.2267e-01,  ..., -1.5719e+00,\n",
       "           5.4102e-01,  7.4431e-02],\n",
       "         [-3.6481e-01, -3.1280e-01, -2.3585e-01,  ...,  2.7552e-01,\n",
       "           1.0043e-01,  4.2600e-01]],\n",
       "\n",
       "        [[-8.2389e-02,  2.7986e-02, -2.5746e-02,  ...,  1.8564e-02,\n",
       "          -4.6991e-02, -5.1760e-02],\n",
       "         [-2.0051e-01, -2.3945e-01, -2.3043e-01,  ..., -7.9743e-02,\n",
       "           5.2609e-02,  1.7664e-01],\n",
       "         [ 1.0503e-01, -1.1060e+00, -3.3243e-01,  ..., -9.2095e-02,\n",
       "          -6.2586e-01, -4.0180e-02],\n",
       "         ...,\n",
       "         [ 6.9852e-02, -5.2001e-01, -1.6400e-01,  ..., -4.7743e-01,\n",
       "          -5.1104e-01,  2.6599e-01],\n",
       "         [-1.1893e-01, -9.4737e-01, -2.1178e-01,  ..., -4.7595e-01,\n",
       "          -1.5111e-01, -4.1781e-03],\n",
       "         [-2.5013e-01, -2.3911e-01, -1.2230e-01,  ...,  1.3933e-01,\n",
       "          -2.3338e-01,  4.1139e-01]],\n",
       "\n",
       "        [[-9.6117e-02,  3.3484e-02,  3.3583e-04,  ...,  4.7325e-02,\n",
       "          -1.0489e-02, -4.8729e-02],\n",
       "         [-1.1983e-01, -3.1227e-01, -2.1094e-01,  ..., -6.8321e-03,\n",
       "          -4.5459e-02,  1.7615e-01],\n",
       "         [ 1.3393e-02, -1.0250e+00, -3.1129e-01,  ..., -5.9213e-02,\n",
       "          -4.9694e-01, -2.7043e-02],\n",
       "         ...,\n",
       "         [ 2.6110e-01, -4.6020e-01,  2.7039e-02,  ..., -4.2121e-01,\n",
       "          -4.1198e-01,  4.1709e-01],\n",
       "         [-1.7738e-01, -1.2634e+00,  2.4544e-01,  ...,  5.6751e-01,\n",
       "          -5.2401e-01,  8.0776e-01],\n",
       "         [-2.4295e-01,  1.3399e-01,  1.1778e-01,  ...,  3.7028e-01,\n",
       "          -2.8465e-03,  5.2703e-01]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0159,  0.0651,  0.0423,  ...,  0.1560, -0.0291, -0.0374],\n",
       "         [-0.1343, -0.2533,  0.0592,  ...,  0.0834,  0.0114,  0.0589],\n",
       "         [ 0.2658, -1.3150, -0.1270,  ..., -0.2518, -0.7060, -0.1099],\n",
       "         ...,\n",
       "         [-0.5085, -0.4000,  0.2769,  ..., -1.0359,  1.0428, -0.0813],\n",
       "         [ 0.0033,  0.1675,  0.1643,  ..., -0.2823,  0.1061, -0.0853],\n",
       "         [-0.0396, -0.0874, -0.5663,  ...,  0.4393,  0.4108,  0.2631]],\n",
       "\n",
       "        [[ 0.0276,  0.0653,  0.0543,  ...,  0.1483, -0.0048, -0.0313],\n",
       "         [ 0.1110, -0.2660,  0.0032,  ...,  0.2543,  0.1759,  0.1242],\n",
       "         [ 0.2764, -1.1983, -0.3717,  ..., -0.1786, -0.6483, -0.1365],\n",
       "         ...,\n",
       "         [-0.3731, -0.5151,  0.1422,  ..., -0.5719,  0.7325,  0.0800],\n",
       "         [-0.1321,  0.9328,  0.4495,  ..., -1.4071,  0.5834,  0.0549],\n",
       "         [-0.0225, -0.3806, -0.3346,  ...,  0.4548,  0.2293,  0.4567]],\n",
       "\n",
       "        [[-0.0224,  0.0434,  0.0910,  ...,  0.1150, -0.0337, -0.0088],\n",
       "         [-0.1045, -0.3654,  0.1898,  ...,  0.0264,  0.0977,  0.1417],\n",
       "         [ 0.2514, -1.4829,  0.0241,  ..., -0.1916, -0.6476,  0.0626],\n",
       "         ...,\n",
       "         [ 0.4708, -0.5085, -0.4762,  ..., -0.8562, -0.2719, -0.0076],\n",
       "         [ 0.1147, -0.6638, -0.2340,  ..., -0.2820,  0.2226, -0.2221],\n",
       "         [-0.0389, -0.0897, -0.0696,  ...,  0.1411,  0.0122,  0.3858]],\n",
       "\n",
       "        [[-0.0222,  0.0367,  0.1165,  ...,  0.1466,  0.0035, -0.0334],\n",
       "         [-0.1993, -0.3434,  0.0710,  ...,  0.0432, -0.1260, -0.1232],\n",
       "         [ 0.0278, -1.2574, -0.1178,  ..., -0.2000, -0.7025, -0.2102],\n",
       "         ...,\n",
       "         [ 0.1960, -0.2354,  0.3045,  ..., -0.3612, -0.2847,  0.6145],\n",
       "         [-0.0591, -1.1552,  0.1155,  ...,  0.4554, -0.0333,  0.6168],\n",
       "         [ 0.0111,  0.1789,  0.1200,  ...,  0.2875,  0.1656,  0.6577]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0514,  0.1225, -0.0349,  ...,  0.2321, -0.0349, -0.1094],\n",
       "         [ 0.1147, -0.2064, -0.1617,  ...,  0.2216, -0.0856,  0.1231],\n",
       "         [ 0.0680, -1.3419, -0.5367,  ..., -0.1168, -0.0169,  0.1782],\n",
       "         ...,\n",
       "         [-0.2956, -0.2580,  0.4027,  ..., -0.9304,  0.7551,  0.2485],\n",
       "         [ 0.0241,  0.2382,  0.1116,  ..., -0.2682,  0.0025, -0.2002],\n",
       "         [ 0.1209, -0.0625, -0.2627,  ...,  0.7223,  0.2062, -0.1883]],\n",
       "\n",
       "        [[ 0.0635,  0.1319, -0.0234,  ...,  0.1850, -0.0252, -0.1191],\n",
       "         [-0.2359, -0.0942, -0.3038,  ...,  0.2555, -0.0200,  0.0975],\n",
       "         [-0.2010, -1.2541, -0.3632,  ..., -0.2060, -0.3439, -0.0458],\n",
       "         ...,\n",
       "         [-0.1513, -0.3835,  0.1335,  ..., -0.6243,  0.9652, -0.3221],\n",
       "         [ 0.0599,  1.0650,  0.4061,  ..., -1.5190,  0.6497, -0.3326],\n",
       "         [ 0.3240, -0.6886, -0.1265,  ...,  0.6276,  0.1216, -0.3012]],\n",
       "\n",
       "        [[ 0.0508,  0.0997, -0.0409,  ...,  0.1753, -0.0587, -0.1151],\n",
       "         [ 0.1388, -0.2497, -0.1360,  ...,  0.0945, -0.0152,  0.0344],\n",
       "         [ 0.0998, -1.4654, -0.4708,  ..., -0.1336, -0.0663,  0.1832],\n",
       "         ...,\n",
       "         [ 0.3990,  0.1435, -0.2294,  ..., -0.8814, -0.3694, -0.1292],\n",
       "         [ 0.1659, -0.3556,  0.2072,  ..., -0.2971,  0.3618, -0.1768],\n",
       "         [ 0.3205, -0.0487,  0.0377,  ...,  0.4105, -0.0455, -0.2583]],\n",
       "\n",
       "        [[ 0.0502,  0.1402, -0.0613,  ...,  0.1875, -0.0346, -0.1181],\n",
       "         [ 0.0027, -0.2868, -0.3199,  ...,  0.1365, -0.1234, -0.0874],\n",
       "         [ 0.0258, -1.1858, -0.3707,  ..., -0.0979,  0.0579, -0.0412],\n",
       "         ...,\n",
       "         [ 0.1778, -0.1524,  0.2099,  ..., -0.5065, -0.2914,  0.6011],\n",
       "         [-0.1576, -1.2964, -0.0432,  ...,  0.4724, -0.1035,  0.5096],\n",
       "         [ 0.0570,  0.0373,  0.0174,  ...,  0.2630, -0.0788,  0.3017]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 2.7711e-02,  1.1851e-01, -9.6621e-02,  ...,  1.4659e-01,\n",
       "          -7.5337e-02, -7.2576e-02],\n",
       "         [-1.7578e-01, -1.1288e-01, -3.3357e-01,  ..., -5.5192e-02,\n",
       "           6.7158e-01, -6.2735e-01],\n",
       "         [-6.3238e-02, -1.2565e+00, -4.7800e-01,  ..., -3.8874e-01,\n",
       "           2.5320e-01, -6.9055e-01],\n",
       "         ...,\n",
       "         [-2.4026e-01, -4.2114e-01,  3.7445e-01,  ..., -8.7939e-01,\n",
       "           5.3844e-01,  7.2930e-01],\n",
       "         [-7.2683e-02, -4.3411e-03, -5.9003e-02,  ..., -1.7956e-01,\n",
       "          -2.8852e-01, -2.1365e-01],\n",
       "         [ 2.5753e-01, -1.8246e-01, -4.7700e-01,  ...,  6.9519e-01,\n",
       "          -2.4540e-01, -4.4015e-01]],\n",
       "\n",
       "        [[ 3.3766e-02,  1.4279e-01, -6.3092e-02,  ...,  1.0575e-01,\n",
       "          -8.0475e-02, -3.4581e-02],\n",
       "         [-3.2446e-01,  1.2723e-01, -3.2198e-01,  ..., -1.0616e-03,\n",
       "           6.0817e-01, -4.3402e-01],\n",
       "         [-2.8331e-01, -1.2794e+00, -5.8368e-02,  ..., -5.7538e-01,\n",
       "          -1.8031e-01, -6.3433e-01],\n",
       "         ...,\n",
       "         [ 1.3108e-01, -3.0131e-01, -3.1595e-01,  ..., -6.1314e-01,\n",
       "           4.4042e-01,  1.6509e-01],\n",
       "         [ 1.1424e-01,  1.3027e+00,  9.1315e-02,  ..., -1.5085e+00,\n",
       "           1.6944e-01,  2.7723e-01],\n",
       "         [ 4.6500e-01, -8.0180e-01, -2.8657e-01,  ...,  3.3694e-01,\n",
       "           6.6460e-02, -1.3251e-01]],\n",
       "\n",
       "        [[ 4.5126e-02,  1.4415e-01, -9.1725e-02,  ...,  1.0572e-01,\n",
       "          -1.1243e-01, -4.1642e-02],\n",
       "         [-2.1380e-01, -4.3938e-02, -1.5347e-01,  ..., -1.5556e-01,\n",
       "           7.8585e-01, -6.1109e-01],\n",
       "         [-1.5408e-01, -1.3123e+00, -3.2369e-01,  ..., -4.2173e-01,\n",
       "           3.3721e-01, -6.4370e-01],\n",
       "         ...,\n",
       "         [ 1.5776e-01,  1.6728e-02, -1.3488e-01,  ..., -9.2675e-01,\n",
       "          -7.8885e-01, -1.0618e-01],\n",
       "         [ 7.6643e-02, -4.1240e-01,  7.6976e-02,  ..., -9.9803e-02,\n",
       "           3.0009e-01, -4.9585e-02],\n",
       "         [ 1.6374e-01, -3.2935e-01, -7.0282e-02,  ...,  3.6693e-01,\n",
       "          -4.6365e-01, -2.7305e-01]],\n",
       "\n",
       "        [[-1.1457e-03,  1.8138e-01, -1.0182e-01,  ...,  1.4858e-01,\n",
       "          -1.1359e-01, -4.6936e-02],\n",
       "         [-2.0226e-01,  1.1123e-01, -2.8868e-01,  ..., -1.4840e-01,\n",
       "           4.2741e-01, -6.3351e-01],\n",
       "         [-1.2182e-01, -9.3126e-01, -3.5410e-01,  ..., -2.8918e-01,\n",
       "           2.0973e-01, -7.7657e-01],\n",
       "         ...,\n",
       "         [-5.3148e-01, -3.4020e-01,  3.6361e-01,  ..., -4.3433e-01,\n",
       "          -3.8505e-01, -5.9253e-02],\n",
       "         [ 9.9729e-02, -1.1798e+00,  3.8833e-01,  ...,  4.3279e-01,\n",
       "           1.2887e-01, -3.0984e-01],\n",
       "         [-3.0289e-01,  3.2177e-01,  3.0252e-01,  ...,  4.0071e-01,\n",
       "          -5.0271e-01,  7.5544e-02]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0647,  0.0759, -0.0454,  ...,  0.0146, -0.0546,  0.0070],\n",
       "         [-0.3364, -0.3982, -0.6897,  ..., -0.1434,  0.2300, -0.2547],\n",
       "         [ 0.0922, -1.6277, -0.4397,  ..., -0.1950,  0.4593, -0.4882],\n",
       "         ...,\n",
       "         [ 0.0813, -0.0869,  0.0343,  ..., -0.8095,  0.5763,  0.1053],\n",
       "         [ 0.2062, -0.0103, -0.0095,  ..., -0.2832, -0.1841, -0.4108],\n",
       "         [ 0.0213, -0.2665, -0.5423,  ...,  0.5337, -0.0378, -0.5004]],\n",
       "\n",
       "        [[ 0.0634,  0.0949, -0.0464,  ..., -0.0152, -0.0508,  0.0206],\n",
       "         [-0.5398, -0.2575, -0.5109,  ..., -0.3466,  0.1666,  0.2668],\n",
       "         [-0.4157, -1.4574, -0.1229,  ..., -0.5828,  0.2659, -0.3229],\n",
       "         ...,\n",
       "         [ 0.1635, -0.3777,  0.0682,  ..., -0.2873, -0.0391,  0.3168],\n",
       "         [ 0.0228,  1.2348,  0.1604,  ..., -1.4032,  0.0148,  0.4177],\n",
       "         [ 0.4059, -1.0679, -0.4933,  ...,  0.2971,  0.2926,  0.0833]],\n",
       "\n",
       "        [[ 0.0669,  0.0877, -0.0512,  ..., -0.0193, -0.0679,  0.0206],\n",
       "         [-0.2660, -0.3676, -0.5745,  ..., -0.2637,  0.4015, -0.4354],\n",
       "         [ 0.0281, -1.7654, -0.3581,  ..., -0.2087,  0.5721, -0.5476],\n",
       "         ...,\n",
       "         [ 0.2021, -0.6550, -0.1697,  ..., -1.2497, -0.8847,  0.1857],\n",
       "         [-0.3221, -0.6113, -0.1575,  ..., -0.0291,  0.1627,  0.2870],\n",
       "         [ 0.0370, -0.7078, -0.3673,  ...,  0.1058, -0.4366, -0.0538]],\n",
       "\n",
       "        [[ 0.0547,  0.0964, -0.0485,  ...,  0.0029, -0.0596,  0.0163],\n",
       "         [-0.2563, -0.2663, -0.5076,  ..., -0.3003,  0.0765, -0.1758],\n",
       "         [ 0.2151, -1.3490, -0.3337,  ..., -0.0979,  0.4006, -0.5563],\n",
       "         ...,\n",
       "         [ 0.2058,  0.1525,  0.4501,  ..., -0.4713, -0.3474,  0.3080],\n",
       "         [-0.1029, -0.8243,  0.1095,  ...,  0.8758,  0.1902,  0.0863],\n",
       "         [-0.3312,  0.7238,  0.2136,  ...,  0.3474, -0.1856,  0.2049]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0426,  0.0626, -0.0174,  ...,  0.0147,  0.0520, -0.0314],\n",
       "         [-0.3689, -0.1628, -0.3042,  ...,  0.0217,  0.1740, -0.0934],\n",
       "         [-0.2512, -1.4258,  0.0379,  ..., -0.1669,  0.1952, -0.4168],\n",
       "         ...,\n",
       "         [ 0.0205, -0.6174,  0.3144,  ..., -0.6068,  0.1860, -0.3614],\n",
       "         [ 0.5187,  0.3133,  0.1564,  ..., -0.1830, -0.4204, -0.3608],\n",
       "         [ 0.1675, -0.2671, -0.4066,  ...,  0.4469, -0.1692, -0.5713]],\n",
       "\n",
       "        [[-0.0511,  0.0656, -0.0272,  ...,  0.0080,  0.0492, -0.0211],\n",
       "         [-0.2963, -0.1148,  0.0440,  ..., -0.1915, -0.1594,  0.5469],\n",
       "         [ 0.0459, -1.3906,  0.5069,  ..., -0.7323, -0.1206, -0.0166],\n",
       "         ...,\n",
       "         [ 0.4715, -0.3020, -0.2424,  ...,  0.0441,  0.0118, -0.0903],\n",
       "         [ 0.1709,  1.3882,  0.0460,  ..., -0.8973, -0.0037, -0.2049],\n",
       "         [ 0.5987, -0.7518, -0.9920,  ...,  0.3204,  0.3774, -0.0253]],\n",
       "\n",
       "        [[-0.0488,  0.0603, -0.0174,  ...,  0.0122,  0.0429, -0.0265],\n",
       "         [-0.2782, -0.0957, -0.1824,  ..., -0.0609,  0.2320, -0.3877],\n",
       "         [-0.2139, -1.5552,  0.1210,  ..., -0.1782,  0.3288, -0.4552],\n",
       "         ...,\n",
       "         [ 0.2906, -0.6379,  0.0562,  ..., -0.6743, -0.0468, -0.1537],\n",
       "         [-0.0913, -0.3105, -0.0093,  ...,  0.3927,  0.1568,  0.4266],\n",
       "         [-0.3512, -0.7160, -0.7775,  ...,  0.4216, -0.9069, -0.0188]],\n",
       "\n",
       "        [[-0.0522,  0.0695, -0.0083,  ...,  0.0123,  0.0520, -0.0254],\n",
       "         [-0.3428, -0.0805, -0.1638,  ..., -0.1979,  0.0027, -0.0665],\n",
       "         [-0.2386, -1.1736,  0.1235,  ..., -0.0292,  0.2062, -0.4437],\n",
       "         ...,\n",
       "         [ 0.3534,  0.2783,  0.8204,  ..., -0.1600, -0.3415, -0.2823],\n",
       "         [-0.3308, -0.3011,  0.0834,  ...,  1.0433, -0.0583, -0.0662],\n",
       "         [-0.7555,  1.0935,  0.3559,  ...,  0.0046,  0.2143,  0.4428]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0771,  0.0379, -0.0107,  ...,  0.0332,  0.0304, -0.0193],\n",
       "         [-0.8354, -0.5119, -0.2967,  ..., -0.0916, -0.0167, -0.1291],\n",
       "         [-0.4441, -1.8254, -0.2948,  ..., -0.4701, -0.3683, -0.4526],\n",
       "         ...,\n",
       "         [ 0.0542, -1.0010, -0.0441,  ..., -0.4713,  0.1595, -0.6324],\n",
       "         [ 0.1131, -0.2556,  0.3320,  ..., -0.1715,  0.1622,  0.0176],\n",
       "         [ 0.0042, -0.3354, -0.3527,  ...,  0.3052, -0.3082, -0.2358]],\n",
       "\n",
       "        [[-0.0738,  0.0352, -0.0064,  ...,  0.0278,  0.0319, -0.0143],\n",
       "         [-0.4199, -0.4042, -0.0946,  ..., -0.2190,  0.1268,  0.3524],\n",
       "         [ 0.2087, -1.6931, -0.2835,  ..., -0.9743, -0.2728, -0.1780],\n",
       "         ...,\n",
       "         [ 0.0375, -0.3544, -0.7173,  ..., -0.1579,  0.2057, -0.6893],\n",
       "         [-0.0697,  1.2451, -0.3373,  ..., -0.6530,  0.1015, -0.3595],\n",
       "         [ 0.1543, -0.5606, -1.0635,  ...,  0.0328,  0.4226,  0.0625]],\n",
       "\n",
       "        [[-0.0782,  0.0372, -0.0082,  ...,  0.0302,  0.0260, -0.0163],\n",
       "         [-0.7938, -0.4743, -0.1566,  ..., -0.1538,  0.0395, -0.2696],\n",
       "         [-0.4834, -2.0565, -0.2910,  ..., -0.4364, -0.2574, -0.4668],\n",
       "         ...,\n",
       "         [ 0.0671, -0.5483,  0.0658,  ..., -0.6803, -0.2176, -0.1500],\n",
       "         [-0.0600, -0.0598, -0.3077,  ...,  0.4762, -0.0827,  0.2414],\n",
       "         [-0.7308, -0.4766, -0.6026,  ...,  0.7126, -1.2103,  0.2582]],\n",
       "\n",
       "        [[-0.0708,  0.0367, -0.0051,  ...,  0.0306,  0.0333, -0.0199],\n",
       "         [-0.8527, -0.3364, -0.1568,  ..., -0.3808, -0.0930, -0.3178],\n",
       "         [-0.4797, -1.6222, -0.1491,  ..., -0.4158, -0.3718, -0.3962],\n",
       "         ...,\n",
       "         [ 0.2553, -0.0056,  0.5515,  ...,  0.0415,  0.0741, -0.5109],\n",
       "         [-0.7334, -0.1671, -0.1063,  ...,  0.8154, -0.0772, -0.2188],\n",
       "         [-0.9362,  0.7737,  0.0102,  ...,  0.1815, -0.2927,  0.3807]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0297,  0.0865, -0.0221,  ...,  0.0203, -0.0046, -0.0528],\n",
       "         [-0.2270, -0.7160, -0.3083,  ...,  0.2820,  0.5089, -0.5677],\n",
       "         [ 0.3045, -1.9404, -0.3053,  ..., -0.6044,  0.0992, -0.4363],\n",
       "         ...,\n",
       "         [ 0.0598, -0.8599, -0.2959,  ..., -0.2344,  0.6200, -0.8348],\n",
       "         [ 0.0482, -0.4597, -0.0675,  ..., -0.2040,  0.5216, -0.6102],\n",
       "         [-0.0999, -0.6548, -0.5798,  ...,  0.1777, -0.0241, -0.2065]],\n",
       "\n",
       "        [[-0.0213,  0.0849, -0.0213,  ...,  0.0173, -0.0043, -0.0465],\n",
       "         [ 0.3380, -0.2967, -0.2541,  ..., -0.1234,  0.4986, -0.0036],\n",
       "         [ 0.6479, -1.3474, -0.4731,  ..., -1.2241,  0.0378, -0.0611],\n",
       "         ...,\n",
       "         [ 0.2140, -0.3553, -1.0793,  ..., -0.0988,  0.1064, -0.5203],\n",
       "         [ 0.2492,  0.9325, -0.4179,  ..., -0.6718, -0.0477, -0.2662],\n",
       "         [ 0.3539, -0.4459, -0.9070,  ..., -0.0293,  0.5522, -0.2255]],\n",
       "\n",
       "        [[-0.0209,  0.0825, -0.0187,  ...,  0.0199,  0.0049, -0.0447],\n",
       "         [-0.2413, -0.7495, -0.2458,  ...,  0.2652,  0.3072, -0.5974],\n",
       "         [ 0.1699, -2.0157, -0.3021,  ..., -0.6116,  0.1043, -0.4098],\n",
       "         ...,\n",
       "         [ 0.0041, -0.4436,  0.2574,  ..., -0.6699, -0.0575, -0.0360],\n",
       "         [-0.0505, -0.3031,  0.2033,  ...,  0.4642,  0.2194,  0.2242],\n",
       "         [-0.3499, -0.5801, -0.4305,  ...,  0.8415, -1.0074,  0.3255]],\n",
       "\n",
       "        [[-0.0294,  0.0999, -0.0293,  ...,  0.0055,  0.0022, -0.0522],\n",
       "         [-0.1693, -0.5224, -0.1109,  ..., -0.0097,  0.4828, -0.6007],\n",
       "         [ 0.2409, -1.6847, -0.0440,  ..., -0.5744,  0.1736, -0.3553],\n",
       "         ...,\n",
       "         [ 0.2018, -0.1209,  0.6885,  ...,  0.2955,  0.6510, -0.1977],\n",
       "         [-0.3977, -0.1054,  0.1152,  ...,  0.7319,  0.0432, -0.0974],\n",
       "         [-0.8482,  0.3607,  0.5868,  ...,  0.7320, -0.0631,  0.5998]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.3717, -0.7092, -0.2582,  ...,  0.3469,  0.3358, -0.4262],\n",
       "         [-0.1172, -0.4977, -0.3255,  ...,  0.7220,  0.0540, -0.7019],\n",
       "         [ 0.0620, -1.4104, -0.2751,  ..., -0.8366, -0.0621, -0.5348],\n",
       "         ...,\n",
       "         [-0.4283, -0.6859, -0.1539,  ...,  0.0352, -0.0454, -1.4535],\n",
       "         [-0.0473, -0.3818, -0.4050,  ...,  0.3636,  0.0185, -1.1717],\n",
       "         [ 0.1628, -0.2731, -0.4481,  ..., -0.1551, -0.0023, -0.2328]],\n",
       "\n",
       "        [[-0.5919, -0.8480, -0.5311,  ...,  0.4817, -0.0684, -0.5817],\n",
       "         [ 0.0735, -0.2169, -0.3575,  ...,  0.4432,  0.3001, -0.2124],\n",
       "         [ 0.1027, -0.8445, -0.5376,  ..., -1.4637,  0.0094,  0.2103],\n",
       "         ...,\n",
       "         [ 1.0615, -0.2603, -1.2151,  ...,  0.4057, -0.0658,  0.4686],\n",
       "         [ 0.5192, -0.0962, -0.4071,  ...,  0.0023, -0.0727, -0.3963],\n",
       "         [ 0.0883, -0.1224, -0.3437,  ..., -0.0188,  0.3819, -0.0345]],\n",
       "\n",
       "        [[-0.4914, -0.6923, -0.2729,  ..., -0.0216,  0.4140, -0.6273],\n",
       "         [-0.2116, -0.5216, -0.4079,  ...,  0.5020,  0.3882, -0.6379],\n",
       "         [-0.2550, -1.7517, -0.1500,  ..., -1.2746,  0.2730, -0.1412],\n",
       "         ...,\n",
       "         [-0.2816, -0.1639, -0.5150,  ..., -0.5874,  0.2325,  0.0595],\n",
       "         [-0.1862, -0.2221,  0.0933,  ...,  0.0997,  0.3096,  0.1371],\n",
       "         [-0.4301, -0.2910, -0.5221,  ...,  0.3292, -0.4089,  0.5274]],\n",
       "\n",
       "        [[-0.1565, -0.0579, -0.2130,  ..., -0.0510,  0.2079, -0.0839],\n",
       "         [-0.5007, -0.3150, -0.4684,  ...,  0.3854,  0.4796, -0.6907],\n",
       "         [-0.4125, -1.0686, -0.1748,  ..., -0.9834,  0.3777, -0.1478],\n",
       "         ...,\n",
       "         [-0.6264, -0.1029,  0.4156,  ...,  0.8325,  0.4049,  0.0661],\n",
       "         [-0.5132,  0.1978, -0.1088,  ...,  0.7921,  0.2797,  0.7323],\n",
       "         [-0.4712,  0.2871,  0.0752,  ...,  0.1572,  0.2276,  0.5396]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)), attentions=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.lr_scheduler.LambdaLR at 0x7ff934fa4f40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "# # Instantiate scheduler\n",
    "# lr_scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer=optimizer,\n",
    "#     num_warmup_steps=0.06 * (len(train_dataloader) * num_epochs),\n",
    "#     num_training_steps=(len(train_dataloader) * num_epochs),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"f1\", module_type: \"metric\", features: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)}, usage: \"\"\"\n",
       "Args:\n",
       "    predictions (`list` of `int`): Predicted labels.\n",
       "    references (`list` of `int`): Ground truth labels.\n",
       "    labels (`list` of `int`): The set of labels to include when `average` is not set to `'binary'`, and the order of the labels if `average` is `None`. Labels present in the data can be excluded, for example to calculate a multiclass average ignoring a majority negative class. Labels not present in the data will result in 0 components in a macro average. For multilabel targets, labels are column indices. By default, all labels in `predictions` and `references` are used in sorted order. Defaults to None.\n",
       "    pos_label (`int`): The class to be considered the positive class, in the case where `average` is set to `binary`. Defaults to 1.\n",
       "    average (`string`): This parameter is required for multiclass/multilabel targets. If set to `None`, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data. Defaults to `'binary'`.\n",
       "\n",
       "        - 'binary': Only report results for the class specified by `pos_label`. This is applicable only if the classes found in `predictions` and `references` are binary.\n",
       "        - 'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
       "        - 'macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
       "        - 'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters `'macro'` to account for label imbalance. This option can result in an F-score that is not between precision and recall.\n",
       "        - 'samples': Calculate metrics for each instance, and find their average (only meaningful for multilabel classification).\n",
       "    sample_weight (`list` of `float`): Sample weights Defaults to None.\n",
       "\n",
       "Returns:\n",
       "    f1 (`float` or `array` of `float`): F1 score or list of f1 scores, depending on the value passed to `average`. Minimum possible value is 0. Maximum possible value is 1. Higher f1 scores are better.\n",
       "\n",
       "Examples:\n",
       "\n",
       "    Example 1-A simple binary example\n",
       "        >>> f1_metric = evaluate.load(\"f1\")\n",
       "        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0])\n",
       "        >>> print(results)\n",
       "        {'f1': 0.5}\n",
       "\n",
       "    Example 2-The same simple binary example as in Example 1, but with `pos_label` set to `0`.\n",
       "        >>> f1_metric = evaluate.load(\"f1\")\n",
       "        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], pos_label=0)\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.67\n",
       "\n",
       "    Example 3-The same simple binary example as in Example 1, but with `sample_weight` included.\n",
       "        >>> f1_metric = evaluate.load(\"f1\")\n",
       "        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], sample_weight=[0.9, 0.5, 3.9, 1.2, 0.3])\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.35\n",
       "\n",
       "    Example 4-A multiclass example, with different values for the `average` input.\n",
       "        >>> predictions = [0, 2, 1, 0, 0, 1]\n",
       "        >>> references = [0, 1, 2, 0, 1, 2]\n",
       "        >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"macro\")\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.27\n",
       "        >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"micro\")\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.33\n",
       "        >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"weighted\")\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.27\n",
       "        >>> results = f1_metric.compute(predictions=predictions, references=references, average=None)\n",
       "        >>> print(results)\n",
       "        {'f1': array([0.8, 0. , 0. ])}\n",
       "\n",
       "    Example 5-A multi-label example\n",
       "        >>> f1_metric = evaluate.load(\"f1\", \"multilabel\")\n",
       "        >>> results = f1_metric.compute(predictions=[[0, 1, 1], [1, 1, 0]], references=[[0, 1, 1], [0, 1, 0]], average=\"macro\")\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.67\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/224 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [02:54<00:00,  1.28it/s]\n",
      "100%|██████████| 1557/1557 [08:14<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'f1': 0.09580728769629517}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [03:03<00:00,  1.22it/s]\n",
      " 13%|█▎        | 205/1557 [01:08<07:33,  2.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 208/1557 [01:09<07:41,  2.92it/s]"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch.to(device)\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        predictions, references = predictions, batch[\"labels\"]\n",
    "        metric.add_batch(\n",
    "            predictions=predictions,\n",
    "            references=references,\n",
    "        )\n",
    "\n",
    "    eval_metric = metric.compute(average = \"macro\")\n",
    "    print(f\"epoch {epoch}:\", eval_metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./peft_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reload saved peft weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peft_model_dir = \"/mnt/sdc/niallt/saved_models/peft_training/ckpts/icd9-triage-no-category-in-text/fewshot_64/mimic-roberta-base/declutr/2_anch_2_pos_min_1024/LORA/23-06-2023--11-41/\"\n",
    "peft_model_dir = \"/mnt/sdd/efficient_ml_data/saved_models/peft/ckpts/ICD9-Triage/full/roberta-base/LORA/30-08-2023--15-58/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/sdd/efficient_ml_data/saved_models/peft/ckpts/ICD9-Triage/full/roberta-base/LORA/30-08-2023--15-58//adapter_model.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m adapter_bin \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpeft_model_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/adapter_model.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/sdd/efficient_ml_data/saved_models/peft/ckpts/ICD9-Triage/full/roberta-base/LORA/30-08-2023--15-58//adapter_model.bin'"
     ]
    }
   ],
   "source": [
    "adapter_bin = torch.load(f\"{peft_model_dir}/adapter_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_model.model.bert.encoder.layer.0.attention.self.query.lora_A.weight': tensor([[-0.0171,  0.0368, -0.0372,  ..., -0.0156,  0.0369,  0.0535],\n",
       "         [-0.0262,  0.0111, -0.0117,  ..., -0.0040, -0.0437,  0.0237],\n",
       "         [-0.0066,  0.0427, -0.0378,  ...,  0.0340, -0.0255,  0.0529],\n",
       "         ...,\n",
       "         [ 0.0131, -0.0496, -0.0212,  ...,  0.0491,  0.0521, -0.0051],\n",
       "         [-0.0099,  0.0169,  0.0190,  ..., -0.0289,  0.0178,  0.0147],\n",
       "         [ 0.0184, -0.0021,  0.0051,  ...,  0.0164, -0.0060, -0.0724]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.0.attention.self.query.lora_B.weight': tensor([[-0.0051, -0.0075,  0.0026,  ..., -0.0222, -0.0095, -0.0070],\n",
       "         [ 0.0025, -0.0080,  0.0042,  ...,  0.0061,  0.0087, -0.0097],\n",
       "         [-0.0120, -0.0257,  0.0023,  ...,  0.0039,  0.0017, -0.0115],\n",
       "         ...,\n",
       "         [-0.0007,  0.0175,  0.0042,  ..., -0.0065,  0.0036, -0.0025],\n",
       "         [-0.0158,  0.0124, -0.0370,  ..., -0.0119, -0.0216,  0.0210],\n",
       "         [-0.0283, -0.0057,  0.0069,  ...,  0.0304, -0.0148,  0.0111]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.0.attention.self.value.lora_A.weight': tensor([[ 0.0191,  0.0393, -0.0517,  ..., -0.0228,  0.0138,  0.0245],\n",
       "         [ 0.0032,  0.0160, -0.0203,  ...,  0.0038,  0.0403,  0.0655],\n",
       "         [ 0.0088, -0.0100, -0.0337,  ...,  0.0073,  0.0263,  0.0312],\n",
       "         ...,\n",
       "         [-0.0226,  0.0429, -0.0277,  ...,  0.0174,  0.0296,  0.0580],\n",
       "         [ 0.0406, -0.0283,  0.0086,  ..., -0.0181, -0.0188, -0.0202],\n",
       "         [-0.0134,  0.0141, -0.0306,  ...,  0.0219,  0.0189,  0.0254]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.0.attention.self.value.lora_B.weight': tensor([[-0.0021, -0.0050, -0.0113,  ..., -0.0029,  0.0105, -0.0062],\n",
       "         [ 0.0187,  0.0162,  0.0199,  ...,  0.0121, -0.0193,  0.0185],\n",
       "         [-0.0094, -0.0124, -0.0068,  ..., -0.0137,  0.0074, -0.0088],\n",
       "         ...,\n",
       "         [-0.0035, -0.0082,  0.0007,  ..., -0.0020,  0.0022, -0.0030],\n",
       "         [ 0.0096,  0.0132,  0.0003,  ...,  0.0098,  0.0014, -0.0008],\n",
       "         [-0.0101, -0.0100, -0.0110,  ..., -0.0097,  0.0092, -0.0152]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.1.attention.self.query.lora_A.weight': tensor([[-0.0238,  0.0128, -0.0109,  ...,  0.0223, -0.0074, -0.0221],\n",
       "         [ 0.0445, -0.0277, -0.0020,  ..., -0.0407,  0.0474,  0.0544],\n",
       "         [ 0.0154,  0.0160, -0.0103,  ..., -0.0087,  0.0112,  0.0406],\n",
       "         ...,\n",
       "         [-0.0289,  0.0112,  0.0104,  ...,  0.0103,  0.0118, -0.0042],\n",
       "         [-0.0573, -0.0213, -0.0384,  ..., -0.0013,  0.0446,  0.0317],\n",
       "         [ 0.0395, -0.0001,  0.0013,  ...,  0.0311, -0.0188,  0.0381]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.1.attention.self.query.lora_B.weight': tensor([[-0.0138, -0.0401, -0.0010,  ..., -0.0153, -0.0355,  0.0111],\n",
       "         [ 0.0134,  0.0182, -0.0040,  ...,  0.0215,  0.0098, -0.0161],\n",
       "         [ 0.0114,  0.0133, -0.0009,  ...,  0.0130,  0.0252, -0.0036],\n",
       "         ...,\n",
       "         [ 0.0013,  0.0033,  0.0067,  ...,  0.0032,  0.0002,  0.0025],\n",
       "         [-0.0009, -0.0059, -0.0047,  ..., -0.0046, -0.0045,  0.0106],\n",
       "         [ 0.0063,  0.0089,  0.0097,  ...,  0.0079,  0.0069, -0.0057]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.1.attention.self.value.lora_A.weight': tensor([[-0.0025, -0.0015,  0.0130,  ...,  0.0415,  0.0018, -0.0208],\n",
       "         [ 0.0028,  0.0277, -0.0220,  ...,  0.0455, -0.0539,  0.0043],\n",
       "         [-0.0368,  0.0175, -0.0253,  ..., -0.0285,  0.0031, -0.0063],\n",
       "         ...,\n",
       "         [-0.0336,  0.0274,  0.0106,  ..., -0.0290,  0.0302,  0.0239],\n",
       "         [ 0.0107,  0.0056,  0.0344,  ..., -0.0032, -0.0247, -0.0223],\n",
       "         [-0.0189, -0.0196, -0.0107,  ...,  0.0252,  0.0275,  0.0101]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.1.attention.self.value.lora_B.weight': tensor([[ 0.0055, -0.0088, -0.0035,  ...,  0.0045,  0.0073,  0.0001],\n",
       "         [-0.0162, -0.0114,  0.0204,  ...,  0.0168, -0.0182,  0.0075],\n",
       "         [-0.0066, -0.0120,  0.0082,  ...,  0.0103, -0.0056,  0.0048],\n",
       "         ...,\n",
       "         [-0.0111, -0.0159,  0.0135,  ...,  0.0039, -0.0035,  0.0100],\n",
       "         [ 0.0102,  0.0269, -0.0019,  ..., -0.0198,  0.0103,  0.0118],\n",
       "         [-0.0056, -0.0060,  0.0026,  ...,  0.0122, -0.0097,  0.0015]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.2.attention.self.query.lora_A.weight': tensor([[ 0.0088, -0.0130,  0.0435,  ..., -0.0335,  0.0009,  0.0219],\n",
       "         [ 0.0134, -0.0360,  0.0102,  ..., -0.0025,  0.0167,  0.0308],\n",
       "         [ 0.0608,  0.0116,  0.0306,  ...,  0.0391,  0.0570,  0.0306],\n",
       "         ...,\n",
       "         [-0.0381,  0.0377, -0.0074,  ...,  0.0185,  0.0266, -0.0218],\n",
       "         [ 0.0100,  0.0347,  0.0013,  ..., -0.0107, -0.0234, -0.0054],\n",
       "         [-0.0286,  0.0193, -0.0308,  ...,  0.0291, -0.0253, -0.0034]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.2.attention.self.query.lora_B.weight': tensor([[-0.0151,  0.0031, -0.0143,  ..., -0.0055, -0.0022,  0.0261],\n",
       "         [ 0.0127, -0.0111,  0.0014,  ...,  0.0191,  0.0220,  0.0188],\n",
       "         [-0.0475,  0.0361, -0.0262,  ..., -0.0150, -0.0268, -0.0054],\n",
       "         ...,\n",
       "         [-0.0113,  0.0019, -0.0189,  ..., -0.0335, -0.0361, -0.0112],\n",
       "         [-0.0112,  0.0120,  0.0068,  ..., -0.0184,  0.0008, -0.0021],\n",
       "         [ 0.0053, -0.0162, -0.0102,  ...,  0.0182, -0.0130, -0.0116]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.2.attention.self.value.lora_A.weight': tensor([[-0.0282, -0.0105, -0.0077,  ...,  0.0076,  0.0265, -0.0023],\n",
       "         [-0.0255, -0.0219, -0.0134,  ..., -0.0348,  0.0178, -0.0058],\n",
       "         [ 0.0088, -0.0117,  0.0151,  ...,  0.0383, -0.0466,  0.0025],\n",
       "         ...,\n",
       "         [-0.0194, -0.0313,  0.0039,  ..., -0.0044, -0.0182,  0.0215],\n",
       "         [-0.0109, -0.0219, -0.0391,  ..., -0.0239,  0.0291, -0.0246],\n",
       "         [-0.0205, -0.0169,  0.0595,  ...,  0.0226, -0.0313,  0.0044]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.2.attention.self.value.lora_B.weight': tensor([[ 0.0078, -0.0082, -0.0033,  ..., -0.0048,  0.0068, -0.0093],\n",
       "         [ 0.0131, -0.0077, -0.0126,  ..., -0.0086,  0.0103, -0.0072],\n",
       "         [-0.0054,  0.0025,  0.0050,  ...,  0.0059, -0.0048,  0.0037],\n",
       "         ...,\n",
       "         [-0.0072,  0.0097,  0.0076,  ...,  0.0070, -0.0103,  0.0091],\n",
       "         [ 0.0026, -0.0019, -0.0015,  ...,  0.0028,  0.0023, -0.0046],\n",
       "         [ 0.0032, -0.0070,  0.0009,  ..., -0.0037,  0.0074, -0.0029]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.3.attention.self.query.lora_A.weight': tensor([[ 0.0280, -0.0453,  0.0168,  ...,  0.0057, -0.0686,  0.0002],\n",
       "         [-0.0130, -0.0386, -0.0140,  ..., -0.0411, -0.0221,  0.0276],\n",
       "         [-0.0185,  0.0573, -0.0103,  ..., -0.0035,  0.0432,  0.0377],\n",
       "         ...,\n",
       "         [ 0.0202,  0.0351, -0.0047,  ...,  0.0408,  0.0665,  0.0027],\n",
       "         [ 0.0264, -0.0217,  0.0211,  ..., -0.0371, -0.0290,  0.0282],\n",
       "         [ 0.0050, -0.0137,  0.0211,  ..., -0.0358, -0.0044,  0.0002]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.3.attention.self.query.lora_B.weight': tensor([[ 0.0274,  0.0272, -0.0235,  ..., -0.0276,  0.0271,  0.0274],\n",
       "         [ 0.0036,  0.0031, -0.0015,  ..., -0.0031,  0.0030,  0.0046],\n",
       "         [ 0.0108,  0.0097, -0.0052,  ..., -0.0097,  0.0096,  0.0099],\n",
       "         ...,\n",
       "         [-0.0006,  0.0019, -0.0040,  ..., -0.0030,  0.0002,  0.0013],\n",
       "         [-0.0112, -0.0108,  0.0083,  ...,  0.0089, -0.0111, -0.0078],\n",
       "         [-0.0117, -0.0118,  0.0097,  ...,  0.0101, -0.0097, -0.0101]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.3.attention.self.value.lora_A.weight': tensor([[-0.0565, -0.0011, -0.0017,  ..., -0.0014,  0.0173,  0.0201],\n",
       "         [ 0.0204, -0.0228, -0.0141,  ...,  0.0219, -0.0042,  0.0131],\n",
       "         [-0.0209, -0.0062, -0.0517,  ...,  0.0033, -0.0108, -0.0383],\n",
       "         ...,\n",
       "         [ 0.0031,  0.0142, -0.0681,  ..., -0.0021,  0.0191, -0.0021],\n",
       "         [-0.0203, -0.0285, -0.0098,  ...,  0.0098, -0.0279, -0.0331],\n",
       "         [-0.0406,  0.0271, -0.0176,  ..., -0.0048,  0.0279, -0.0312]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.3.attention.self.value.lora_B.weight': tensor([[-0.0079, -0.0130, -0.0079,  ..., -0.0128,  0.0085, -0.0084],\n",
       "         [ 0.0039, -0.0031,  0.0106,  ...,  0.0049, -0.0033,  0.0017],\n",
       "         [-0.0083,  0.0050, -0.0104,  ..., -0.0072,  0.0015, -0.0012],\n",
       "         ...,\n",
       "         [-0.0046,  0.0059,  0.0004,  ..., -0.0119, -0.0079,  0.0064],\n",
       "         [-0.0115,  0.0002, -0.0090,  ...,  0.0016,  0.0119, -0.0042],\n",
       "         [ 0.0041,  0.0026, -0.0020,  ...,  0.0090, -0.0010, -0.0014]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.4.attention.self.query.lora_A.weight': tensor([[ 0.0156,  0.0176, -0.0645,  ...,  0.0433,  0.0175,  0.0435],\n",
       "         [ 0.0242,  0.0161, -0.0122,  ..., -0.0081,  0.0002,  0.0438],\n",
       "         [ 0.0055, -0.0078, -0.0632,  ..., -0.0177,  0.0191,  0.0298],\n",
       "         ...,\n",
       "         [-0.0376, -0.0268, -0.0260,  ..., -0.0434, -0.0237,  0.0244],\n",
       "         [ 0.0115,  0.0032,  0.0186,  ..., -0.0294, -0.0076, -0.0261],\n",
       "         [ 0.0172, -0.0238,  0.0016,  ..., -0.0286,  0.0146, -0.0009]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.4.attention.self.query.lora_B.weight': tensor([[ 0.0112,  0.0160, -0.0049,  ..., -0.0128,  0.0021, -0.0101],\n",
       "         [-0.0046,  0.0073,  0.0336,  ...,  0.0115,  0.0129, -0.0050],\n",
       "         [-0.0065, -0.0064,  0.0001,  ...,  0.0056,  0.0052,  0.0029],\n",
       "         ...,\n",
       "         [-0.0055,  0.0021,  0.0083,  ..., -0.0037,  0.0060,  0.0035],\n",
       "         [ 0.0063,  0.0135, -0.0119,  ..., -0.0067, -0.0177, -0.0043],\n",
       "         [ 0.0248, -0.0004, -0.0237,  ..., -0.0153, -0.0288, -0.0278]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.4.attention.self.value.lora_A.weight': tensor([[-3.6837e-03, -1.3533e-02,  1.2163e-02,  ..., -1.3020e-02,\n",
       "           1.3219e-02, -2.3787e-02],\n",
       "         [ 1.4214e-02, -7.8291e-03, -3.7921e-02,  ..., -2.0776e-02,\n",
       "          -2.0186e-02, -3.8673e-02],\n",
       "         [ 2.5159e-02,  3.2977e-02,  9.6277e-05,  ...,  3.2277e-02,\n",
       "          -2.1940e-02,  3.2281e-02],\n",
       "         ...,\n",
       "         [-2.1435e-02,  9.9209e-03, -9.5125e-03,  ...,  1.9789e-02,\n",
       "          -2.9217e-02, -2.4248e-02],\n",
       "         [-5.4182e-02, -1.1547e-02, -3.2381e-02,  ...,  2.9909e-02,\n",
       "          -2.8953e-03, -3.4276e-02],\n",
       "         [-1.1146e-05, -1.4586e-03,  1.6023e-02,  ...,  7.2437e-03,\n",
       "           3.3597e-03,  1.6565e-02]], device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.4.attention.self.value.lora_B.weight': tensor([[-1.8966e-02, -2.4920e-02,  2.3505e-02,  ..., -2.2074e-02,\n",
       "           2.3383e-02, -1.1857e-02],\n",
       "         [ 2.2027e-03,  3.4875e-03, -1.7038e-04,  ...,  7.1081e-03,\n",
       "          -7.0541e-03,  2.1895e-03],\n",
       "         [-8.3157e-03, -4.6295e-03,  2.3222e-03,  ..., -7.4558e-03,\n",
       "           9.0621e-03, -4.6112e-03],\n",
       "         ...,\n",
       "         [-7.5324e-05,  4.6686e-03, -4.8698e-04,  ...,  4.9690e-03,\n",
       "           2.9044e-03,  3.1462e-03],\n",
       "         [ 9.5018e-03,  1.5367e-02, -1.3800e-02,  ...,  1.4124e-02,\n",
       "          -6.9999e-03,  1.3703e-02],\n",
       "         [-3.2101e-03, -5.8666e-03,  4.5929e-03,  ..., -1.6198e-03,\n",
       "           3.7601e-03,  5.9147e-05]], device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.5.attention.self.query.lora_A.weight': tensor([[-0.0087, -0.0522,  0.0125,  ...,  0.0366, -0.0072, -0.0289],\n",
       "         [-0.0266, -0.0080,  0.0571,  ...,  0.0170,  0.0085,  0.0357],\n",
       "         [-0.0028,  0.0045, -0.0114,  ..., -0.0221,  0.0320,  0.0831],\n",
       "         ...,\n",
       "         [ 0.0178,  0.0130, -0.0011,  ...,  0.0418, -0.0093, -0.0250],\n",
       "         [ 0.0346,  0.0199,  0.0020,  ...,  0.0086, -0.0316,  0.0071],\n",
       "         [ 0.0186, -0.0532,  0.0371,  ...,  0.0253, -0.0122, -0.0116]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.5.attention.self.query.lora_B.weight': tensor([[-0.0068, -0.0113,  0.0137,  ..., -0.0194,  0.0104, -0.0063],\n",
       "         [-0.0026, -0.0105,  0.0043,  ...,  0.0011,  0.0008,  0.0005],\n",
       "         [-0.0153, -0.0190,  0.0043,  ..., -0.0009,  0.0073, -0.0015],\n",
       "         ...,\n",
       "         [ 0.0056, -0.0027, -0.0016,  ...,  0.0106, -0.0091,  0.0087],\n",
       "         [-0.0259, -0.0022,  0.0134,  ..., -0.0178,  0.0169, -0.0238],\n",
       "         [-0.0063, -0.0102,  0.0023,  ...,  0.0087, -0.0082,  0.0052]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.5.attention.self.value.lora_A.weight': tensor([[ 0.0132,  0.0268,  0.0212,  ..., -0.0408, -0.0262, -0.0142],\n",
       "         [ 0.0269, -0.0057, -0.0125,  ...,  0.0414, -0.0281,  0.0208],\n",
       "         [ 0.0391,  0.0144, -0.0382,  ...,  0.0384, -0.0265, -0.0332],\n",
       "         ...,\n",
       "         [ 0.0380, -0.0106, -0.0037,  ..., -0.0066, -0.0122, -0.0491],\n",
       "         [-0.0224, -0.0210,  0.0164,  ...,  0.0053, -0.0169,  0.0450],\n",
       "         [-0.0048, -0.0315, -0.0100,  ...,  0.0279, -0.0410, -0.0330]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.5.attention.self.value.lora_B.weight': tensor([[-0.0133, -0.0168, -0.0160,  ..., -0.0111,  0.0151, -0.0091],\n",
       "         [-0.0108,  0.0048,  0.0067,  ..., -0.0101,  0.0007, -0.0156],\n",
       "         [-0.0095, -0.0029,  0.0082,  ..., -0.0036,  0.0050, -0.0002],\n",
       "         ...,\n",
       "         [ 0.0088,  0.0011, -0.0126,  ...,  0.0005,  0.0015,  0.0053],\n",
       "         [ 0.0122, -0.0001, -0.0214,  ...,  0.0085, -0.0022,  0.0104],\n",
       "         [-0.0044, -0.0051, -0.0011,  ..., -0.0060,  0.0054,  0.0037]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.6.attention.self.query.lora_A.weight': tensor([[ 0.0454, -0.0253,  0.0340,  ...,  0.0092, -0.0035, -0.0448],\n",
       "         [ 0.0213,  0.0056,  0.0035,  ...,  0.0327,  0.0129, -0.0101],\n",
       "         [ 0.0240, -0.0173, -0.0134,  ...,  0.0331, -0.0033,  0.0223],\n",
       "         ...,\n",
       "         [-0.0123, -0.0277,  0.0264,  ..., -0.0303,  0.0484,  0.0142],\n",
       "         [ 0.0484,  0.0239,  0.0417,  ..., -0.0264,  0.0466, -0.0289],\n",
       "         [ 0.0204,  0.0211,  0.0377,  ...,  0.0348,  0.0159, -0.0314]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.6.attention.self.query.lora_B.weight': tensor([[-0.0020, -0.0101,  0.0051,  ..., -0.0010, -0.0039, -0.0126],\n",
       "         [-0.0159,  0.0093,  0.0176,  ..., -0.0176, -0.0187, -0.0076],\n",
       "         [-0.0063,  0.0033,  0.0072,  ..., -0.0102, -0.0078, -0.0035],\n",
       "         ...,\n",
       "         [ 0.0159, -0.0025, -0.0204,  ...,  0.0161,  0.0183,  0.0084],\n",
       "         [-0.0191,  0.0121,  0.0184,  ..., -0.0199, -0.0175, -0.0018],\n",
       "         [ 0.0048, -0.0054, -0.0005,  ...,  0.0059,  0.0057,  0.0022]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.6.attention.self.value.lora_A.weight': tensor([[-0.0064, -0.0312,  0.0052,  ...,  0.0323, -0.0273, -0.0271],\n",
       "         [ 0.0136,  0.0195, -0.0208,  ...,  0.0090,  0.0375, -0.0130],\n",
       "         [-0.0415, -0.0059, -0.0518,  ...,  0.0006,  0.0252,  0.0306],\n",
       "         ...,\n",
       "         [-0.0403, -0.0022, -0.0150,  ...,  0.0006,  0.0019, -0.0060],\n",
       "         [ 0.0176,  0.0364,  0.0474,  ...,  0.0306,  0.0058, -0.0240],\n",
       "         [-0.0348,  0.0305, -0.0350,  ...,  0.0276,  0.0245,  0.0069]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.6.attention.self.value.lora_B.weight': tensor([[-0.0063,  0.0061,  0.0085,  ...,  0.0079,  0.0111, -0.0061],\n",
       "         [ 0.0027, -0.0080, -0.0086,  ..., -0.0081,  0.0053, -0.0008],\n",
       "         [-0.0013, -0.0088,  0.0009,  ...,  0.0021, -0.0058,  0.0043],\n",
       "         ...,\n",
       "         [ 0.0118, -0.0150, -0.0200,  ..., -0.0160, -0.0133,  0.0136],\n",
       "         [-0.0130,  0.0052, -0.0022,  ...,  0.0082,  0.0087,  0.0261],\n",
       "         [ 0.0054,  0.0053, -0.0037,  ..., -0.0040, -0.0063, -0.0111]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.7.attention.self.query.lora_A.weight': tensor([[ 0.0183,  0.0349, -0.0468,  ..., -0.0511, -0.0125, -0.0057],\n",
       "         [ 0.0296,  0.0137,  0.0407,  ...,  0.0193,  0.0088,  0.0142],\n",
       "         [-0.0050, -0.0332,  0.0075,  ...,  0.0336,  0.0328, -0.0087],\n",
       "         ...,\n",
       "         [-0.0086, -0.0589,  0.0356,  ...,  0.0336, -0.0337, -0.0150],\n",
       "         [ 0.0061,  0.0081, -0.0568,  ...,  0.0031,  0.0091,  0.0054],\n",
       "         [-0.0038,  0.0677, -0.0003,  ..., -0.0459, -0.0349,  0.0167]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.7.attention.self.query.lora_B.weight': tensor([[ 1.4075e-02, -9.7758e-05, -7.3732e-03,  ..., -1.0637e-02,\n",
       "          -1.3729e-03,  9.0315e-03],\n",
       "         [ 8.2282e-04, -1.2482e-02,  6.5554e-03,  ...,  1.5421e-03,\n",
       "           6.2144e-03, -2.9563e-03],\n",
       "         [-4.3659e-03,  2.6000e-05,  1.1159e-02,  ...,  1.0109e-02,\n",
       "           1.7988e-03, -7.3567e-03],\n",
       "         ...,\n",
       "         [ 2.1246e-02, -2.8128e-02, -9.0064e-03,  ..., -1.5917e-02,\n",
       "           2.7332e-02,  1.3169e-02],\n",
       "         [-1.0468e-02,  9.4832e-03,  1.0006e-02,  ...,  1.5420e-02,\n",
       "          -1.1422e-02, -8.8356e-03],\n",
       "         [ 4.5146e-03, -6.9338e-03, -8.4201e-03,  ..., -1.1021e-02,\n",
       "           5.4147e-03,  6.4905e-03]], device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.7.attention.self.value.lora_A.weight': tensor([[ 0.0552, -0.0231,  0.0150,  ...,  0.0054, -0.0094,  0.0257],\n",
       "         [ 0.0056,  0.0184, -0.0307,  ..., -0.0028,  0.0302, -0.0096],\n",
       "         [ 0.0229,  0.0053,  0.0448,  ...,  0.0240,  0.0016,  0.0204],\n",
       "         ...,\n",
       "         [ 0.0060,  0.0147, -0.0016,  ...,  0.0400, -0.0041, -0.0205],\n",
       "         [ 0.0012,  0.0039, -0.0034,  ...,  0.0172, -0.0138,  0.0073],\n",
       "         [ 0.0224, -0.0300,  0.0165,  ..., -0.0348,  0.0036,  0.0241]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.7.attention.self.value.lora_B.weight': tensor([[-1.6764e-02,  1.7242e-02, -1.2652e-02,  ..., -1.1281e-02,\n",
       "           1.6102e-02, -1.3965e-02],\n",
       "         [ 3.4783e-03, -1.8147e-02, -1.4179e-03,  ...,  1.7043e-02,\n",
       "          -8.8065e-04,  1.2509e-03],\n",
       "         [-5.3442e-03,  1.4779e-03, -4.1466e-03,  ..., -6.6825e-03,\n",
       "          -5.8406e-05,  4.0344e-03],\n",
       "         ...,\n",
       "         [ 7.2522e-03, -7.4559e-03,  6.1769e-03,  ...,  2.7254e-03,\n",
       "          -8.2204e-03,  1.3298e-02],\n",
       "         [ 8.6848e-03,  8.6466e-03, -6.3489e-03,  ..., -7.0085e-03,\n",
       "          -1.6014e-02,  8.2061e-03],\n",
       "         [ 2.4097e-02, -1.5165e-02,  2.7672e-02,  ...,  1.8354e-02,\n",
       "          -3.0604e-02,  2.1012e-02]], device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.8.attention.self.query.lora_A.weight': tensor([[-0.0016,  0.0419, -0.0409,  ..., -0.0446,  0.0238,  0.0362],\n",
       "         [-0.0221,  0.0271, -0.0279,  ..., -0.0021,  0.0035,  0.0058],\n",
       "         [ 0.0068,  0.0045,  0.0156,  ...,  0.0077, -0.0008,  0.0059],\n",
       "         ...,\n",
       "         [ 0.0281, -0.0121, -0.0356,  ..., -0.0400, -0.0023,  0.0052],\n",
       "         [-0.0253,  0.0146, -0.0829,  ..., -0.0227, -0.0103,  0.0094],\n",
       "         [-0.0316, -0.0098,  0.0285,  ...,  0.0049,  0.0408, -0.0547]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.8.attention.self.query.lora_B.weight': tensor([[ 1.3277e-02,  5.3055e-03, -6.8612e-03,  ...,  1.3476e-02,\n",
       "           2.7170e-02, -2.1217e-03],\n",
       "         [-2.3086e-02, -2.7906e-02,  2.1837e-02,  ..., -2.4378e-02,\n",
       "          -1.9471e-02,  2.5115e-02],\n",
       "         [-1.7530e-02, -2.1384e-02,  1.6553e-02,  ..., -1.5746e-02,\n",
       "          -1.2636e-02,  1.9978e-02],\n",
       "         ...,\n",
       "         [-1.6562e-05,  2.4805e-03, -2.4643e-03,  ..., -4.1555e-03,\n",
       "          -2.5833e-02, -5.1966e-03],\n",
       "         [ 6.1825e-03,  7.1870e-03, -5.7426e-03,  ...,  1.0457e-02,\n",
       "           1.1645e-02, -6.5206e-03],\n",
       "         [ 1.0108e-02, -3.1164e-03,  3.6923e-03,  ...,  1.2535e-02,\n",
       "           1.3522e-02,  1.0200e-03]], device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.8.attention.self.value.lora_A.weight': tensor([[ 0.0054, -0.0094, -0.0627,  ..., -0.0552, -0.0078,  0.0448],\n",
       "         [ 0.0398, -0.0037,  0.0385,  ...,  0.0240,  0.0066, -0.0185],\n",
       "         [-0.0048,  0.0563,  0.0286,  ...,  0.0585,  0.0077, -0.0275],\n",
       "         ...,\n",
       "         [-0.0136,  0.0031,  0.0061,  ..., -0.0519,  0.0276, -0.0087],\n",
       "         [ 0.0034,  0.0090,  0.0021,  ..., -0.0004, -0.0016,  0.0124],\n",
       "         [ 0.0296,  0.0082,  0.0322,  ...,  0.0599, -0.0372,  0.0093]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.8.attention.self.value.lora_B.weight': tensor([[-0.0064,  0.0088,  0.0093,  ..., -0.0119, -0.0044,  0.0112],\n",
       "         [ 0.0110, -0.0140, -0.0132,  ...,  0.0136,  0.0109, -0.0135],\n",
       "         [-0.0162,  0.0063,  0.0054,  ..., -0.0076, -0.0136,  0.0132],\n",
       "         ...,\n",
       "         [-0.0178,  0.0171,  0.0187,  ..., -0.0163, -0.0155,  0.0137],\n",
       "         [ 0.0131, -0.0073, -0.0071,  ...,  0.0095,  0.0085, -0.0126],\n",
       "         [ 0.0062, -0.0137, -0.0070,  ...,  0.0083,  0.0043, -0.0101]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.9.attention.self.query.lora_A.weight': tensor([[ 2.0285e-03, -3.3236e-02,  6.0933e-03,  ...,  2.9124e-02,\n",
       "           1.6620e-02,  6.0897e-05],\n",
       "         [-1.6150e-02,  2.9631e-03, -1.5518e-03,  ..., -3.0117e-02,\n",
       "           3.2267e-02,  3.3310e-02],\n",
       "         [ 3.7694e-02,  5.7778e-03,  5.4841e-02,  ..., -8.4874e-03,\n",
       "           3.3917e-02, -1.8778e-02],\n",
       "         ...,\n",
       "         [-1.5161e-02, -1.6225e-02, -4.5689e-02,  ..., -2.4025e-02,\n",
       "          -2.0508e-02,  9.9185e-03],\n",
       "         [-2.5840e-02,  5.8102e-03,  6.4915e-02,  ...,  1.0897e-02,\n",
       "          -1.0598e-02, -1.7403e-02],\n",
       "         [-2.9182e-02, -6.2420e-02,  6.0129e-03,  ...,  1.5877e-02,\n",
       "           2.5592e-02,  1.0158e-02]], device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.9.attention.self.query.lora_B.weight': tensor([[-0.0240,  0.0239, -0.0279,  ...,  0.0261, -0.0283, -0.0302],\n",
       "         [-0.0128,  0.0116, -0.0178,  ...,  0.0144, -0.0170, -0.0059],\n",
       "         [-0.0074,  0.0080, -0.0108,  ...,  0.0075, -0.0112, -0.0122],\n",
       "         ...,\n",
       "         [-0.0217,  0.0230, -0.0265,  ...,  0.0179, -0.0258, -0.0266],\n",
       "         [-0.0040,  0.0048, -0.0087,  ...,  0.0018, -0.0085, -0.0105],\n",
       "         [ 0.0188, -0.0193,  0.0230,  ..., -0.0192,  0.0233,  0.0171]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.9.attention.self.value.lora_A.weight': tensor([[-0.0307,  0.0290,  0.0236,  ...,  0.0006,  0.0289, -0.0159],\n",
       "         [-0.0417,  0.0209,  0.0346,  ..., -0.0016, -0.0307, -0.0367],\n",
       "         [-0.0138, -0.0062, -0.0060,  ...,  0.0019, -0.0017,  0.0224],\n",
       "         ...,\n",
       "         [-0.0071,  0.0054, -0.0059,  ...,  0.0277,  0.0164, -0.0141],\n",
       "         [-0.0066,  0.0347,  0.0148,  ..., -0.0334, -0.0066,  0.0421],\n",
       "         [ 0.0335,  0.0485, -0.0473,  ...,  0.0317, -0.0053,  0.0032]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.9.attention.self.value.lora_B.weight': tensor([[ 1.2871e-02, -1.8352e-02,  1.3174e-02,  ...,  9.8449e-03,\n",
       "          -6.9081e-03, -4.4848e-03],\n",
       "         [ 1.6492e-02, -1.8603e-02,  1.7257e-02,  ...,  1.7600e-02,\n",
       "          -1.8435e-02, -1.6550e-02],\n",
       "         [ 1.3296e-02, -1.2176e-02,  1.3804e-02,  ...,  1.7504e-02,\n",
       "          -1.7876e-03, -1.4419e-02],\n",
       "         ...,\n",
       "         [ 3.3247e-05,  6.4596e-03, -1.6294e-03,  ..., -1.2256e-03,\n",
       "          -4.1829e-03, -3.4295e-03],\n",
       "         [-8.9916e-04, -1.6010e-03, -3.7540e-04,  ...,  7.2434e-04,\n",
       "           1.1652e-03,  4.0791e-04],\n",
       "         [-1.1751e-02,  1.2185e-02, -1.3293e-02,  ..., -1.2356e-02,\n",
       "           1.0778e-02,  1.4590e-02]], device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.10.attention.self.query.lora_A.weight': tensor([[ 0.0291,  0.0165, -0.0287,  ..., -0.0326,  0.0397,  0.0248],\n",
       "         [-0.0310, -0.0360,  0.0118,  ...,  0.0031, -0.0118, -0.0105],\n",
       "         [-0.0156, -0.0727,  0.0103,  ...,  0.0180, -0.0173, -0.0322],\n",
       "         ...,\n",
       "         [ 0.0307, -0.0017,  0.0702,  ...,  0.0519, -0.0033,  0.0014],\n",
       "         [-0.0261, -0.0549,  0.0544,  ...,  0.0310,  0.0009, -0.0456],\n",
       "         [-0.0171, -0.0548,  0.0362,  ..., -0.0178,  0.0160,  0.0135]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.10.attention.self.query.lora_B.weight': tensor([[-0.0236,  0.0209,  0.0207,  ...,  0.0210,  0.0209,  0.0201],\n",
       "         [ 0.0045, -0.0058, -0.0036,  ..., -0.0052, -0.0050, -0.0044],\n",
       "         [-0.0017,  0.0097,  0.0041,  ...,  0.0071,  0.0101,  0.0093],\n",
       "         ...,\n",
       "         [ 0.0014,  0.0022, -0.0022,  ..., -0.0012,  0.0021,  0.0039],\n",
       "         [ 0.0109, -0.0050, -0.0127,  ..., -0.0099, -0.0070, -0.0073],\n",
       "         [-0.0172,  0.0117,  0.0174,  ...,  0.0155,  0.0134,  0.0125]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.10.attention.self.value.lora_A.weight': tensor([[-0.0263, -0.0402,  0.0078,  ...,  0.0139,  0.0036, -0.0009],\n",
       "         [-0.0082, -0.0277, -0.0077,  ..., -0.0270, -0.0127,  0.0141],\n",
       "         [ 0.0051, -0.0400,  0.0062,  ...,  0.0371, -0.0132, -0.0003],\n",
       "         ...,\n",
       "         [-0.0159, -0.0275,  0.0392,  ..., -0.0119,  0.0212, -0.0063],\n",
       "         [ 0.0345, -0.0083, -0.0603,  ...,  0.0141,  0.0304, -0.0170],\n",
       "         [ 0.0117,  0.0281, -0.0344,  ...,  0.0096, -0.0125, -0.0176]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.10.attention.self.value.lora_B.weight': tensor([[-0.0057,  0.0060,  0.0080,  ..., -0.0051,  0.0045,  0.0072],\n",
       "         [ 0.0017,  0.0037, -0.0009,  ...,  0.0009,  0.0028,  0.0059],\n",
       "         [-0.0066,  0.0052,  0.0021,  ..., -0.0037,  0.0084,  0.0049],\n",
       "         ...,\n",
       "         [ 0.0169, -0.0214, -0.0209,  ...,  0.0203, -0.0206, -0.0225],\n",
       "         [ 0.0009,  0.0006,  0.0103,  ..., -0.0027,  0.0055,  0.0067],\n",
       "         [-0.0020,  0.0052, -0.0006,  ..., -0.0027,  0.0022,  0.0071]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.11.attention.self.query.lora_A.weight': tensor([[ 0.0317, -0.0389,  0.0460,  ...,  0.0073, -0.0131, -0.0605],\n",
       "         [ 0.0324, -0.0509, -0.0152,  ...,  0.0355, -0.0551, -0.0166],\n",
       "         [ 0.0078, -0.0155,  0.0116,  ...,  0.0515,  0.0050, -0.0202],\n",
       "         ...,\n",
       "         [-0.0138,  0.0372, -0.0561,  ..., -0.0226, -0.0087,  0.0093],\n",
       "         [-0.0009,  0.0065, -0.0506,  ..., -0.0441,  0.0063,  0.0575],\n",
       "         [-0.0028,  0.0655, -0.0538,  ...,  0.0013,  0.0142,  0.0019]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.11.attention.self.query.lora_B.weight': tensor([[-0.0108, -0.0111, -0.0109,  ...,  0.0096,  0.0120,  0.0127],\n",
       "         [ 0.0127,  0.0124,  0.0115,  ..., -0.0122, -0.0124, -0.0145],\n",
       "         [-0.0040, -0.0051, -0.0053,  ...,  0.0035,  0.0051,  0.0055],\n",
       "         ...,\n",
       "         [-0.0048, -0.0046, -0.0041,  ...,  0.0058,  0.0051,  0.0060],\n",
       "         [ 0.0084,  0.0087,  0.0106,  ..., -0.0122, -0.0094, -0.0084],\n",
       "         [ 0.0143,  0.0144,  0.0144,  ..., -0.0126, -0.0144, -0.0148]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.11.attention.self.value.lora_A.weight': tensor([[ 0.0151, -0.0339,  0.0292,  ..., -0.0496,  0.0304, -0.0402],\n",
       "         [ 0.0032,  0.0337, -0.0337,  ..., -0.0464, -0.0229, -0.0101],\n",
       "         [-0.0315, -0.0027, -0.0160,  ...,  0.0629,  0.0018,  0.0076],\n",
       "         ...,\n",
       "         [ 0.0174,  0.0085,  0.0098,  ...,  0.0255, -0.0136, -0.0421],\n",
       "         [ 0.0232,  0.0174, -0.0509,  ...,  0.0076, -0.0230, -0.0302],\n",
       "         [-0.0225, -0.0112,  0.0217,  ...,  0.0894, -0.0194,  0.0192]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.bert.encoder.layer.11.attention.self.value.lora_B.weight': tensor([[-0.0079, -0.0218,  0.0144,  ..., -0.0021, -0.0130,  0.0214],\n",
       "         [-0.0105, -0.0111,  0.0015,  ...,  0.0150, -0.0033,  0.0035],\n",
       "         [-0.0024,  0.0012, -0.0093,  ..., -0.0223, -0.0330,  0.0047],\n",
       "         ...,\n",
       "         [-0.0190, -0.0258,  0.0134,  ..., -0.0117, -0.0012,  0.0265],\n",
       "         [-0.0198, -0.0343,  0.0262,  ...,  0.0257,  0.0034,  0.0306],\n",
       "         [ 0.0073, -0.0104,  0.0071,  ..., -0.0066, -0.0167,  0.0083]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.classifier.weight': tensor([[-0.0057,  0.0383, -0.0008,  ..., -0.0019,  0.0251,  0.0160],\n",
       "         [-0.0356, -0.0238, -0.0100,  ...,  0.0131, -0.0505,  0.0155],\n",
       "         [-0.0425, -0.0694,  0.0067,  ..., -0.0062, -0.0091, -0.0004],\n",
       "         ...,\n",
       "         [-0.0476, -0.0104,  0.0006,  ...,  0.0230, -0.0086, -0.0276],\n",
       "         [ 0.0048, -0.0246, -0.0215,  ..., -0.0168, -0.0139,  0.0229],\n",
       "         [ 0.0452,  0.0295, -0.0069,  ..., -0.0113,  0.0912, -0.0325]],\n",
       "        device='cuda:0'),\n",
       " 'base_model.model.classifier.bias': tensor([ 0.0050,  0.0005,  0.0054, -0.0042, -0.0032, -0.0070, -0.0083],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PeftConfig.from_pretrained(peft_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='dmis-lab/biobert-v1.1', revision=None, task_type='SEQ_CLS', inference_mode=True, r=8, target_modules={'query', 'value'}, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "config = PeftConfig.from_pretrained(peft_model_dir)\n",
    "# load base model \n",
    "model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path, num_labels = 7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "all_eval = concatenate_datasets([tokenized_datasets[\"validation\"], tokenized_datasets[\"test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 6228\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_layer11_weights = model.roberta.encoder.layer[0].attention.self.query.weight.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0729, -0.0029, -0.0902,  ...,  0.1033,  0.0900, -0.1030],\n",
       "        [-0.0516,  0.2061,  0.0739,  ...,  0.0657,  0.0634,  0.1282],\n",
       "        [ 0.0878,  0.0698, -0.0515,  ..., -0.0426, -0.0081,  0.1100],\n",
       "        ...,\n",
       "        [-0.1871,  0.0172, -0.0315,  ..., -0.0503,  0.1024, -0.1165],\n",
       "        [-0.2532,  0.0439,  0.0638,  ...,  0.0701, -0.1045,  0.0118],\n",
       "        [-0.0516, -0.0859,  0.1027,  ..., -0.1895,  0.0033, -0.0541]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_layer11_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PeftModelForSequenceClassification:\n\tsize mismatch for base_model.model.classifier.modules_to_save.default.out_proj.weight: copying a param with shape torch.Size([7, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for base_model.model.classifier.modules_to_save.default.out_proj.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb Cell 234\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B129.67.153.198/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb#Y505sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load peft model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B129.67.153.198/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb#Y505sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m PeftModel\u001b[39m.\u001b[39;49mfrom_pretrained(model, peft_model_dir)\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/peft/peft_model.py:306\u001b[0m, in \u001b[0;36mPeftModel.from_pretrained\u001b[0;34m(cls, model, model_id, adapter_name, is_trainable, config, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     model \u001b[39m=\u001b[39m MODEL_TYPE_TO_PEFT_MODEL_MAPPING[config\u001b[39m.\u001b[39mtask_type](model, config, adapter_name)\n\u001b[0;32m--> 306\u001b[0m model\u001b[39m.\u001b[39;49mload_adapter(model_id, adapter_name, is_trainable\u001b[39m=\u001b[39;49mis_trainable, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    307\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/peft/peft_model.py:606\u001b[0m, in \u001b[0;36mPeftModel.load_adapter\u001b[0;34m(self, model_id, adapter_name, is_trainable, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m adapters_weights \u001b[39m=\u001b[39m load_peft_weights(model_id, device\u001b[39m=\u001b[39mtorch_device, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhf_hub_download_kwargs)\n\u001b[1;32m    605\u001b[0m \u001b[39m# load the weights into the model\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m load_result \u001b[39m=\u001b[39m set_peft_model_state_dict(\u001b[39mself\u001b[39;49m, adapters_weights, adapter_name\u001b[39m=\u001b[39;49madapter_name)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    608\u001b[0m     (\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhf_device_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    609\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhf_device_map\u001b[39m.\u001b[39mvalues())\u001b[39m.\u001b[39mintersection({\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdisk\u001b[39m\u001b[39m\"\u001b[39m})) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m    610\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpeft_config) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    611\u001b[0m ):\n\u001b[1;32m    612\u001b[0m     device_map \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdevice_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/peft/utils/save_and_load.py:158\u001b[0m, in \u001b[0;36mset_peft_model_state_dict\u001b[0;34m(model, peft_model_state_dict, adapter_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m load_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mload_state_dict(peft_model_state_dict, strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mis_prompt_learning:\n\u001b[1;32m    160\u001b[0m     model\u001b[39m.\u001b[39mprompt_encoder[adapter_name]\u001b[39m.\u001b[39membedding\u001b[39m.\u001b[39mload_state_dict(\n\u001b[1;32m    161\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m: peft_model_state_dict[\u001b[39m\"\u001b[39m\u001b[39mprompt_embeddings\u001b[39m\u001b[39m\"\u001b[39m]}, strict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PeftModelForSequenceClassification:\n\tsize mismatch for base_model.model.classifier.modules_to_save.default.out_proj.weight: copying a param with shape torch.Size([7, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for base_model.model.classifier.modules_to_save.default.out_proj.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "# load peft model\n",
    "model = PeftModel.from_pretrained(model, peft_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BertForSequenceClassification(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=7, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=7, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_loaded_model_layer11 = model.bert.encoder.layer[0].attention.self.query.weight.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(org_layer11_weights, peft_loaded_model_layer11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0024, -0.0051, -0.0104,  ..., -0.0529, -0.0080, -0.0795],\n",
       "        [-0.0238,  0.0116, -0.0225,  ...,  0.0170, -0.0107,  0.0075],\n",
       "        [-0.0422,  0.0222,  0.0508,  ..., -0.0590, -0.0259, -0.0288],\n",
       "        ...,\n",
       "        [ 0.0169, -0.0077, -0.0231,  ..., -0.0427,  0.0233,  0.0325],\n",
       "        [-0.0583,  0.1086, -0.0798,  ..., -0.0704, -0.0072,  0.0647],\n",
       "        [ 0.0236,  0.0544,  0.0459,  ...,  0.0631, -0.0455, -0.0590]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_layer11_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge and unload\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unloaded_peft_layer11 = model.roberta.encoder.layer[0].attention.self.query.weight.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0042,  0.0016, -0.0165,  ..., -0.0577, -0.0042, -0.0744],\n",
       "        [-0.0217,  0.0038, -0.0154,  ...,  0.0222, -0.0149,  0.0017],\n",
       "        [-0.0429,  0.0249,  0.0484,  ..., -0.0611, -0.0243, -0.0267],\n",
       "        ...,\n",
       "        [ 0.0160, -0.0047, -0.0260,  ..., -0.0447,  0.0249,  0.0347],\n",
       "        [-0.0568,  0.1029, -0.0745,  ..., -0.0662, -0.0102,  0.0604],\n",
       "        [ 0.0259,  0.0459,  0.0535,  ...,  0.0692, -0.0503, -0.0655]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unloaded_peft_layer11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'org_layer11_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb Cell 241\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B129.67.153.198/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb#Y510sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39mequal(org_layer11_weights, unloaded_peft_layer11)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'org_layer11_weights' is not defined"
     ]
    }
   ],
   "source": [
    "torch.equal(org_layer11_weights, unloaded_peft_layer11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "def compute_metrics(eval_pred):\n",
    "        precision_score = evaluate.load(\"precision\")\n",
    "        recall_score = evaluate.load(\"recall\")\n",
    "        accuracy_score = evaluate.load(\"accuracy\")\n",
    "        f1_score = evaluate.load(\"f1\")        \n",
    "        roc_auc_score = evaluate.load(\"roc_auc\", \"multiclass\")        \n",
    "\n",
    "        logits, labels = eval_pred\n",
    "        \n",
    "        # print(f\"logits are: {logits} of shape: {logits.shape}\")\n",
    "        #TODO add softmax to convert logits to probs\n",
    "        # print(f\"logits shape is: {logits.shape}\")\n",
    "        pred_scores = softmax(logits, axis = -1)        \n",
    "        predictions = np.argmax(logits, axis = -1)\n",
    "        \n",
    "        # print(f\"Labels are: {labels}\\n\")\n",
    "        # print(f\"Preds are: {predictions}\")\n",
    "        precision = precision_score.compute(predictions=predictions, references=labels, average = \"macro\")[\"precision\"]\n",
    "        recall = recall_score.compute(predictions=predictions, references=labels, average = \"macro\")[\"recall\"]\n",
    "        accuracy = accuracy_score.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "        f1_macro = f1_score.compute(predictions=predictions, references=labels, average = \"macro\")[\"f1\"]\n",
    "        f1_micro = f1_score.compute(predictions=predictions, references=labels, average = \"micro\")[\"f1\"]\n",
    "        f1_weighted = f1_score.compute(predictions=predictions, references=labels, average = \"weighted\")[\"f1\"]\n",
    "        # roc_auc has slightly different format - needs the probs/scores rather than predicted labels\n",
    "        roc_auc = roc_auc_score.compute(references=labels,\n",
    "                                        prediction_scores = pred_scores,\n",
    "                                        multi_class = 'ovr', \n",
    "                                        average = \"macro\")['roc_auc']\n",
    "        \n",
    "        return {\"precision\": precision, \n",
    "                \"recall\": recall,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"f1_macro\":f1_macro,\n",
    "                \"f1_micro\":f1_micro,\n",
    "                \"f1_weighted\":f1_weighted,\n",
    "                \"roc_auc_macro\":roc_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of labels from the dataset\n",
    "num_labels = len(np.unique(datasets[\"validation\"][\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/accelerate/utils/imports.py:245: UserWarning: Intel Extension for PyTorch 1.12 needs to work with PyTorch 1.12.*, but PyTorch 2.0.1 is found. Please switch to the matching version and run again.\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='195' max='195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [195/195 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mniall-taylor\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/niallt/efficient-ml/notebooks/wandb/run-20231107_153722-ebnz0umn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/niall-taylor/huggingface/runs/ebnz0umn' target=\"_blank\">fallen-resonance-1</a></strong> to <a href='https://wandb.ai/niall-taylor/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/niall-taylor/huggingface' target=\"_blank\">https://wandb.ai/niall-taylor/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/niall-taylor/huggingface/runs/ebnz0umn' target=\"_blank\">https://wandb.ai/niall-taylor/huggingface/runs/ebnz0umn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run over evaluation dataloader and collect metrics\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./test_trainer\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    do_train=False,  \n",
    "    do_eval=True,\n",
    "    per_device_eval_batch_size=16  \n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                    args = training_args,\n",
    "                    train_dataset=tokenized_datasets[\"train\"],\n",
    "                    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "                    compute_metrics=compute_metrics,\n",
    "                    tokenizer=tokenizer,\n",
    "                    data_collator=collate_fn,)\n",
    "\n",
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.18856966495513916,\n",
       " 'eval_precision': 0.872335055021986,\n",
       " 'eval_recall': 0.8682285224869758,\n",
       " 'eval_accuracy': 0.9421965317919075,\n",
       " 'eval_f1_macro': 0.8697938878679062,\n",
       " 'eval_f1_micro': 0.9421965317919075,\n",
       " 'eval_f1_weighted': 0.9418719624376168,\n",
       " 'eval_roc_auc_macro': 0.9928218321449308,\n",
       " 'eval_runtime': 26.456,\n",
       " 'eval_samples_per_second': 117.705,\n",
       " 'eval_steps_per_second': 7.371}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "    batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# below is miscellanous code that is not used in the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load standard model with peft\n",
    "model_name_or_path = \"roberta-base\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map = \"auto\")\n",
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type = \"SEQ_CLS\", inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='roberta-base', revision=None, task_type='SEQ_CLS', inference_mode=False, r=8, target_modules=['query', 'value'], lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta model gpu usage\n",
    "18777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declutr model gpu usage\n",
    "19905 - 19595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': PromptTuningConfig(peft_type=<PeftType.PROMPT_TUNING: 'PROMPT_TUNING'>, base_model_name_or_path='roberta-base', task_type='SEQ_CLS', inference_mode=False, num_virtual_tokens=10, token_dim=768, num_transformer_submodules=1, num_attention_heads=12, num_layers=12, prompt_tuning_init=<PromptTuningInit.RANDOM: 'RANDOM'>, prompt_tuning_init_text=None, tokenizer_name_or_path=None)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(\n",
       "  in_features=768, out_features=768, bias=True\n",
       "  (lora_dropout): ModuleDict(\n",
       "    (default): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lora_A): ModuleDict(\n",
       "    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "  )\n",
       "  (lora_B): ModuleDict(\n",
       "    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "  )\n",
       "  (lora_embedding_A): ParameterDict()\n",
       "  (lora_embedding_B): ParameterDict()\n",
       ")"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.model.roberta.encoder.layer[0].attention.self.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_module = peft_model.model.roberta.encoder.layer[0].attention.self.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(\n",
       "  in_features=768, out_features=768, bias=True\n",
       "  (lora_dropout): ModuleDict(\n",
       "    (default): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lora_A): ModuleDict(\n",
       "    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "  )\n",
       "  (lora_B): ModuleDict(\n",
       "    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "  )\n",
       "  (lora_embedding_A): ParameterDict()\n",
       "  (lora_embedding_B): ParameterDict()\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to zeros\n",
    "query_module.lora_A.default.weight.data = torch.zeros_like(query_module.lora_A.default.weight.data)\n",
    "query_module.weight.data = torch.zeros_like(query_module.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0729, -0.0029, -0.0902,  ...,  0.1033,  0.0900, -0.1030],\n",
       "        [-0.0516,  0.2061,  0.0739,  ...,  0.0657,  0.0634,  0.1282],\n",
       "        [ 0.0878,  0.0698, -0.0515,  ..., -0.0426, -0.0081,  0.1100],\n",
       "        ...,\n",
       "        [-0.1871,  0.0172, -0.0315,  ..., -0.0503,  0.1024, -0.1165],\n",
       "        [-0.2532,  0.0439,  0.0638,  ...,  0.0701, -0.1045,  0.0118],\n",
       "        [-0.0516, -0.0859,  0.1027,  ..., -0.1895,  0.0033, -0.0541]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test query module\n",
    "# create tensor of shape (768, 768) and set dtype to float16\n",
    "tensor = torch.rand(768, 768).to(\"cuda\").to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_result = query_module(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6777,  1.2158,  0.5444,  ..., -1.5322,  2.0527, -0.0883],\n",
       "        [ 0.1980, -0.7061,  0.8887,  ..., -0.8794,  0.0526,  1.4717],\n",
       "        [ 0.4829,  1.0625,  0.4050,  ...,  0.5127,  1.7363,  0.4033],\n",
       "        ...,\n",
       "        [ 0.5737, -0.4644, -0.1860,  ...,  0.7104,  0.6699,  0.5977],\n",
       "        [ 1.0684, -0.0388,  0.4219,  ...,  0.7651,  1.5244,  1.4688],\n",
       "        [ 0.6953,  0.8516, -0.0283,  ..., -0.2627,  1.2002,  0.5142]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 query_module.get_submodule()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">get_submodule</span><span style=\"font-weight: bold\">()</span> missing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> required positional argument: <span style=\"color: #008000; text-decoration-color: #008000\">'target'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 query_module.get_submodule()                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mget_submodule\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing \u001b[1;36m1\u001b[0m required positional argument: \u001b[32m'target'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_module.get_submodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=768, bias=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[0].attention.self.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "39nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
