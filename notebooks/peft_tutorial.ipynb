{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "#set visible cuda devices\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    PrefixTuningConfig,\n",
    "    PromptEncoderConfig,\n",
    "    PromptTuningConfig,\n",
    "    prepare_model_for_int8_training,\n",
    "    # AutoPeftModel,\n",
    "    prepare_model_for_kbit_training # only for latest dev version of peft\n",
    ")\n",
    "\n",
    "\n",
    "import evaluate\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import (AutoModelForSequenceClassification, \n",
    "                          AutoModelForCausalLM,\n",
    "                          AutoModelForMaskedLM,\n",
    "                          AutoModel,\n",
    "                        AutoTokenizer,\n",
    "                        get_linear_schedule_with_warmup,\n",
    "                        set_seed,\n",
    "                        LlamaForSequenceClassification,\n",
    "                        LlamaForCausalLM,\n",
    "                        LlamaTokenizer, LongformerForMaskedLM, LongformerForSequenceClassification)\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from loguru import logger as loguru_logger\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from data_utils.model_utils import count_trainable_parameters, freeze_model, unfreeze_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup some parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count trainable params of a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.llama.tokenization_llama.LlamaTokenizer"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LlamaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 2\n",
    "# model_name_or_path = \"/mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-wecho/sampled_250000/08-03-2023--13-06/checkpoint-84000/\" # \n",
    "# model_name_or_path = \"/mnt/sdc/niallt/saved_models/declutr/mimic/few_epoch/mimic-roberta-base/2_anch_2_pos_min_1024/transformer_format/\"\n",
    "# model_name_or_path = \"/mnt/sdc/niallt/saved_models/language_modelling/mimic/mimic-roberta-base/sampled_250000/22-12-2022--12-45/checkpoint-100000/\"\n",
    "# model_name_or_path = \"/mnt/sdc/niallt/saved_models/declutr/mimic/few_epoch/mimic-roberta-base/2_anch_2_pos_min_1024/transformer_format/\"\n",
    "model_name_or_path = \"roberta-base\" # | roberta-large\n",
    "peft_method = \"LORA\" # | PROMPT_TUNING | PREFIX_TUNING | P_TUNING\n",
    "device = \"cuda\"\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## llama model\n",
    "# model_name_or_path = \"decapoda-research/llama-7b-hf\" # ybelkada/falcon-7b-sharded-bf16\n",
    "model_name_or_path =\"ybelkada/falcon-7b-sharded-bf16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a363db36d247929bcb6e7fc3ab8a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca6676602f74e20a4b889a84caddb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/6.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/accelerate/utils/imports.py:197: UserWarning: Intel Extension for PyTorch 1.12 needs to work with PyTorch 1.12.*, but PyTorch 2.0.1 is found. Please switch to the matching version and run again.\n",
      "  warnings.warn(\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a97c69788fe479e820f8c1cf7858b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## open llama 3b\n",
    "model_path = 'openlm-research/open_llama_3b'\n",
    "model = LlamaForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 3200, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (k_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (v_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (o_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3200, out_features=8640, bias=False)\n",
       "          (down_proj): Linear(in_features=8640, out_features=3200, bias=False)\n",
       "          (up_proj): Linear(in_features=3200, out_features=8640, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3200, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    }
   ],
   "source": [
    "auto_model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 3200, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (k_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (v_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (o_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3200, out_features=8640, bias=False)\n",
       "          (down_proj): Linear(in_features=8640, out_features=3200, bias=False)\n",
       "          (up_proj): Linear(in_features=3200, out_features=8640, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3200, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load standard model with peft\n",
    "model_name_or_path = \"roberta-base\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type = \"SEQ_CLS\", inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184260"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(peft_model.base_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### can we load in a base peft model with no spcific task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can happen is the get_peft_model will end up freezing all layers if no task is specified\n",
    "\n",
    "[x] - Works for AutoModel with no LM head\n",
    "[]  - Does not work for AutoModelForMLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "auto_model = AutoModel.from_pretrained(model_name_or_path, torch_dtype=torch.float16)\n",
    "mlm_model = AutoModelForMaskedLM.from_pretrained(model_name_or_path, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type=None, inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, base_model_name_or_path=None, revision=None, task_type=None, inference_mode=False, r=8, target_modules=None, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lora_roberta  \u001b[39m=\u001b[39m get_peft_model(model, peft_config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "lora_roberta  = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForMaskedLM(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 124,992,345 || trainable%: 0.23594404921357384\n"
     ]
    }
   ],
   "source": [
    "lora_roberta.print_trainable_parameters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we use peft on top of peft method - i.e. LORA first and then PROMPT_TUNING on top of that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_roberta  = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,479,172 || all params: 125,534,212 || trainable%: 1.1783018959006968\n"
     ]
    }
   ],
   "source": [
    "lora_roberta.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count trainable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1479172"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(lora_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,479,172 || all params: 125,534,212 || trainable%: 1.1783018959006968\n"
     ]
    }
   ],
   "source": [
    "lora_roberta.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'named_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B129.67.153.198/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb#Y223sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m lr \u001b[39m=\u001b[39m \u001b[39m1e-3\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B129.67.153.198/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb#Y223sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m second_peft_config \u001b[39m=\u001b[39m PromptTuningConfig(task_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSEQ_CLS\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B129.67.153.198/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb#Y223sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m                                     num_virtual_tokens\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B129.67.153.198/home/niallt/efficient-ml/notebooks/peft_tutorial.ipynb#Y223sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m full_peft_roberta \u001b[39m=\u001b[39m get_peft_model(lora_roberta, second_peft_config)\n",
      "File \u001b[0;32m~/peft/src/peft/mapping.py:122\u001b[0m, in \u001b[0;36mget_peft_model\u001b[0;34m(model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(peft_config, PromptLearningConfig):\n\u001b[1;32m    121\u001b[0m     peft_config \u001b[39m=\u001b[39m _prepare_prompt_learning_config(peft_config, model_config)\n\u001b[0;32m--> 122\u001b[0m \u001b[39mreturn\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING[peft_config\u001b[39m.\u001b[39;49mtask_type](model, peft_config, adapter_name\u001b[39m=\u001b[39;49madapter_name)\n",
      "File \u001b[0;32m~/peft/src/peft/peft_model.py:613\u001b[0m, in \u001b[0;36mPeftModelForSequenceClassification.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, model, peft_config: PeftConfig, adapter_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 613\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(model, peft_config, adapter_name)\n\u001b[1;32m    614\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodules_to_save \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    615\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodules_to_save \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m}\n",
      "File \u001b[0;32m~/peft/src/peft/peft_model.py:111\u001b[0m, in \u001b[0;36mPeftModel.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_additional_trainable_modules(peft_config, adapter_name)\n\u001b[1;32m    110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_adapter(adapter_name, peft_config)\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39mis_gradient_checkpointing\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    114\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_model_for_gradient_checkpointing(model)\n",
      "File \u001b[0;32m~/peft/src/peft/peft_model.py:375\u001b[0m, in \u001b[0;36mPeftModel.add_adapter\u001b[0;34m(self, adapter_name, peft_config)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpeft_config[adapter_name] \u001b[39m=\u001b[39m peft_config\n\u001b[1;32m    374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(peft_config, PromptLearningConfig):\n\u001b[0;32m--> 375\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_prompt_encoder(adapter_name)\n\u001b[1;32m    376\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_model\u001b[39m.\u001b[39madd_adapter(adapter_name, peft_config)\n",
      "File \u001b[0;32m~/peft/src/peft/peft_model.py:223\u001b[0m, in \u001b[0;36mPeftModel._setup_prompt_encoder\u001b[0;34m(self, adapter_name)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mnum_transformer_submodules \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     config\u001b[39m.\u001b[39mnum_transformer_submodules \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mtask_type \u001b[39m==\u001b[39m TaskType\u001b[39m.\u001b[39mSEQ_2_SEQ_LM \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m named_param, value \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(transformer_backbone\u001b[39m.\u001b[39;49mnamed_parameters()):\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mvocab_size:\n\u001b[1;32m    225\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embeddings \u001b[39m=\u001b[39m transformer_backbone\u001b[39m.\u001b[39mget_submodule(named_param\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.weight\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'named_parameters'"
     ]
    }
   ],
   "source": [
    "# now run this through the prefix tuning peft config too\n",
    "\n",
    "second_peft_type = PeftType.PROMPT_TUNING\n",
    "lr = 1e-3\n",
    "second_peft_config = PromptTuningConfig(task_type=\"SEQ_CLS\", \n",
    "                                    num_virtual_tokens=10)\n",
    "\n",
    "full_peft_roberta = get_peft_model(lora_roberta, second_peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mobile bert models\n",
    "at moment does not work with mobile bert models - the peft library does not support them directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpie/bio-mobilebert were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at nlpie/bio-mobilebert and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# moible bert doesn't work with lora right now\n",
    "mobile_bert = AutoModelForSequenceClassification.from_pretrained(\"nlpie/bio-mobilebert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileBertForSequenceClassification(\n",
       "  (mobilebert): MobileBertModel(\n",
       "    (embeddings): MobileBertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
       "      (LayerNorm): NoNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): MobileBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x MobileBertLayer(\n",
       "          (attention): MobileBertAttention(\n",
       "            (self): MobileBertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): MobileBertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): MobileBertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): ReLU()\n",
       "          )\n",
       "          (output): MobileBertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): NoNorm()\n",
       "            (bottleneck): OutputBottleneck(\n",
       "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (bottleneck): Bottleneck(\n",
       "            (input): BottleneckLayer(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "            (attention): BottleneckLayer(\n",
       "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (LayerNorm): NoNorm()\n",
       "            )\n",
       "          )\n",
       "          (ffn): ModuleList(\n",
       "            (0-2): 3 x FFNLayer(\n",
       "              (intermediate): MobileBertIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): ReLU()\n",
       "              )\n",
       "              (output): FFNOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (LayerNorm): NoNorm()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): MobileBertPooler()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileBertConfig {\n",
       "  \"_name_or_path\": \"nlpie/bio-mobilebert\",\n",
       "  \"architectures\": [\n",
       "    \"MobileBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_activation\": false,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"embedding_size\": 128,\n",
       "  \"hidden_act\": \"relu\",\n",
       "  \"hidden_dropout_prob\": 0.0,\n",
       "  \"hidden_size\": 512,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 512,\n",
       "  \"intra_bottleneck_size\": 128,\n",
       "  \"key_query_shared_bottleneck\": true,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"mobilebert\",\n",
       "  \"normalization_type\": \"no_norm\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_feedforward_networks\": 4,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.30.2\",\n",
       "  \"trigram_input\": true,\n",
       "  \"true_hidden_size\": 128,\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_bottleneck\": true,\n",
       "  \"use_bottleneck_attention\": false,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_bert.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", target_modules=[\"key\", \"value\", \"query\"], inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get peft model\n",
    "lora_mobile_bert  = get_peft_model(mobile_bert, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MobileBertForSequenceClassification(\n",
       "      (mobilebert): MobileBertModel(\n",
       "        (embeddings): MobileBertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 512)\n",
       "          (token_type_embeddings): Embedding(2, 512)\n",
       "          (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
       "          (LayerNorm): NoNorm()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (encoder): MobileBertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-23): 24 x MobileBertLayer(\n",
       "              (attention): MobileBertAttention(\n",
       "                (self): MobileBertSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=128, out_features=128, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(\n",
       "                    in_features=128, out_features=128, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=128, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): Linear(\n",
       "                    in_features=512, out_features=128, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=128, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): MobileBertSelfOutput(\n",
       "                  (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  (LayerNorm): NoNorm()\n",
       "                )\n",
       "              )\n",
       "              (intermediate): MobileBertIntermediate(\n",
       "                (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (intermediate_act_fn): ReLU()\n",
       "              )\n",
       "              (output): MobileBertOutput(\n",
       "                (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (LayerNorm): NoNorm()\n",
       "                (bottleneck): OutputBottleneck(\n",
       "                  (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                  (LayerNorm): NoNorm()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (bottleneck): Bottleneck(\n",
       "                (input): BottleneckLayer(\n",
       "                  (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  (LayerNorm): NoNorm()\n",
       "                )\n",
       "                (attention): BottleneckLayer(\n",
       "                  (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  (LayerNorm): NoNorm()\n",
       "                )\n",
       "              )\n",
       "              (ffn): ModuleList(\n",
       "                (0-2): 3 x FFNLayer(\n",
       "                  (intermediate): MobileBertIntermediate(\n",
       "                    (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                    (intermediate_act_fn): ReLU()\n",
       "                  )\n",
       "                  (output): FFNOutput(\n",
       "                    (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                    (LayerNorm): NoNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): MobileBertPooler()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=512, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=512, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_mobile_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longformer models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load longformer \n",
    "\n",
    "longformer = LongformerForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerClassificationHead(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longformer.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148660994"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(longformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592130"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(longformer.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"longformer\" in \"yikuan8/Clinical-Longformer\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at yikuan8/Clinical-Longformer were not used when initializing LongformerForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'longformer.embeddings.position_ids', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "auto_longformer = AutoModelForSequenceClassification.from_pretrained(\"yikuan8/Clinical-Longformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148660994"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(auto_longformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592130"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(auto_longformer.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerClassificationHead(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_longformer.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type=None, target_modules=[\"query\",\"value\",\"key\", \n",
    "                                                         \"query_global\", \n",
    "                                                         \"value_global\",\n",
    "                                                         \"key_global\"] ,inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_longformer = get_peft_model(longformer, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LongformerForSequenceClassification(\n",
       "      (longformer): LongformerModel(\n",
       "        (embeddings): LongformerEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "        )\n",
       "        (encoder): LongformerEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x LongformerLayer(\n",
       "              (attention): LongformerAttention(\n",
       "                (self): LongformerSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (query_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                )\n",
       "                (output): LongformerSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): LongformerIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): LongformerOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): LongformerClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 149,545,730 || trainable%: 0.5916156883917716\n"
     ]
    }
   ],
   "source": [
    "peft_longformer.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(peft_longformer.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze classifier\n",
    "unfreeze_model(peft_longformer.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592130"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(peft_longformer.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,476,866 || all params: 149,545,730 || trainable%: 0.987568150558361\n"
     ]
    }
   ],
   "source": [
    "peft_longformer.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LongformerForSequenceClassification(\n",
       "      (longformer): LongformerModel(\n",
       "        (embeddings): LongformerEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "        )\n",
       "        (encoder): LongformerEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x LongformerLayer(\n",
       "              (attention): LongformerAttention(\n",
       "                (self): LongformerSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (query_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                )\n",
       "                (output): LongformerSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): LongformerIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): LongformerOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): LongformerClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerClassificationHead(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_longformer.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when no task is specified peft library freezes all non-lora weights including the classifier etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a57c6d755b0429a97e69d6e1d5a51c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d6bce44e31432eab757d90e0bccb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9c1d7d6fdc4769b694234daa06d97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create set of inputs to pass to transformer model\n",
    "inputs = tokenizer([\"Hello, my dog is cute\", \"Hello, my cat is cute\"], return_tensors=\"pt\", padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 31414,     6,  ...,     1,     1,     1],\n",
       "        [    0, 31414,     6,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass to model\n",
    "outputs = peft_longformer(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we just load with seq task type? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", target_modules=[\"query\",\"value\",\"key\", \n",
    "                                                         \"query_global\", \n",
    "                                                         \"value_global\",\n",
    "                                                         \"key_global\"] ,inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_long_auto = get_peft_model(auto_longformer, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LongformerForSequenceClassification(\n",
       "      (longformer): LongformerModel(\n",
       "        (embeddings): LongformerEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "        )\n",
       "        (encoder): LongformerEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x LongformerLayer(\n",
       "              (attention): LongformerAttention(\n",
       "                (self): LongformerSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (query_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value_global): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                )\n",
       "                (output): LongformerSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): LongformerIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): LongformerOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): LongformerClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): LongformerClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_long_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,068,996 || all params: 150,137,860 || trainable%: 1.3780641338567101\n"
     ]
    }
   ],
   "source": [
    "lora_long_auto.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModulesToSaveWrapper(\n",
       "  (original_module): LongformerClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       "  (modules_to_save): ModuleDict(\n",
       "    (default): LongformerClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_long_auto.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184260"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(lora_long_auto.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591360"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768*768 + 768*2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 bit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n",
      "- configuration_RW.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n",
      "- modelling_RW.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9fd57bfaae451b98550c51cf81dbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ybelkada/falcon-7b-sharded-bf16 were not used when initializing RWForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing RWForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RWForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RWForSequenceClassification were not initialized from the model checkpoint at ybelkada/falcon-7b-sharded-bf16 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# can you do 8 bit roberta?\n",
    "model_name_or_path = \"ybelkada/falcon-7b-sharded-bf16\" # | roberta-large | ybelkada/falcon-7b-sharded-bf16\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path,num_labels=7, torch_dtype=torch.bfloat16, \n",
    "                                                              load_in_8bit=True, output_hidden_states=False,                                                                \n",
    "                                                                device_map=\"auto\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.word_embeddings.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prepared = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prepared.transformer.word_embeddings.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model_prepared.roberta.encoder.layer[0].attention.self.query.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear8bitLt(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear8bitLt(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear8bitLt(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear8bitLt(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear8bitLt(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear8bitLt(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear8bitLt(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# falcon \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no pad token\n"
     ]
    }
   ],
   "source": [
    "tokenizer\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    print(\"no pad token\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d702e5fc01164d68987727903f0e30a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ybelkada/falcon-7b-sharded-bf16 were not used when initializing RWForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing RWForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RWForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RWForSequenceClassification were not initialized from the model checkpoint at ybelkada/falcon-7b-sharded-bf16 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "falcon_model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path,num_labels=7, torch_dtype=torch.bfloat16, \n",
    "                                                              load_in_8bit=True, output_hidden_states=False,                                                                \n",
    "                                                                device_map=\"auto\", trust_remote_code = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RWForSequenceClassification(\n",
       "  (transformer): RWModel(\n",
       "    (word_embeddings): Embedding(65024, 4544)\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x DecoderLayer(\n",
       "        (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): Attention(\n",
       "          (maybe_rotary): RotaryEmbedding()\n",
       "          (query_key_value): Linear8bitLt(in_features=4544, out_features=4672, bias=False)\n",
       "          (dense): Linear8bitLt(in_features=4544, out_features=4544, bias=False)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): MLP(\n",
       "          (dense_h_to_4h): Linear8bitLt(in_features=4544, out_features=18176, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (dense_4h_to_h): Linear8bitLt(in_features=18176, out_features=4544, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=4544, out_features=7, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falcon_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "falcon_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falcon_model.config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1d32496bf54e3686fecef02280e58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at decapoda-research/llama-7b-hf were not used when initializing LlamaForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at decapoda-research/llama-7b-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 8 bit llama\n",
    "llama_model = LlamaForSequenceClassification.from_pretrained(model_name_or_path, num_labels=7, torch_dtype=torch.bfloat16, \n",
    "                                                              load_in_8bit=True, output_hidden_states=False,                                                                \n",
    "                                                                device_map=\"auto\",\n",
    "                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16bit\n",
    "# llama_model = LlamaForSequenceClassification.from_pretrained(model_name_or_path, num_labels=7, torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (score): Linear(in_features=4096, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForSequenceClassification(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (score): Linear(in_features=4096, out_features=7, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", output_hidden_states=True)\n",
    "# custom_model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['roberta.embeddings.position_ids', 'roberta.embeddings.word_embeddings.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for p in roberta_model.parameters():\n",
    "    print(p.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"roberta-base\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.27.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['roberta.embeddings.position_ids', 'roberta.embeddings.word_embeddings.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"/mnt/sdc/niallt/saved_models/declutr/mimic/few_epoch/mimic-roberta-base/2_anch_2_pos_min_1024/transformer_format/\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.27.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for p in custom_model.parameters():\n",
    "    print(p.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761365d64da44b13b8182f80716e95db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac81ba4c83314027a2f1cd2fed7413a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "# custom_tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "llama_tokenizer = LlamaTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaTokenizerFast(name_or_path='/mnt/sdc/niallt/saved_models/declutr/mimic/few_epoch/mimic-roberta-base/2_anch_2_pos_min_1024/transformer_format/', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peft_config = LoraConfig(task_type=\"SEQ_CLS\", inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)\n",
    "# lr = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(params=roberta_model.parameters(), lr=0.001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_optimizer = AdamW(params=custom_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to load different peft setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_peft_model(model_name_or_path,                     \n",
    "                     peft_method,\n",
    "                     task_type,                     \n",
    "                     device,\n",
    "                     num_virtual_tokens= 20,\n",
    "                     num_labels = 7):\n",
    "    '''\n",
    "    Function to setup the peft model for training and return a peft model based on the peft method specified.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if peft_method == \"LORA\":\n",
    "        loguru_logger.info(\"Using LORA\")\n",
    "        peft_type = PeftType.LORA\n",
    "        lr = 3e-4\n",
    "        peft_config = LoraConfig(task_type=task_type, inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)\n",
    "    elif peft_method == \"PREFIX_TUNING\":\n",
    "        loguru_logger.info(\"Using PREFIX_TUNING\")\n",
    "        peft_type = PeftType.PREFIX_TUNING\n",
    "        peft_config = PrefixTuningConfig(task_type=task_type, num_virtual_tokens=20)\n",
    "        lr = 1e-2\n",
    "    elif peft_method == \"PROMPT_TUNING\":\n",
    "        loguru_logger.info(\"Using PROMPT_TUNING\")\n",
    "        peft_type = PeftType.PROMPT_TUNING\n",
    "        peft_config = PromptTuningConfig(task_type=task_type, num_virtual_tokens=10)\n",
    "        lr = 1e-3\n",
    "    elif peft_method == \"P_TUNING\":\n",
    "        loguru_logger.info(\"Using P_TUNING\")\n",
    "        peft_type = PeftType.P_TUNING\n",
    "        peft_config = PromptEncoderConfig(task_type=task_type, num_virtual_tokens=20, encoder_hidden_size=128)\n",
    "        lr = 1e-3\n",
    "        \n",
    "\n",
    "    # load peft model\n",
    "    if \"llama\" in model_name_or_path:\n",
    "        loguru_logger.info(\"Loading LLAMA model in 8 bit\")\n",
    "        # model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path,\n",
    "        #                                                            torch_dtype=torch.bfloat16,\n",
    "        #                                                            num_labels = num_labels,return_dict=True)\n",
    "        # 8 bit\n",
    "        model = LlamaForSequenceClassification.from_pretrained(model_name_or_path, num_labels=num_labels, torch_dtype=torch.float16, \n",
    "                                                              load_in_8bit=True, output_hidden_states=False,                                                                \n",
    "                                                                device_map=\"auto\",\n",
    "                                                                )\n",
    "    else:\n",
    "        \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels = num_labels,return_dict=True)\n",
    "        model.to(device)\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    # setup optimizer and lr_scheduler\n",
    "    optimizer = AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "    # Instantiate scheduler\n",
    "    lr_scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0.06 * (len(train_dataloader) * num_epochs),\n",
    "        num_training_steps=(len(train_dataloader) * num_epochs),\n",
    "    )\n",
    "    return model, peft_config, optimizer, lr_scheduler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup task and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of various datasets and their sentence keys\n",
    "task_to_keys ={\n",
    "                \"cola\": (\"sentence\", None),\n",
    "                \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "                \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "                \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "                \"qnli\": (\"question\", \"sentence\"),\n",
    "                \"qqp\": (\"question1\", \"question2\"),\n",
    "                \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "                \"sst2\": (\"sentence\", None),\n",
    "                \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "                \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "                \"mimic-note-category\": (\"TEXT\", None),\n",
    "                \"icd9-triage\":(\"text\", None),\n",
    "                \"icd9-triage-no-category-in-text\":(\"text\", None),\n",
    "                \"mednli\":(\"sentence1\", \"sentence2\")\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task for now is icd9-triage\n",
    "task = \"mednli\"\n",
    "\n",
    "# task = \"mrpc\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets.yaml', 'r') as f:\n",
    "    datasets = yaml.load(f, yaml.FullLoader)\n",
    "\n",
    "try:\n",
    "    dataset_info = datasets[task]\n",
    "\n",
    "except KeyError:\n",
    "    print(f\"Task name {task} not in datasets.yaml. Available tasks are: {list(datasets.keys())}\")\n",
    "    exit(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_data_dir': '',\n",
       " 'eval_data_dir': '',\n",
       " 'data_dir': '/mnt/sdd/efficient_ml_data/datasets/MedNLI',\n",
       " 'training_file': '',\n",
       " 'validation_file': '',\n",
       " 'test_file': '',\n",
       " 'task_type': 'SEQ_CLS',\n",
       " 'label_name': '',\n",
       " 'text_column': ['sentence1 sentence2'],\n",
       " 'remove_columns': ['sentence1 sentence2']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_from_disk(dataset_info[\"data_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load dataset\n",
    "\n",
    "# training_data_dir = \"/mnt/sdc/niallt/mimic_iii/processed/HADM_ID_split/icd9-triage/no_category_in_text/fewshot_64/\"\n",
    "# eval_data_dir = \"/mnt/sdc/niallt/mimic_iii/processed/HADM_ID_split/icd9-triage/no_category_in_text/\"\n",
    "# datasets = load_dataset(\"csv\", \n",
    "#                         data_files = {\"train\":f\"{training_data_dir}/train.csv\",\n",
    "#                                         \"validation\":f\"{eval_data_dir}/valid.csv\",\n",
    "#                                         \"test\":f\"{eval_data_dir}/test.csv\"},\n",
    "#                         cache_dir = \"/mnt/sdc/niallt/.cache/\")\n",
    "\n",
    "# loguru_logger.info(f\"Number of training samples: {len(datasets['train'])}\\n and validation samples:{len(datasets['validation'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of labels\n",
    "num_labels = len(np.unique(datasets[\"train\"][\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets[\"train\"])/batch_size * num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_training_steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-process/encode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1_key, sentence2_key = task_to_keys[task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mnt/sdd/efficient_ml_data/datasets/MedNLI/train/cache-c9adf01eef7de685.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4d318ae9654dbf8b11c198baec3c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1395 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mnt/sdd/efficient_ml_data/datasets/MedNLI/test/cache-1c451bd3938b5117.arrow\n"
     ]
    }
   ],
   "source": [
    "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
    "    padding_side = \"left\"\n",
    "else:\n",
    "    padding_side = \"right\"\n",
    "\n",
    "if \"llama\" in model_name_or_path:\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "# set the sentence/task keys\n",
    "# sentence1_key, sentence2_key = task_to_keys[task]\n",
    "\n",
    "# for glue\n",
    "# def tokenize_function(examples):\n",
    "#     # max_length=None => use the model max length (it's actually the default)\n",
    "#     outputs = tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True, max_length=480)\n",
    "#     return outputs\n",
    "\n",
    "# own\n",
    "def tokenize_function(examples):\n",
    "    # max_length is important when using prompt tuning  or prefix tuning or p tuning as virtual tokens are added - which can overshoot the max length in pefts current form\n",
    "    # for now set to 480 and see how it goes\n",
    "    if sentence2_key is None:\n",
    "        return tokenizer(examples[sentence1_key], truncation=True, max_length = 480)\n",
    "    return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True, max_length=480)\n",
    "\n",
    "# own\n",
    "tokenized_datasets = datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=['sentence1', 'sentence2'], # remove_columns=['text', 'triage-category']\n",
    ")\n",
    "\n",
    "# for glue\n",
    "# tokenized_datasets = datasets.map(\n",
    "#     tokenize_function,\n",
    "#     batched=True,\n",
    "#     remove_columns=[\"idx\", \"sentence1\", \"sentence2\"],\n",
    "# )\n",
    "# We also rename the 'label' column to 'labels' which is the expected name for labels by the models of the\n",
    "# transformers library\n",
    "# tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "\n",
    "def collate_fn(examples):\n",
    "    return tokenizer.pad(examples, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "# Instantiate dataloaders.\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, collate_fn=collate_fn, batch_size=batch_size)\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], shuffle=False, collate_fn=collate_fn, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 2,\n",
       " 'input_ids': [0,\n",
       "  574,\n",
       "  10155,\n",
       "  58,\n",
       "  8091,\n",
       "  13,\n",
       "  5309,\n",
       "  112,\n",
       "  4,\n",
       "  406,\n",
       "  36,\n",
       "  15609,\n",
       "  7012,\n",
       "  321,\n",
       "  4,\n",
       "  245,\n",
       "  228,\n",
       "  793,\n",
       "  2189,\n",
       "  43,\n",
       "  8,\n",
       "  36149,\n",
       "  877,\n",
       "  132,\n",
       "  4,\n",
       "  306,\n",
       "  4,\n",
       "  2,\n",
       "  2,\n",
       "  27690,\n",
       "  34,\n",
       "  10944,\n",
       "  5309,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Labs were notable for Cr 1.7 (baseline 0.5 per old records) and lactate 2.4.</s></s> Patient has elevated Cr</s>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use tokenizer to decode a sample\n",
    "\n",
    "tokenizer.decode(train_dataloader.dataset[0][\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "# run through dataloader and check that the labels are correct\n",
    "for batch in train_dataloader:\n",
    "    # print length of input ids\n",
    "    print(len(batch[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "        precision_score = evaluate.load(\"precision\")\n",
    "        recall_score = evaluate.load(\"recall\")\n",
    "        accuracy_score = evaluate.load(\"accuracy\")\n",
    "        f1_score = evaluate.load(\"f1\")        \n",
    "        roc_auc_score = evaluate.load(\"roc_auc\", \"multiclass\")        \n",
    "\n",
    "        logits, labels = eval_pred\n",
    "        \n",
    "        # print(f\"logits are: {logits} of shape: {logits.shape}\")\n",
    "        #TODO add softmax to convert logits to probs\n",
    "        # print(f\"logits shape is: {logits.shape}\")\n",
    "        pred_scores = softmax(logits, axis = -1)        \n",
    "        predictions = np.argmax(logits, axis = -1)\n",
    "        \n",
    "        # print(f\"Labels are: {labels}\\n\")\n",
    "        # print(f\"Preds are: {predictions}\")\n",
    "        precision = precision_score.compute(predictions=predictions, references=labels, average = \"macro\")[\"precision\"]\n",
    "        recall = recall_score.compute(predictions=predictions, references=labels, average = \"macro\")[\"recall\"]\n",
    "        accuracy = accuracy_score.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "        f1_macro = f1_score.compute(predictions=predictions, references=labels, average = \"macro\")[\"f1\"]\n",
    "        f1_micro = f1_score.compute(predictions=predictions, references=labels, average = \"micro\")[\"f1\"]\n",
    "        f1_weighted = f1_score.compute(predictions=predictions, references=labels, average = \"weighted\")[\"f1\"]\n",
    "        # roc_auc has slightly different format - needs the probs/scores rather than predicted labels\n",
    "        roc_auc = roc_auc_score.compute(references=labels,\n",
    "                                        prediction_scores = pred_scores,\n",
    "                                        multi_class = 'ovr', \n",
    "                                        average = \"macro\")['roc_auc']\n",
    "        \n",
    "        return {\"precision\": precision, \n",
    "                \"recall\": recall,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"f1_macro\":f1_macro,\n",
    "                \"f1_micro\":f1_micro,\n",
    "                \"f1_weighted\":f1_weighted,\n",
    "                \"roc_auc_macro\":roc_auc}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup PEFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 15:54:44.832 | INFO     | __main__:setup_peft_model:13 - Using LORA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf1eeabaa1a4f38b2bf6d55a019a2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at decapoda-research/llama-7b-hf were not used when initializing LlamaForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlamaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at decapoda-research/llama-7b-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,251,648 || all params: 6,611,595,264 || trainable%: 0.06430593268692861\n"
     ]
    }
   ],
   "source": [
    "model, peft_config, optimizer, lr_scheduler = setup_peft_model(model_name_or_path, peft_method = \"LORA\", task_type = \"SEQ_CLS\", device = \"cuda\", num_labels = num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 13:53:51.951 | INFO     | __main__:setup_peft_model:13 - Using LORA\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1486862 || all params: 125541902 || trainable%: 1.1843551645409993\n"
     ]
    }
   ],
   "source": [
    "# roberta_model, peft_config, optimizer, lr_scheduler = setup_peft_model(\"roberta-base\", peft_method = \"LORA\", task_type = \"SEQ_CLS\", device = \"cuda\", num_labels = num_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros: tensor(149774, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Count the number of zeros in each parameter tensor\n",
    "num_zeros = 0\n",
    "for param in model.parameters():\n",
    "    num_zeros += torch.numel(param) - torch.count_nonzero(param)\n",
    "print(\"Number of zeros:\", num_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros: tensor(150612, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Count the number of zeros in each parameter tensor\n",
    "num_zeros = 0\n",
    "for param in roberta_model.parameters():\n",
    "    num_zeros += torch.numel(param) - torch.count_nonzero(param)\n",
    "print(\"Number of zeros:\", num_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros: tensor(149774, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Count the number of zeros in each parameter tensor\n",
    "num_zeros = 0\n",
    "for param in declutr_model.parameters():\n",
    "    num_zeros += torch.numel(param) - torch.count_nonzero(param)\n",
    "print(\"Number of zeros:\", num_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                                                      Param #\n",
       "====================================================================================================\n",
       "PeftModelForSequenceClassification                                          --\n",
       "├─LoraModel: 1-1                                                            --\n",
       "│    └─RobertaForSequenceClassification: 2-1                                --\n",
       "│    │    └─RobertaModel: 3-1                                               124,349,952\n",
       "│    │    └─ModulesToSaveWrapper: 3-2                                       1,191,950\n",
       "====================================================================================================\n",
       "Total params: 125,541,902\n",
       "Trainable params: 1,486,862\n",
       "Non-trainable params: 124,055,040\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "====================================================================================================\n",
    "Layer (type:depth-idx)                                                      Param #\n",
    "====================================================================================================\n",
    "PeftModelForSequenceClassification                                          --\n",
    "├─LoraModel: 1-1                                                            --\n",
    "│    └─RobertaForSequenceClassification: 2-1                                --\n",
    "│    │    └─RobertaModel: 3-1                                               124,349,952\n",
    "│    │    └─ModulesToSaveWrapper: 3-2                                       1,191,950\n",
    "====================================================================================================\n",
    "Total params: 125,541,902\n",
    "Trainable params: 1,486,862\n",
    "Non-trainable params: 124,055,040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable params: 1486862 || all params: 125541902 || trainable%: 1.1843551645409993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1983452398406846"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "294912/1486862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, base_model_name_or_path='roberta-base', task_type='SEQ_CLS', inference_mode=False, r=8, target_modules=['query', 'value'], lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train PEFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForSequenceClassification(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=4096, out_features=7, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=4096, out_features=7, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### debugging - custom roberta model leads to weird memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "predictions:tensor([1, 5, 5, 4], device='cuda:0')\n",
      "references:tensor([0, 1, 1, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for batch in eval_dataloader:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch.to(device))\n",
    "    predictions = outputs.logits.argmax(dim=-1)\n",
    "    predictions, references = predictions, batch[\"labels\"]\n",
    "    print(batch.keys())\n",
    "    # print(f\"outputs:{outputs}\")\n",
    "    print(f\"predictions:{predictions}\")\n",
    "    print(f\"references:{references}\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(2.0110, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.0555, -0.0210, -0.1128,  0.0344,  0.1020, -0.0508, -0.0510],\n",
       "        [-0.0573, -0.0200, -0.1036,  0.0467,  0.1004, -0.0551, -0.0567],\n",
       "        [-0.0556, -0.0172, -0.1156,  0.0369,  0.0998, -0.0592, -0.0500],\n",
       "        [-0.0651, -0.0201, -0.1072,  0.0478,  0.0974, -0.0566, -0.0518]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(2.0342, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.1482, -0.0124, -0.0138,  0.2247,  0.0693, -0.3117,  0.2074],\n",
       "        [-0.0756,  0.0031, -0.0501,  0.1328,  0.0983, -0.2762,  0.2746],\n",
       "        [-0.0222,  0.0371, -0.0096,  0.2350,  0.1343, -0.2727,  0.1959],\n",
       "        [-0.0484, -0.0302, -0.0769,  0.1806, -0.0051, -0.2624,  0.1530]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=(tensor([[[ 0.1712, -0.0483, -0.0230,  ..., -0.0518,  0.0839,  0.0430],\n",
       "         [ 0.0998, -0.1730, -0.0247,  ..., -0.1891, -0.0604,  0.0077],\n",
       "         [-0.1805, -0.3721, -0.0325,  ..., -0.2030, -0.2124,  0.0519],\n",
       "         ...,\n",
       "         [-0.2720,  0.0421,  0.2390,  ..., -0.5429,  0.1871, -0.1404],\n",
       "         [ 0.2573, -0.1542,  0.0187,  ..., -0.9629,  0.0768,  0.2467],\n",
       "         [-0.0058, -0.2664, -0.1019,  ...,  0.3818,  0.1682,  0.1829]],\n",
       "\n",
       "        [[ 0.1712, -0.0483, -0.0230,  ..., -0.0518,  0.0839,  0.0430],\n",
       "         [ 0.0998, -0.1730, -0.0247,  ..., -0.1891, -0.0604,  0.0077],\n",
       "         [-0.1805, -0.3721, -0.0325,  ..., -0.2030, -0.2124,  0.0519],\n",
       "         ...,\n",
       "         [-0.2097, -0.3274,  0.2702,  ...,  0.1441,  0.2568,  0.0109],\n",
       "         [ 0.2086,  0.5350,  0.6377,  ..., -0.0962,  0.0451,  0.0018],\n",
       "         [-0.0058, -0.2664, -0.1019,  ...,  0.3818,  0.1682,  0.1829]],\n",
       "\n",
       "        [[ 0.1712, -0.0483, -0.0230,  ..., -0.0518,  0.0839,  0.0430],\n",
       "         [ 0.0998, -0.1730, -0.0247,  ..., -0.1891, -0.0604,  0.0077],\n",
       "         [-0.1805, -0.3721, -0.0325,  ..., -0.2030, -0.2124,  0.0519],\n",
       "         ...,\n",
       "         [-0.1175, -0.1669,  0.1918,  ...,  0.0619,  0.0245, -0.1847],\n",
       "         [ 0.0338, -0.4038, -0.0889,  ..., -0.3330, -0.0938,  0.0060],\n",
       "         [-0.0058, -0.2664, -0.1019,  ...,  0.3818,  0.1682,  0.1829]],\n",
       "\n",
       "        [[ 0.1712, -0.0483, -0.0230,  ..., -0.0518,  0.0839,  0.0430],\n",
       "         [ 0.0998, -0.1730, -0.0247,  ..., -0.1891, -0.0604,  0.0077],\n",
       "         [-0.1805, -0.3721, -0.0325,  ..., -0.2030, -0.2124,  0.0519],\n",
       "         ...,\n",
       "         [ 0.0581, -0.1827, -0.1092,  ..., -0.3845,  0.0741, -0.1307],\n",
       "         [ 0.1218, -0.5385, -0.0160,  ...,  0.2719, -0.8401,  0.5507],\n",
       "         [-0.0058, -0.2664, -0.1019,  ...,  0.3818,  0.1682,  0.1829]]],\n",
       "       device='cuda:0'), tensor([[[ 0.0266, -0.0183,  0.0226,  ..., -0.0470,  0.0279, -0.1413],\n",
       "         [ 0.7323, -0.0684, -0.2277,  ..., -0.0679, -0.2408,  0.3948],\n",
       "         [ 0.1194, -0.8336, -0.3854,  ..., -0.3688, -0.5647,  0.4122],\n",
       "         ...,\n",
       "         [-0.0295, -0.1339,  0.2329,  ..., -1.1826,  0.1676, -0.3673],\n",
       "         [ 0.2965, -0.3175,  0.0475,  ..., -0.8617, -0.1269,  0.3743],\n",
       "         [-0.6358,  0.0322,  0.0531,  ...,  0.3302, -0.0740,  0.1952]],\n",
       "\n",
       "        [[ 0.0303, -0.0222,  0.0138,  ..., -0.0474,  0.0220, -0.1401],\n",
       "         [ 0.6678, -0.0404, -0.1844,  ..., -0.1214, -0.2659,  0.3617],\n",
       "         [ 0.0596, -0.7457, -0.3503,  ..., -0.3038, -0.6008,  0.3613],\n",
       "         ...,\n",
       "         [-0.0030, -0.4433,  0.3480,  ..., -0.0401,  0.5283, -0.2611],\n",
       "         [ 0.4993,  1.2664,  0.8888,  ..., -0.2329,  0.2774, -0.4313],\n",
       "         [-0.5244, -0.0666,  0.0281,  ...,  0.3130,  0.0643,  0.0481]],\n",
       "\n",
       "        [[ 0.0312, -0.0185,  0.0239,  ..., -0.0476,  0.0206, -0.1396],\n",
       "         [ 0.7046, -0.0233, -0.1864,  ..., -0.0691, -0.2736,  0.4682],\n",
       "         [ 0.1767, -0.8106, -0.3678,  ..., -0.3029, -0.5620,  0.4151],\n",
       "         ...,\n",
       "         [ 0.1061, -0.6260, -0.2030,  ..., -0.0800,  0.1122, -0.0906],\n",
       "         [ 0.0156, -0.6508,  0.2366,  ..., -0.3733, -0.3156,  0.4479],\n",
       "         [-0.4355, -0.0773, -0.0132,  ...,  0.3110, -0.0291,  0.0852]],\n",
       "\n",
       "        [[ 0.0329, -0.0212,  0.0261,  ..., -0.0436,  0.0156, -0.1299],\n",
       "         [ 0.7559, -0.0049, -0.1947,  ..., -0.0397, -0.2475,  0.4408],\n",
       "         [ 0.1648, -0.8419, -0.3752,  ..., -0.2754, -0.5540,  0.4090],\n",
       "         ...,\n",
       "         [ 0.3755, -0.2268, -0.2233,  ..., -0.1891,  0.0449,  0.1021],\n",
       "         [ 0.3526, -0.8990,  0.0121,  ...,  0.4529, -1.2892,  1.2771],\n",
       "         [-0.3810,  0.0097,  0.1224,  ...,  0.3566, -0.0115,  0.1439]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0689,  0.0070,  0.0441,  ...,  0.0143,  0.0442, -0.0497],\n",
       "         [ 0.5191, -0.1454, -0.2387,  ...,  0.1558, -0.5789,  0.5470],\n",
       "         [ 0.0837, -0.8679, -0.2341,  ..., -0.2964, -0.7411,  0.5421],\n",
       "         ...,\n",
       "         [ 0.2520, -0.1139,  0.4221,  ..., -1.5155,  0.2572, -0.3989],\n",
       "         [-0.2664,  0.0746,  0.1572,  ..., -0.6143, -0.2336,  0.2225],\n",
       "         [-0.5096,  0.2834,  0.2533,  ...,  0.5363,  0.3496,  0.4659]],\n",
       "\n",
       "        [[ 0.0715,  0.0100,  0.0420,  ...,  0.0050,  0.0493, -0.0576],\n",
       "         [ 0.5085, -0.0621, -0.2482,  ...,  0.0812, -0.5425,  0.5431],\n",
       "         [ 0.1147, -0.8768, -0.0555,  ..., -0.2742, -0.7695,  0.5062],\n",
       "         ...,\n",
       "         [ 0.0961, -0.4087,  0.2188,  ..., -0.4123,  0.5325, -0.1047],\n",
       "         [ 0.4908,  1.5552,  0.7788,  ..., -1.2737,  0.3759, -0.2535],\n",
       "         [-0.4357,  0.1588,  0.2271,  ...,  0.5161,  0.3326,  0.2792]],\n",
       "\n",
       "        [[ 0.0566, -0.0087,  0.0461,  ...,  0.0078,  0.0394, -0.0573],\n",
       "         [ 0.4967, -0.1478, -0.1599,  ...,  0.0954, -0.5346,  0.5979],\n",
       "         [ 0.1895, -0.8428, -0.1251,  ..., -0.2910, -0.7579,  0.5128],\n",
       "         ...,\n",
       "         [ 0.3105, -0.6041, -0.0093,  ..., -0.1796, -0.1528,  0.2044],\n",
       "         [ 0.2661, -0.7101,  0.3244,  ..., -0.3433, -0.2251,  0.3180],\n",
       "         [-0.4708,  0.0930,  0.2542,  ...,  0.4450,  0.3021,  0.3112]],\n",
       "\n",
       "        [[ 0.0735,  0.0279,  0.0412,  ...,  0.0146,  0.0436, -0.0619],\n",
       "         [ 0.5847, -0.2176, -0.2296,  ...,  0.1573, -0.5229,  0.4669],\n",
       "         [ 0.2027, -0.8637, -0.2009,  ..., -0.2402, -0.6588,  0.4709],\n",
       "         ...,\n",
       "         [ 0.3734, -0.6683,  0.0307,  ..., -0.1150, -0.3139,  0.2051],\n",
       "         [-0.0371, -1.3621, -0.0310,  ...,  0.7322, -0.8900,  0.9141],\n",
       "         [-0.3280,  0.2318,  0.3352,  ...,  0.5411,  0.3552,  0.3557]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 8.4426e-02,  2.8092e-02,  5.4468e-02,  ...,  7.0186e-02,\n",
       "           1.6382e-02, -6.0602e-02],\n",
       "         [ 1.9033e-01,  1.9446e-01, -1.0785e-01,  ..., -8.3040e-03,\n",
       "          -2.4663e-01,  1.6006e-01],\n",
       "         [ 1.2427e-01, -6.7594e-01, -4.8281e-01,  ..., -9.7735e-02,\n",
       "          -3.0454e-01,  4.2236e-01],\n",
       "         ...,\n",
       "         [ 6.0129e-01,  5.2061e-02,  1.7752e-01,  ..., -1.2854e+00,\n",
       "           4.4943e-01,  1.8361e-02],\n",
       "         [ 1.0377e-01,  7.1123e-02,  2.6853e-01,  ..., -4.5236e-01,\n",
       "          -1.5842e-01,  2.0573e-01],\n",
       "         [ 5.4656e-03,  2.6727e-01,  1.2495e-01,  ...,  4.8198e-01,\n",
       "           3.3929e-03,  4.7976e-01]],\n",
       "\n",
       "        [[ 7.7897e-02,  3.1812e-02,  6.9761e-02,  ...,  5.9715e-02,\n",
       "           3.1596e-02, -6.5110e-02],\n",
       "         [ 1.4983e-01,  1.4753e-01, -1.0663e-01,  ...,  3.0120e-02,\n",
       "          -3.8723e-01,  1.6768e-01],\n",
       "         [ 1.7142e-01, -7.8199e-01, -3.3088e-01,  ...,  7.7460e-02,\n",
       "          -4.5483e-01,  4.8176e-01],\n",
       "         ...,\n",
       "         [-4.7154e-01, -8.8890e-02,  3.8556e-01,  ..., -5.1650e-01,\n",
       "           4.4898e-01, -3.4425e-01],\n",
       "         [-5.0395e-01,  1.4709e+00,  5.1013e-01,  ..., -1.3707e+00,\n",
       "           3.5271e-01, -7.7989e-04],\n",
       "         [-1.6232e-01,  1.3514e-01,  2.1151e-01,  ...,  4.6634e-01,\n",
       "           1.3938e-02,  2.6704e-01]],\n",
       "\n",
       "        [[ 6.3145e-02,  7.6183e-03,  7.8755e-02,  ...,  3.7372e-02,\n",
       "           1.0361e-02, -4.9815e-02],\n",
       "         [ 1.1678e-01,  1.0505e-01, -3.1264e-02,  ..., -1.3323e-02,\n",
       "          -1.7706e-01,  3.0897e-01],\n",
       "         [ 1.4113e-01, -7.5080e-01, -4.1681e-01,  ..., -8.3520e-02,\n",
       "          -3.2725e-01,  5.2990e-01],\n",
       "         ...,\n",
       "         [ 5.2416e-01, -3.3018e-01,  2.4757e-01,  ..., -3.9594e-01,\n",
       "          -7.6063e-01,  1.9301e-01],\n",
       "         [-5.7127e-02, -8.9627e-01,  4.0288e-01,  ..., -5.5673e-01,\n",
       "          -3.3693e-01,  1.3507e-01],\n",
       "         [-1.3547e-01,  1.4972e-01,  3.7383e-01,  ...,  3.3322e-01,\n",
       "          -1.7691e-01,  2.6169e-01]],\n",
       "\n",
       "        [[ 8.3911e-02,  3.2985e-02,  7.0859e-02,  ...,  6.2557e-02,\n",
       "           3.6558e-02, -5.7907e-02],\n",
       "         [ 1.3890e-01,  6.4416e-02,  4.6955e-02,  ..., -2.5258e-02,\n",
       "          -2.5109e-01,  2.5990e-01],\n",
       "         [ 1.8165e-01, -7.8058e-01, -3.6653e-01,  ..., -4.4319e-02,\n",
       "          -1.1436e-01,  5.3255e-01],\n",
       "         ...,\n",
       "         [ 1.2036e-01, -5.5646e-01,  5.9343e-01,  ..., -2.9635e-01,\n",
       "          -2.0279e-01,  4.1090e-01],\n",
       "         [ 1.9428e-01, -1.2220e+00,  2.9549e-01,  ...,  7.9631e-01,\n",
       "          -5.4757e-01,  7.3539e-01],\n",
       "         [-9.4948e-02,  3.6587e-01,  4.3374e-01,  ...,  4.9648e-01,\n",
       "          -1.0835e-01,  4.0826e-01]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-4.0383e-02,  5.8217e-02, -1.9119e-02,  ...,  4.3777e-02,\n",
       "          -4.9207e-02, -6.3465e-02],\n",
       "         [-8.3827e-02, -1.0736e-01, -2.5192e-01,  ..., -6.4802e-02,\n",
       "           5.6631e-03,  1.4622e-01],\n",
       "         [-1.2293e-01, -9.6212e-01, -4.1244e-01,  ..., -1.5250e-01,\n",
       "          -6.2958e-01, -1.3514e-01],\n",
       "         ...,\n",
       "         [-4.1948e-02, -3.3058e-01,  2.8094e-01,  ..., -1.1770e+00,\n",
       "           5.0410e-01,  3.6965e-02],\n",
       "         [ 1.4428e-02, -4.0158e-02, -3.5958e-02,  ..., -4.7659e-01,\n",
       "          -1.1652e-02,  2.2096e-01],\n",
       "         [-2.8226e-01, -1.4444e-01, -3.3402e-01,  ...,  3.2754e-01,\n",
       "           1.4087e-01,  6.2506e-01]],\n",
       "\n",
       "        [[-4.9260e-02,  4.9843e-02, -1.3001e-02,  ...,  3.4380e-02,\n",
       "          -1.2267e-02, -6.0515e-02],\n",
       "         [-2.0145e-01, -1.5034e-01, -2.6453e-01,  ..., -1.8686e-02,\n",
       "          -1.0834e-01,  4.8450e-02],\n",
       "         [ 3.9092e-02, -9.8640e-01, -4.0374e-01,  ..., -7.0195e-02,\n",
       "          -7.4434e-01, -2.6197e-01],\n",
       "         ...,\n",
       "         [-6.3434e-01, -4.4986e-01,  5.7599e-01,  ..., -6.1555e-01,\n",
       "           3.7046e-01, -1.7315e-01],\n",
       "         [-5.9209e-01,  1.3520e+00,  2.2267e-01,  ..., -1.5719e+00,\n",
       "           5.4102e-01,  7.4431e-02],\n",
       "         [-3.6481e-01, -3.1280e-01, -2.3585e-01,  ...,  2.7552e-01,\n",
       "           1.0043e-01,  4.2600e-01]],\n",
       "\n",
       "        [[-8.2389e-02,  2.7986e-02, -2.5746e-02,  ...,  1.8564e-02,\n",
       "          -4.6991e-02, -5.1760e-02],\n",
       "         [-2.0051e-01, -2.3945e-01, -2.3043e-01,  ..., -7.9743e-02,\n",
       "           5.2609e-02,  1.7664e-01],\n",
       "         [ 1.0503e-01, -1.1060e+00, -3.3243e-01,  ..., -9.2095e-02,\n",
       "          -6.2586e-01, -4.0180e-02],\n",
       "         ...,\n",
       "         [ 6.9852e-02, -5.2001e-01, -1.6400e-01,  ..., -4.7743e-01,\n",
       "          -5.1104e-01,  2.6599e-01],\n",
       "         [-1.1893e-01, -9.4737e-01, -2.1178e-01,  ..., -4.7595e-01,\n",
       "          -1.5111e-01, -4.1781e-03],\n",
       "         [-2.5013e-01, -2.3911e-01, -1.2230e-01,  ...,  1.3933e-01,\n",
       "          -2.3338e-01,  4.1139e-01]],\n",
       "\n",
       "        [[-9.6117e-02,  3.3484e-02,  3.3583e-04,  ...,  4.7325e-02,\n",
       "          -1.0489e-02, -4.8729e-02],\n",
       "         [-1.1983e-01, -3.1227e-01, -2.1094e-01,  ..., -6.8321e-03,\n",
       "          -4.5459e-02,  1.7615e-01],\n",
       "         [ 1.3393e-02, -1.0250e+00, -3.1129e-01,  ..., -5.9213e-02,\n",
       "          -4.9694e-01, -2.7043e-02],\n",
       "         ...,\n",
       "         [ 2.6110e-01, -4.6020e-01,  2.7039e-02,  ..., -4.2121e-01,\n",
       "          -4.1198e-01,  4.1709e-01],\n",
       "         [-1.7738e-01, -1.2634e+00,  2.4544e-01,  ...,  5.6751e-01,\n",
       "          -5.2401e-01,  8.0776e-01],\n",
       "         [-2.4295e-01,  1.3399e-01,  1.1778e-01,  ...,  3.7028e-01,\n",
       "          -2.8465e-03,  5.2703e-01]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0159,  0.0651,  0.0423,  ...,  0.1560, -0.0291, -0.0374],\n",
       "         [-0.1343, -0.2533,  0.0592,  ...,  0.0834,  0.0114,  0.0589],\n",
       "         [ 0.2658, -1.3150, -0.1270,  ..., -0.2518, -0.7060, -0.1099],\n",
       "         ...,\n",
       "         [-0.5085, -0.4000,  0.2769,  ..., -1.0359,  1.0428, -0.0813],\n",
       "         [ 0.0033,  0.1675,  0.1643,  ..., -0.2823,  0.1061, -0.0853],\n",
       "         [-0.0396, -0.0874, -0.5663,  ...,  0.4393,  0.4108,  0.2631]],\n",
       "\n",
       "        [[ 0.0276,  0.0653,  0.0543,  ...,  0.1483, -0.0048, -0.0313],\n",
       "         [ 0.1110, -0.2660,  0.0032,  ...,  0.2543,  0.1759,  0.1242],\n",
       "         [ 0.2764, -1.1983, -0.3717,  ..., -0.1786, -0.6483, -0.1365],\n",
       "         ...,\n",
       "         [-0.3731, -0.5151,  0.1422,  ..., -0.5719,  0.7325,  0.0800],\n",
       "         [-0.1321,  0.9328,  0.4495,  ..., -1.4071,  0.5834,  0.0549],\n",
       "         [-0.0225, -0.3806, -0.3346,  ...,  0.4548,  0.2293,  0.4567]],\n",
       "\n",
       "        [[-0.0224,  0.0434,  0.0910,  ...,  0.1150, -0.0337, -0.0088],\n",
       "         [-0.1045, -0.3654,  0.1898,  ...,  0.0264,  0.0977,  0.1417],\n",
       "         [ 0.2514, -1.4829,  0.0241,  ..., -0.1916, -0.6476,  0.0626],\n",
       "         ...,\n",
       "         [ 0.4708, -0.5085, -0.4762,  ..., -0.8562, -0.2719, -0.0076],\n",
       "         [ 0.1147, -0.6638, -0.2340,  ..., -0.2820,  0.2226, -0.2221],\n",
       "         [-0.0389, -0.0897, -0.0696,  ...,  0.1411,  0.0122,  0.3858]],\n",
       "\n",
       "        [[-0.0222,  0.0367,  0.1165,  ...,  0.1466,  0.0035, -0.0334],\n",
       "         [-0.1993, -0.3434,  0.0710,  ...,  0.0432, -0.1260, -0.1232],\n",
       "         [ 0.0278, -1.2574, -0.1178,  ..., -0.2000, -0.7025, -0.2102],\n",
       "         ...,\n",
       "         [ 0.1960, -0.2354,  0.3045,  ..., -0.3612, -0.2847,  0.6145],\n",
       "         [-0.0591, -1.1552,  0.1155,  ...,  0.4554, -0.0333,  0.6168],\n",
       "         [ 0.0111,  0.1789,  0.1200,  ...,  0.2875,  0.1656,  0.6577]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0514,  0.1225, -0.0349,  ...,  0.2321, -0.0349, -0.1094],\n",
       "         [ 0.1147, -0.2064, -0.1617,  ...,  0.2216, -0.0856,  0.1231],\n",
       "         [ 0.0680, -1.3419, -0.5367,  ..., -0.1168, -0.0169,  0.1782],\n",
       "         ...,\n",
       "         [-0.2956, -0.2580,  0.4027,  ..., -0.9304,  0.7551,  0.2485],\n",
       "         [ 0.0241,  0.2382,  0.1116,  ..., -0.2682,  0.0025, -0.2002],\n",
       "         [ 0.1209, -0.0625, -0.2627,  ...,  0.7223,  0.2062, -0.1883]],\n",
       "\n",
       "        [[ 0.0635,  0.1319, -0.0234,  ...,  0.1850, -0.0252, -0.1191],\n",
       "         [-0.2359, -0.0942, -0.3038,  ...,  0.2555, -0.0200,  0.0975],\n",
       "         [-0.2010, -1.2541, -0.3632,  ..., -0.2060, -0.3439, -0.0458],\n",
       "         ...,\n",
       "         [-0.1513, -0.3835,  0.1335,  ..., -0.6243,  0.9652, -0.3221],\n",
       "         [ 0.0599,  1.0650,  0.4061,  ..., -1.5190,  0.6497, -0.3326],\n",
       "         [ 0.3240, -0.6886, -0.1265,  ...,  0.6276,  0.1216, -0.3012]],\n",
       "\n",
       "        [[ 0.0508,  0.0997, -0.0409,  ...,  0.1753, -0.0587, -0.1151],\n",
       "         [ 0.1388, -0.2497, -0.1360,  ...,  0.0945, -0.0152,  0.0344],\n",
       "         [ 0.0998, -1.4654, -0.4708,  ..., -0.1336, -0.0663,  0.1832],\n",
       "         ...,\n",
       "         [ 0.3990,  0.1435, -0.2294,  ..., -0.8814, -0.3694, -0.1292],\n",
       "         [ 0.1659, -0.3556,  0.2072,  ..., -0.2971,  0.3618, -0.1768],\n",
       "         [ 0.3205, -0.0487,  0.0377,  ...,  0.4105, -0.0455, -0.2583]],\n",
       "\n",
       "        [[ 0.0502,  0.1402, -0.0613,  ...,  0.1875, -0.0346, -0.1181],\n",
       "         [ 0.0027, -0.2868, -0.3199,  ...,  0.1365, -0.1234, -0.0874],\n",
       "         [ 0.0258, -1.1858, -0.3707,  ..., -0.0979,  0.0579, -0.0412],\n",
       "         ...,\n",
       "         [ 0.1778, -0.1524,  0.2099,  ..., -0.5065, -0.2914,  0.6011],\n",
       "         [-0.1576, -1.2964, -0.0432,  ...,  0.4724, -0.1035,  0.5096],\n",
       "         [ 0.0570,  0.0373,  0.0174,  ...,  0.2630, -0.0788,  0.3017]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[ 2.7711e-02,  1.1851e-01, -9.6621e-02,  ...,  1.4659e-01,\n",
       "          -7.5337e-02, -7.2576e-02],\n",
       "         [-1.7578e-01, -1.1288e-01, -3.3357e-01,  ..., -5.5192e-02,\n",
       "           6.7158e-01, -6.2735e-01],\n",
       "         [-6.3238e-02, -1.2565e+00, -4.7800e-01,  ..., -3.8874e-01,\n",
       "           2.5320e-01, -6.9055e-01],\n",
       "         ...,\n",
       "         [-2.4026e-01, -4.2114e-01,  3.7445e-01,  ..., -8.7939e-01,\n",
       "           5.3844e-01,  7.2930e-01],\n",
       "         [-7.2683e-02, -4.3411e-03, -5.9003e-02,  ..., -1.7956e-01,\n",
       "          -2.8852e-01, -2.1365e-01],\n",
       "         [ 2.5753e-01, -1.8246e-01, -4.7700e-01,  ...,  6.9519e-01,\n",
       "          -2.4540e-01, -4.4015e-01]],\n",
       "\n",
       "        [[ 3.3766e-02,  1.4279e-01, -6.3092e-02,  ...,  1.0575e-01,\n",
       "          -8.0475e-02, -3.4581e-02],\n",
       "         [-3.2446e-01,  1.2723e-01, -3.2198e-01,  ..., -1.0616e-03,\n",
       "           6.0817e-01, -4.3402e-01],\n",
       "         [-2.8331e-01, -1.2794e+00, -5.8368e-02,  ..., -5.7538e-01,\n",
       "          -1.8031e-01, -6.3433e-01],\n",
       "         ...,\n",
       "         [ 1.3108e-01, -3.0131e-01, -3.1595e-01,  ..., -6.1314e-01,\n",
       "           4.4042e-01,  1.6509e-01],\n",
       "         [ 1.1424e-01,  1.3027e+00,  9.1315e-02,  ..., -1.5085e+00,\n",
       "           1.6944e-01,  2.7723e-01],\n",
       "         [ 4.6500e-01, -8.0180e-01, -2.8657e-01,  ...,  3.3694e-01,\n",
       "           6.6460e-02, -1.3251e-01]],\n",
       "\n",
       "        [[ 4.5126e-02,  1.4415e-01, -9.1725e-02,  ...,  1.0572e-01,\n",
       "          -1.1243e-01, -4.1642e-02],\n",
       "         [-2.1380e-01, -4.3938e-02, -1.5347e-01,  ..., -1.5556e-01,\n",
       "           7.8585e-01, -6.1109e-01],\n",
       "         [-1.5408e-01, -1.3123e+00, -3.2369e-01,  ..., -4.2173e-01,\n",
       "           3.3721e-01, -6.4370e-01],\n",
       "         ...,\n",
       "         [ 1.5776e-01,  1.6728e-02, -1.3488e-01,  ..., -9.2675e-01,\n",
       "          -7.8885e-01, -1.0618e-01],\n",
       "         [ 7.6643e-02, -4.1240e-01,  7.6976e-02,  ..., -9.9803e-02,\n",
       "           3.0009e-01, -4.9585e-02],\n",
       "         [ 1.6374e-01, -3.2935e-01, -7.0282e-02,  ...,  3.6693e-01,\n",
       "          -4.6365e-01, -2.7305e-01]],\n",
       "\n",
       "        [[-1.1457e-03,  1.8138e-01, -1.0182e-01,  ...,  1.4858e-01,\n",
       "          -1.1359e-01, -4.6936e-02],\n",
       "         [-2.0226e-01,  1.1123e-01, -2.8868e-01,  ..., -1.4840e-01,\n",
       "           4.2741e-01, -6.3351e-01],\n",
       "         [-1.2182e-01, -9.3126e-01, -3.5410e-01,  ..., -2.8918e-01,\n",
       "           2.0973e-01, -7.7657e-01],\n",
       "         ...,\n",
       "         [-5.3148e-01, -3.4020e-01,  3.6361e-01,  ..., -4.3433e-01,\n",
       "          -3.8505e-01, -5.9253e-02],\n",
       "         [ 9.9729e-02, -1.1798e+00,  3.8833e-01,  ...,  4.3279e-01,\n",
       "           1.2887e-01, -3.0984e-01],\n",
       "         [-3.0289e-01,  3.2177e-01,  3.0252e-01,  ...,  4.0071e-01,\n",
       "          -5.0271e-01,  7.5544e-02]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0647,  0.0759, -0.0454,  ...,  0.0146, -0.0546,  0.0070],\n",
       "         [-0.3364, -0.3982, -0.6897,  ..., -0.1434,  0.2300, -0.2547],\n",
       "         [ 0.0922, -1.6277, -0.4397,  ..., -0.1950,  0.4593, -0.4882],\n",
       "         ...,\n",
       "         [ 0.0813, -0.0869,  0.0343,  ..., -0.8095,  0.5763,  0.1053],\n",
       "         [ 0.2062, -0.0103, -0.0095,  ..., -0.2832, -0.1841, -0.4108],\n",
       "         [ 0.0213, -0.2665, -0.5423,  ...,  0.5337, -0.0378, -0.5004]],\n",
       "\n",
       "        [[ 0.0634,  0.0949, -0.0464,  ..., -0.0152, -0.0508,  0.0206],\n",
       "         [-0.5398, -0.2575, -0.5109,  ..., -0.3466,  0.1666,  0.2668],\n",
       "         [-0.4157, -1.4574, -0.1229,  ..., -0.5828,  0.2659, -0.3229],\n",
       "         ...,\n",
       "         [ 0.1635, -0.3777,  0.0682,  ..., -0.2873, -0.0391,  0.3168],\n",
       "         [ 0.0228,  1.2348,  0.1604,  ..., -1.4032,  0.0148,  0.4177],\n",
       "         [ 0.4059, -1.0679, -0.4933,  ...,  0.2971,  0.2926,  0.0833]],\n",
       "\n",
       "        [[ 0.0669,  0.0877, -0.0512,  ..., -0.0193, -0.0679,  0.0206],\n",
       "         [-0.2660, -0.3676, -0.5745,  ..., -0.2637,  0.4015, -0.4354],\n",
       "         [ 0.0281, -1.7654, -0.3581,  ..., -0.2087,  0.5721, -0.5476],\n",
       "         ...,\n",
       "         [ 0.2021, -0.6550, -0.1697,  ..., -1.2497, -0.8847,  0.1857],\n",
       "         [-0.3221, -0.6113, -0.1575,  ..., -0.0291,  0.1627,  0.2870],\n",
       "         [ 0.0370, -0.7078, -0.3673,  ...,  0.1058, -0.4366, -0.0538]],\n",
       "\n",
       "        [[ 0.0547,  0.0964, -0.0485,  ...,  0.0029, -0.0596,  0.0163],\n",
       "         [-0.2563, -0.2663, -0.5076,  ..., -0.3003,  0.0765, -0.1758],\n",
       "         [ 0.2151, -1.3490, -0.3337,  ..., -0.0979,  0.4006, -0.5563],\n",
       "         ...,\n",
       "         [ 0.2058,  0.1525,  0.4501,  ..., -0.4713, -0.3474,  0.3080],\n",
       "         [-0.1029, -0.8243,  0.1095,  ...,  0.8758,  0.1902,  0.0863],\n",
       "         [-0.3312,  0.7238,  0.2136,  ...,  0.3474, -0.1856,  0.2049]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0426,  0.0626, -0.0174,  ...,  0.0147,  0.0520, -0.0314],\n",
       "         [-0.3689, -0.1628, -0.3042,  ...,  0.0217,  0.1740, -0.0934],\n",
       "         [-0.2512, -1.4258,  0.0379,  ..., -0.1669,  0.1952, -0.4168],\n",
       "         ...,\n",
       "         [ 0.0205, -0.6174,  0.3144,  ..., -0.6068,  0.1860, -0.3614],\n",
       "         [ 0.5187,  0.3133,  0.1564,  ..., -0.1830, -0.4204, -0.3608],\n",
       "         [ 0.1675, -0.2671, -0.4066,  ...,  0.4469, -0.1692, -0.5713]],\n",
       "\n",
       "        [[-0.0511,  0.0656, -0.0272,  ...,  0.0080,  0.0492, -0.0211],\n",
       "         [-0.2963, -0.1148,  0.0440,  ..., -0.1915, -0.1594,  0.5469],\n",
       "         [ 0.0459, -1.3906,  0.5069,  ..., -0.7323, -0.1206, -0.0166],\n",
       "         ...,\n",
       "         [ 0.4715, -0.3020, -0.2424,  ...,  0.0441,  0.0118, -0.0903],\n",
       "         [ 0.1709,  1.3882,  0.0460,  ..., -0.8973, -0.0037, -0.2049],\n",
       "         [ 0.5987, -0.7518, -0.9920,  ...,  0.3204,  0.3774, -0.0253]],\n",
       "\n",
       "        [[-0.0488,  0.0603, -0.0174,  ...,  0.0122,  0.0429, -0.0265],\n",
       "         [-0.2782, -0.0957, -0.1824,  ..., -0.0609,  0.2320, -0.3877],\n",
       "         [-0.2139, -1.5552,  0.1210,  ..., -0.1782,  0.3288, -0.4552],\n",
       "         ...,\n",
       "         [ 0.2906, -0.6379,  0.0562,  ..., -0.6743, -0.0468, -0.1537],\n",
       "         [-0.0913, -0.3105, -0.0093,  ...,  0.3927,  0.1568,  0.4266],\n",
       "         [-0.3512, -0.7160, -0.7775,  ...,  0.4216, -0.9069, -0.0188]],\n",
       "\n",
       "        [[-0.0522,  0.0695, -0.0083,  ...,  0.0123,  0.0520, -0.0254],\n",
       "         [-0.3428, -0.0805, -0.1638,  ..., -0.1979,  0.0027, -0.0665],\n",
       "         [-0.2386, -1.1736,  0.1235,  ..., -0.0292,  0.2062, -0.4437],\n",
       "         ...,\n",
       "         [ 0.3534,  0.2783,  0.8204,  ..., -0.1600, -0.3415, -0.2823],\n",
       "         [-0.3308, -0.3011,  0.0834,  ...,  1.0433, -0.0583, -0.0662],\n",
       "         [-0.7555,  1.0935,  0.3559,  ...,  0.0046,  0.2143,  0.4428]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0771,  0.0379, -0.0107,  ...,  0.0332,  0.0304, -0.0193],\n",
       "         [-0.8354, -0.5119, -0.2967,  ..., -0.0916, -0.0167, -0.1291],\n",
       "         [-0.4441, -1.8254, -0.2948,  ..., -0.4701, -0.3683, -0.4526],\n",
       "         ...,\n",
       "         [ 0.0542, -1.0010, -0.0441,  ..., -0.4713,  0.1595, -0.6324],\n",
       "         [ 0.1131, -0.2556,  0.3320,  ..., -0.1715,  0.1622,  0.0176],\n",
       "         [ 0.0042, -0.3354, -0.3527,  ...,  0.3052, -0.3082, -0.2358]],\n",
       "\n",
       "        [[-0.0738,  0.0352, -0.0064,  ...,  0.0278,  0.0319, -0.0143],\n",
       "         [-0.4199, -0.4042, -0.0946,  ..., -0.2190,  0.1268,  0.3524],\n",
       "         [ 0.2087, -1.6931, -0.2835,  ..., -0.9743, -0.2728, -0.1780],\n",
       "         ...,\n",
       "         [ 0.0375, -0.3544, -0.7173,  ..., -0.1579,  0.2057, -0.6893],\n",
       "         [-0.0697,  1.2451, -0.3373,  ..., -0.6530,  0.1015, -0.3595],\n",
       "         [ 0.1543, -0.5606, -1.0635,  ...,  0.0328,  0.4226,  0.0625]],\n",
       "\n",
       "        [[-0.0782,  0.0372, -0.0082,  ...,  0.0302,  0.0260, -0.0163],\n",
       "         [-0.7938, -0.4743, -0.1566,  ..., -0.1538,  0.0395, -0.2696],\n",
       "         [-0.4834, -2.0565, -0.2910,  ..., -0.4364, -0.2574, -0.4668],\n",
       "         ...,\n",
       "         [ 0.0671, -0.5483,  0.0658,  ..., -0.6803, -0.2176, -0.1500],\n",
       "         [-0.0600, -0.0598, -0.3077,  ...,  0.4762, -0.0827,  0.2414],\n",
       "         [-0.7308, -0.4766, -0.6026,  ...,  0.7126, -1.2103,  0.2582]],\n",
       "\n",
       "        [[-0.0708,  0.0367, -0.0051,  ...,  0.0306,  0.0333, -0.0199],\n",
       "         [-0.8527, -0.3364, -0.1568,  ..., -0.3808, -0.0930, -0.3178],\n",
       "         [-0.4797, -1.6222, -0.1491,  ..., -0.4158, -0.3718, -0.3962],\n",
       "         ...,\n",
       "         [ 0.2553, -0.0056,  0.5515,  ...,  0.0415,  0.0741, -0.5109],\n",
       "         [-0.7334, -0.1671, -0.1063,  ...,  0.8154, -0.0772, -0.2188],\n",
       "         [-0.9362,  0.7737,  0.0102,  ...,  0.1815, -0.2927,  0.3807]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.0297,  0.0865, -0.0221,  ...,  0.0203, -0.0046, -0.0528],\n",
       "         [-0.2270, -0.7160, -0.3083,  ...,  0.2820,  0.5089, -0.5677],\n",
       "         [ 0.3045, -1.9404, -0.3053,  ..., -0.6044,  0.0992, -0.4363],\n",
       "         ...,\n",
       "         [ 0.0598, -0.8599, -0.2959,  ..., -0.2344,  0.6200, -0.8348],\n",
       "         [ 0.0482, -0.4597, -0.0675,  ..., -0.2040,  0.5216, -0.6102],\n",
       "         [-0.0999, -0.6548, -0.5798,  ...,  0.1777, -0.0241, -0.2065]],\n",
       "\n",
       "        [[-0.0213,  0.0849, -0.0213,  ...,  0.0173, -0.0043, -0.0465],\n",
       "         [ 0.3380, -0.2967, -0.2541,  ..., -0.1234,  0.4986, -0.0036],\n",
       "         [ 0.6479, -1.3474, -0.4731,  ..., -1.2241,  0.0378, -0.0611],\n",
       "         ...,\n",
       "         [ 0.2140, -0.3553, -1.0793,  ..., -0.0988,  0.1064, -0.5203],\n",
       "         [ 0.2492,  0.9325, -0.4179,  ..., -0.6718, -0.0477, -0.2662],\n",
       "         [ 0.3539, -0.4459, -0.9070,  ..., -0.0293,  0.5522, -0.2255]],\n",
       "\n",
       "        [[-0.0209,  0.0825, -0.0187,  ...,  0.0199,  0.0049, -0.0447],\n",
       "         [-0.2413, -0.7495, -0.2458,  ...,  0.2652,  0.3072, -0.5974],\n",
       "         [ 0.1699, -2.0157, -0.3021,  ..., -0.6116,  0.1043, -0.4098],\n",
       "         ...,\n",
       "         [ 0.0041, -0.4436,  0.2574,  ..., -0.6699, -0.0575, -0.0360],\n",
       "         [-0.0505, -0.3031,  0.2033,  ...,  0.4642,  0.2194,  0.2242],\n",
       "         [-0.3499, -0.5801, -0.4305,  ...,  0.8415, -1.0074,  0.3255]],\n",
       "\n",
       "        [[-0.0294,  0.0999, -0.0293,  ...,  0.0055,  0.0022, -0.0522],\n",
       "         [-0.1693, -0.5224, -0.1109,  ..., -0.0097,  0.4828, -0.6007],\n",
       "         [ 0.2409, -1.6847, -0.0440,  ..., -0.5744,  0.1736, -0.3553],\n",
       "         ...,\n",
       "         [ 0.2018, -0.1209,  0.6885,  ...,  0.2955,  0.6510, -0.1977],\n",
       "         [-0.3977, -0.1054,  0.1152,  ...,  0.7319,  0.0432, -0.0974],\n",
       "         [-0.8482,  0.3607,  0.5868,  ...,  0.7320, -0.0631,  0.5998]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.3717, -0.7092, -0.2582,  ...,  0.3469,  0.3358, -0.4262],\n",
       "         [-0.1172, -0.4977, -0.3255,  ...,  0.7220,  0.0540, -0.7019],\n",
       "         [ 0.0620, -1.4104, -0.2751,  ..., -0.8366, -0.0621, -0.5348],\n",
       "         ...,\n",
       "         [-0.4283, -0.6859, -0.1539,  ...,  0.0352, -0.0454, -1.4535],\n",
       "         [-0.0473, -0.3818, -0.4050,  ...,  0.3636,  0.0185, -1.1717],\n",
       "         [ 0.1628, -0.2731, -0.4481,  ..., -0.1551, -0.0023, -0.2328]],\n",
       "\n",
       "        [[-0.5919, -0.8480, -0.5311,  ...,  0.4817, -0.0684, -0.5817],\n",
       "         [ 0.0735, -0.2169, -0.3575,  ...,  0.4432,  0.3001, -0.2124],\n",
       "         [ 0.1027, -0.8445, -0.5376,  ..., -1.4637,  0.0094,  0.2103],\n",
       "         ...,\n",
       "         [ 1.0615, -0.2603, -1.2151,  ...,  0.4057, -0.0658,  0.4686],\n",
       "         [ 0.5192, -0.0962, -0.4071,  ...,  0.0023, -0.0727, -0.3963],\n",
       "         [ 0.0883, -0.1224, -0.3437,  ..., -0.0188,  0.3819, -0.0345]],\n",
       "\n",
       "        [[-0.4914, -0.6923, -0.2729,  ..., -0.0216,  0.4140, -0.6273],\n",
       "         [-0.2116, -0.5216, -0.4079,  ...,  0.5020,  0.3882, -0.6379],\n",
       "         [-0.2550, -1.7517, -0.1500,  ..., -1.2746,  0.2730, -0.1412],\n",
       "         ...,\n",
       "         [-0.2816, -0.1639, -0.5150,  ..., -0.5874,  0.2325,  0.0595],\n",
       "         [-0.1862, -0.2221,  0.0933,  ...,  0.0997,  0.3096,  0.1371],\n",
       "         [-0.4301, -0.2910, -0.5221,  ...,  0.3292, -0.4089,  0.5274]],\n",
       "\n",
       "        [[-0.1565, -0.0579, -0.2130,  ..., -0.0510,  0.2079, -0.0839],\n",
       "         [-0.5007, -0.3150, -0.4684,  ...,  0.3854,  0.4796, -0.6907],\n",
       "         [-0.4125, -1.0686, -0.1748,  ..., -0.9834,  0.3777, -0.1478],\n",
       "         ...,\n",
       "         [-0.6264, -0.1029,  0.4156,  ...,  0.8325,  0.4049,  0.0661],\n",
       "         [-0.5132,  0.1978, -0.1088,  ...,  0.7921,  0.2797,  0.7323],\n",
       "         [-0.4712,  0.2871,  0.0752,  ...,  0.1572,  0.2276,  0.5396]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)), attentions=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.lr_scheduler.LambdaLR at 0x7ff934fa4f40>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "# # Instantiate scheduler\n",
    "# lr_scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer=optimizer,\n",
    "#     num_warmup_steps=0.06 * (len(train_dataloader) * num_epochs),\n",
    "#     num_training_steps=(len(train_dataloader) * num_epochs),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"f1\", module_type: \"metric\", features: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)}, usage: \"\"\"\n",
       "Args:\n",
       "    predictions (`list` of `int`): Predicted labels.\n",
       "    references (`list` of `int`): Ground truth labels.\n",
       "    labels (`list` of `int`): The set of labels to include when `average` is not set to `'binary'`, and the order of the labels if `average` is `None`. Labels present in the data can be excluded, for example to calculate a multiclass average ignoring a majority negative class. Labels not present in the data will result in 0 components in a macro average. For multilabel targets, labels are column indices. By default, all labels in `predictions` and `references` are used in sorted order. Defaults to None.\n",
       "    pos_label (`int`): The class to be considered the positive class, in the case where `average` is set to `binary`. Defaults to 1.\n",
       "    average (`string`): This parameter is required for multiclass/multilabel targets. If set to `None`, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data. Defaults to `'binary'`.\n",
       "\n",
       "        - 'binary': Only report results for the class specified by `pos_label`. This is applicable only if the classes found in `predictions` and `references` are binary.\n",
       "        - 'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
       "        - 'macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
       "        - 'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters `'macro'` to account for label imbalance. This option can result in an F-score that is not between precision and recall.\n",
       "        - 'samples': Calculate metrics for each instance, and find their average (only meaningful for multilabel classification).\n",
       "    sample_weight (`list` of `float`): Sample weights Defaults to None.\n",
       "\n",
       "Returns:\n",
       "    f1 (`float` or `array` of `float`): F1 score or list of f1 scores, depending on the value passed to `average`. Minimum possible value is 0. Maximum possible value is 1. Higher f1 scores are better.\n",
       "\n",
       "Examples:\n",
       "\n",
       "    Example 1-A simple binary example\n",
       "        >>> f1_metric = evaluate.load(\"f1\")\n",
       "        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0])\n",
       "        >>> print(results)\n",
       "        {'f1': 0.5}\n",
       "\n",
       "    Example 2-The same simple binary example as in Example 1, but with `pos_label` set to `0`.\n",
       "        >>> f1_metric = evaluate.load(\"f1\")\n",
       "        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], pos_label=0)\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.67\n",
       "\n",
       "    Example 3-The same simple binary example as in Example 1, but with `sample_weight` included.\n",
       "        >>> f1_metric = evaluate.load(\"f1\")\n",
       "        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], sample_weight=[0.9, 0.5, 3.9, 1.2, 0.3])\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.35\n",
       "\n",
       "    Example 4-A multiclass example, with different values for the `average` input.\n",
       "        >>> predictions = [0, 2, 1, 0, 0, 1]\n",
       "        >>> references = [0, 1, 2, 0, 1, 2]\n",
       "        >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"macro\")\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.27\n",
       "        >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"micro\")\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.33\n",
       "        >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"weighted\")\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.27\n",
       "        >>> results = f1_metric.compute(predictions=predictions, references=references, average=None)\n",
       "        >>> print(results)\n",
       "        {'f1': array([0.8, 0. , 0. ])}\n",
       "\n",
       "    Example 5-A multi-label example\n",
       "        >>> f1_metric = evaluate.load(\"f1\", \"multilabel\")\n",
       "        >>> results = f1_metric.compute(predictions=[[0, 1, 1], [1, 1, 0]], references=[[0, 1, 1], [0, 1, 0]], average=\"macro\")\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.67\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/224 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [02:54<00:00,  1.28it/s]\n",
      "100%|██████████| 1557/1557 [08:14<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'f1': 0.09580728769629517}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [03:03<00:00,  1.22it/s]\n",
      " 13%|█▎        | 205/1557 [01:08<07:33,  2.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 208/1557 [01:09<07:41,  2.92it/s]"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch.to(device)\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        predictions, references = predictions, batch[\"labels\"]\n",
    "        metric.add_batch(\n",
    "            predictions=predictions,\n",
    "            references=references,\n",
    "        )\n",
    "\n",
    "    eval_metric = metric.compute(average = \"macro\")\n",
    "    print(f\"epoch {epoch}:\", eval_metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./peft_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reload saved peft weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_dir = \"/mnt/sdc/niallt/saved_models/peft_training/ckpts/icd9-triage-no-category-in-text/fewshot_64/mimic-roberta-base/declutr/2_anch_2_pos_min_1024/LORA/23-06-2023--11-41/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /mnt/sdc/niallt/saved_models/declutr/mimic/few_epoch/mimic-roberta-base/2_anch_2_pos_min_1024/transformer_format/ were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /mnt/sdc/niallt/saved_models/declutr/mimic/few_epoch/mimic-roberta-base/2_anch_2_pos_min_1024/transformer_format/ and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "config = PeftConfig.from_pretrained(peft_model_dir)\n",
    "# load base model \n",
    "model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path, num_labels = 7)\n",
    "# load peft model\n",
    "model = PeftModel.from_pretrained(model, peft_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# below is miscellanous code that is not used in the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                                                      Param #\n",
       "====================================================================================================\n",
       "PeftModelForSequenceClassification                                          --\n",
       "├─LoraModel: 1-1                                                            --\n",
       "│    └─RobertaForSequenceClassification: 2-1                                --\n",
       "│    │    └─RobertaModel: 3-1                                               124,349,952\n",
       "│    │    └─ModulesToSaveWrapper: 3-2                                       1,191,950\n",
       "====================================================================================================\n",
       "Total params: 125,541,902\n",
       "Trainable params: 1,486,862\n",
       "Non-trainable params: 124,055,040\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta model gpu usage\n",
    "18777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declutr model gpu usage\n",
    "19905 - 19595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': PromptTuningConfig(peft_type=<PeftType.PROMPT_TUNING: 'PROMPT_TUNING'>, base_model_name_or_path='roberta-base', task_type='SEQ_CLS', inference_mode=False, num_virtual_tokens=10, token_dim=768, num_transformer_submodules=1, num_attention_heads=12, num_layers=12, prompt_tuning_init=<PromptTuningInit.RANDOM: 'RANDOM'>, prompt_tuning_init_text=None, tokenizer_name_or_path=None)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.peft_config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "39nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
